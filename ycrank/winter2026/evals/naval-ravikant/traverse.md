# Traverse -- Naval Ravikant Evaluation

The first thing I notice is who's already in this market. Mechanize — backed by Nat Friedman and Daniel Gross, two people whose judgment I trust enough to follow into unfamiliar domains — is already working with Anthropic. Scale AI at a $29B valuation and Surge AI at $1.2B in revenue are both expanding into RL environments. Wing VC counts 35+ entrants. The customer base is five frontier labs. This is the opposite of a contrarian bet — this is a hot market with consensus pricing, where the smart money has already chosen its horses. When I invested in Uber, ride-sharing was illegal. When I backed Bitcoin, it was nerd money. Traverse is entering a space where every VC blog has published their RL environment thesis, and the question isn't whether the market exists but whether a two-person team that pivoted weeks ago can win it.

The specific knowledge question is where this falls apart for me. Lance Yan led ML at a university AI organization and worked at Kalshi. Zachary Yu worked at Mercor and Uber AI Solutions. These are smart, technically literate builders with adjacency to the AI lab ecosystem — but adjacency is not depth. Building verifiers for non-deterministic domains — for taste, for subjective judgment in medicine and law — requires the kind of knowledge that comes from years of obsessive engagement with the problem of machine evaluation of human judgment. Nothing in either founder's background suggests they've been living inside this specific problem. They pivoted from Clice AI, which was personal AI agents for team coordination — a fundamentally different product and a fundamentally different insight. The pivot during the YC batch tells me they're responsive, maybe even sharp, but it also tells me their engagement with non-deterministic RL verification is measured in weeks. Any competent ML team could identify the same gap between deterministic and non-deterministic RL training after reading the same Wing VC analysis these founders presumably read.

The leverage architecture concerns me almost as much. Contracted RL environment construction for individual labs is closer to selling your time than owning equity in a scalable system. Each domain requires custom verifier work. Each lab has specific needs. The company's own framing — "mastery in one domain before scaling lessons across fields" — describes sequential, labor-intensive expansion, not a platform where one engineer's work serves millions. Compare this to Stack Overflow, where every question answered made the knowledge graph more valuable for every future user. Or Alchemy, where the API layer served every blockchain developer simultaneously. Traverse is proposing to build bespoke verifiers for a handful of buyers. That's a services business with a technology wrapper. Where does the nonlinear output come from?

The strongest bull case is genuinely interesting, and I want to engage with it honestly. If the non-deterministic verifier problem is as hard as it sounds — if building reliable evaluation for subjective, taste-dependent work requires a fundamentally different methodology than scaling up human labelers — then whoever cracks it first owns something every lab will pay for. The big data companies are optimized for deterministic labeling at scale; retooling for subjective verification may require different intuitions, different processes, different hiring. If Traverse builds genuine compounding expertise through tight feedback loops with one lab, and if that expertise transfers across domains, they could be one of the 3-5 survivors Wing VC predicts. The timing is real — labs are spending tens of millions annually and that budget is growing 3-5x. But "if" is doing enormous work in every sentence of this paragraph. This requires two early-career founders, post-pivot, with no demonstrated RL training expertise, to out-execute Scale AI's resources, Surge AI's contractor network, and Mechanize's lab relationships — all while selling to a customer base small enough to count on one hand.

The compounding and defensibility story is the weakest link. The dossier says it plainly: "No defensibility signals found in public sources." No proprietary datasets, no patents, no network effects, no accumulated data moat. The inferred moat — domain-specific verifier expertise that improves with lab feedback — is a hypothesis about the future, not a present reality. In a market consolidating to 3-5 players from 35+, the survivors will be the ones with the deepest lab relationships, the most accumulated training data, and the most proven verifier quality. Traverse starts from zero on all three dimensions, competing against companies with billion-dollar resources and existing Anthropic contracts.

These are capable young builders who identified a real problem. But capable builders in a consensus market with no demonstrated specific knowledge, no leverage mechanics, and no defensibility — that's a company I wish well but don't fund. The knowledge that makes this company succeed has to be learned on the job, which means it can be learned by anyone, which means it will be.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 6/30 |
| Leverage Architecture and Scalability of the Model | 9/25 |
| Contrarian Positioning and Non-Consensus Timing | 7/20 |
| Founder Integrity and Long-Term Orientation | 8/15 |
| Technical Compounding and Defensibility Over Time | 4/10 |
| **Total** | **34/100** |

**Total Score: 34/100** (Pass)
