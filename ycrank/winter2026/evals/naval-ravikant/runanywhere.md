# RunAnywhere -- Naval Ravikant Evaluation

The most striking thing about RunAnywhere is the competitive terrain it occupies. Meta ships ExecuTorch powering billions of devices. Google has MediaPipe with LLM inference APIs. Apple has MLX optimized for its own silicon. Nexa AI has $3.4M in revenue and a 31-person team with a two-year head start. And into this, two engineers from Rochester Institute of Technology are shipping a cross-platform SDK with the thesis that none of these incumbents will build the commercial control plane. This is not a contrarian bet -- it's a consensus market with a business model hypothesis layered on top. The question is whether that business model layer -- the fleet management, policy routing, OTA delivery -- is a durable wedge or a feature that any of these incumbents can bolt on when they decide to.

The specific knowledge question is where this falls short for me. Sanchit spent time as an SWE 2 at Intuit. Shubham worked at AWS on distributed systems. Relevant, yes. But this is pipeline knowledge -- the kind of expertise you acquire through a standard engineering career at good companies. When I backed the Alchemy founders, they'd been living inside the crypto infrastructure problem for years and could articulate non-obvious constraints about node reliability that surprised people who'd been in the space longer. I don't see that here. The insight that on-device AI deployment is fragmented across platforms and runtimes is real, but it's the observation any competent mobile developer would make after two weeks of trying to ship a local model. Specific knowledge isn't just knowing the problem exists -- it's knowing something about the solution space that others can't easily learn.

The leverage architecture is where the company is most structurally sound, and it's the reason I'm not dismissing it outright. The open-source SDK with a commercial control plane is the proven open-core infrastructure playbook -- GitLab, HashiCorp, Confluent all walked this path. A single API abstracting iOS, Android, React Native, Flutter, and web creates integration surface area. The control plane layer -- OTA model delivery, policy-based routing between local and cloud inference, fleet analytics -- has genuine switching costs once embedded in production workflows. That's real leverage potential. But the SDK itself is a convenience wrapper over existing runtimes (llama.cpp, CoreML, ONNX). It's not a new computational primitive. It's distribution and developer experience, not deep technology. The leverage is in the control plane, and the control plane has zero paying customers that I can see.

The bull case deserves genuine engagement. If on-device AI follows the trajectory of cloud computing -- from "interesting but niche" to "required infrastructure" -- then whoever owns the developer SDK and management layer wins disproportionately. 9,000 GitHub stars for a pre-seed company is real community traction, not noise. The cross-platform coverage is time-consuming to replicate even for well-funded teams. Meta and Google have a structural disincentive to build a commercial control plane -- Meta monetizes through ads and wants you in their PyTorch ecosystem, Google monetizes through cloud and doesn't want to cannibalize inference revenue. That business model misalignment is a real opening. If RunAnywhere can convert 1% of that open-source community into paying enterprise customers before a competitor closes the gap, the compounding begins. The Alchemy parallel would require the founders to rapidly develop the domain-specific intuition they currently lack -- possible, but it's a bet on learning speed rather than demonstrated knowledge.

The timing is consensus, not contrarian. Every hardware manufacturer, every cloud provider, every ML framework team is talking about on-device AI in 2025-2026. When I invested in Uber, ride-sharing was illegal. When I invested in Bitcoin, it was dismissed as nerd money. RunAnywhere is entering a market where Apple's keynotes feature on-device AI, Qualcomm designs NPUs specifically for local inference, and the EU AI Act creates regulatory tailwinds. The founders aren't betting against a gloomy crowd -- they're surfing the same wave everyone else sees. That doesn't make it a bad business, but it removes the asymmetric upside that comes from being right when others think you're wrong. The pricing of this opportunity already reflects the optimism.

I'd pass. The founders are competent engineers building useful infrastructure, but the specific knowledge isn't there -- this is a problem identified through standard engineering experience, not years of domain obsession. The competitive landscape features the three most powerful technology companies on earth giving away free tools in the same space. The timing is peak consensus. And the technology is a wrapper layer, not a compounding primitive. For this to work at the scale I invest for, either the founders need to develop non-obvious insights about on-device AI orchestration faster than well-resourced competitors, or the control plane needs to become so operationally embedded that switching costs protect it. Both are possible. Neither is evidenced yet.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 7/30 |
| Leverage Architecture and Scalability of the Model | 14/25 |
| Contrarian Positioning and Non-Consensus Timing | 7/20 |
| Founder Integrity and Long-Term Orientation | 8/15 |
| Technical Compounding and Defensibility Over Time | 5/10 |
| **Total** | **41/100** |

**Total Score: 41/100** (Pass)
