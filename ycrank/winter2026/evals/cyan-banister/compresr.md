# Compresr -- Cyan Banister Evaluation

Here's the thing that jumped out at me before anything else: this is an AI infrastructure cost-optimization tool in 2026. That might be the single most consensus category in venture capital right now. Every investor I talk to is looking for "picks and shovels" plays in AI. Developer tools, inference optimization, middleware layers — the deal flow is a firehose of these companies. When I say I'm looking for companies that are not popular and difficult to assess, Compresr is the inverse of that. It's easy to understand, it's in a hot space, and it has well-funded competitors and a free open-source alternative from Microsoft with nearly six thousand GitHub stars already integrated into the major frameworks. The weirdness has been completely arbitraged out of this category before Compresr even got started.

If I could sit down with these founders, my first question would be the same one it always is — tell me your story, not the business. And from what I can see in this dossier, the answer would be: "We were at EPFL, we researched prompt compression in the Data Science Lab, and we decided to productize it." That's a legitimate origin story for a technical product, and I respect the domain expertise. Ivan Zakazov specifically researched LLM context compression, Oussama Gabouj worked on prompt compression and efficient ML systems. They know the problem space academically. But I'm not hearing the biographical thread that tells me this person will fight through the crisis that inevitably comes — the moment when Microsoft decides to commercialize LLMLingua, or when OpenAI drops token prices another 10x, or when Anthropic expands prompt caching to make compression redundant. My portfolio is full of founders whose life story made quitting unthinkable. Here I see four talented graduate students who could return to research if the startup doesn't work. That doesn't disqualify them — it just means I'm not the right investor for this.

The strongest bull case, and I want to be honest about it, is this: agentic AI workflows are generating explosion-level token volumes through conversation history, tool traces, and retrieved context. Even as per-token costs fall, total inference spend is doubling. Someone could become the Cloudflare of AI inference — a proxy layer that sits between every application and every LLM API, compressing and optimizing all that traffic. The Context Gateway architecture is the right shape for that vision, and the structural disincentive for LLM providers to offer native compression (it cannibalize their per-token revenue) creates a genuine window. If Compresr builds materially superior compression to LLMLingua and packages it as a frictionless managed service, they could capture real value. That's a plausible path to a meaningful company.

But I keep coming back to the same structural concern: this company's entire value proposition is pegged to token costs remaining expensive enough to justify paying for compression. LLM inference costs have fallen roughly 10x annually, and providers are simultaneously expanding context windows. Anthropic already ships prompt caching. OpenAI offers cached context discounts. The trend line points toward a world where the pain this product addresses gets naturally solved by platform evolution. It's like building a company around optimizing dial-up modem speeds right before broadband arrives. The timing window might be real, but it's closing, and I don't see a moat that survives the transition. Claimed proprietary algorithms that "outperform traditional retrieval baselines" with no published benchmarks are a research assertion, not a defensibility story.

On the team dynamics front, four co-founders from the same EPFL ecosystem is actually one of the better signals here — shared context, shared vocabulary, likely years of working together. But four peer-level founders (all Master's or PhD students) without a demonstrated hierarchy makes me think about my HQ Trivia lesson. How do they resolve fundamental disagreements? Who has final say? The fact that they gave themselves four different C-suite titles (CEO, CTO, CAIO, COO) doesn't answer that question — it might even mask it. I'd want to probe this deeply before writing a check.

This company doesn't create economic access for underserved populations, doesn't operate in a stigmatized or regulated space that deters other investors, and doesn't give me the visceral jolt of energy I felt with investments like Niantic or Crusoe. It's a technically competent team building a useful product in a crowded, consensus category with significant commoditization risk. There are investors who are the right fit for this — someone who evaluates compression benchmarks and developer adoption curves and infrastructure layer economics. I'm not that investor. I'm looking for the founders and ideas that everyone else has passed on, the ones that seem a little crazy until they're not. This one seems perfectly rational, which is exactly my concern.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Founder Biographical Grit and Personal Stake | 8/30 |
| Anti-Consensus Conviction and Weird Factor | 5/25 |
| Economic Access and Real-World Impact | 3/20 |
| Navigating Complexity in Hard Spaces | 4/15 |
| Co-Founder Alignment and Team Resilience | 5/10 |
| **Total** | **25/100** |

**Total Score: 25/100** (Pass)
