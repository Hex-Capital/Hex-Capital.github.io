# Overshoot -- Peter Thiel Evaluation

The competitive landscape tells you everything you need to know. Fireworks AI has raised $331 million and is valued at four billion dollars. Together AI has raised $534 million. Replicate was acquired by Cloudflare. AWS, Google, and Azure all offer vision APIs. Into this arena step two founders with a two-person team and the thesis that inference for video needs to be specialized. This is not a secret -- it is an engineering observation that every platform engineer at these companies has already made. The question is not whether video inference benefits from specialization; the question is whether that specialization justifies an independent company when incumbents with hundred-million-dollar war chests can assign a team to the problem next quarter. The answer, structurally, is no. Overshoot is entering a market that is already competitive and becoming more so. The Girardian dynamics are clear: multiple players converging on the same models, the same developers, the same use cases. This is precisely the Red Ocean I avoid.

The founders deserve more credit than the thesis. Zakaria built low-latency pricing systems at Uber for seven years -- surge pricing is among the most demanding real-time infrastructure problems in consumer technology -- and then wrote GPU kernels and inference engines at Meta AI. Younes was a founding engineer at COSMONiO, a computer vision company acquired by Intel in 2020, where he built a training and serving platform from scratch. These are not "men in suits." They have genuine technical depth in exactly the domains this company requires. The cousin relationship adds relational trust. If I were evaluating only on founder-market fit, this team would score well. But founder quality cannot compensate for structural deficiency in the market itself. Brilliant people building in a competitive market still lose -- they just lose more impressively.

The claim of 10x faster inference warrants scrutiny. Overshoot asserts sub-200ms latency on vision workloads, which they describe as ten times faster than existing platforms. But faster inference on open-source models -- Qwen3-VL, InternVL -- is optimization, not invention. Overshoot did not create these models. It does not control their development roadmap. It cannot prevent Fireworks or Together from running the same models with their own optimizations. The "three lines of code" SDK integration is developer-friendly, but it is also a thin layer -- thin layers create convenience, not lock-in. When Stripe launched, there was no competent developer payments API; the gap was structural. Overshoot is building a video-specialized variant of APIs that already exist and already support vision models. This is going from one to n, not from zero to one. A better version of something that exists is not a monopoly -- it is a feature.

The bull case requires believing three things simultaneously: that real-time VLM inference for video is genuinely different enough from text and image inference to sustain a standalone platform indefinitely; that the specialization advantage compounds faster than generalist platforms can close the gap; and that developer SDK adoption creates meaningful switching costs. If all three are true, Overshoot could become the Twilio of video AI -- the default infrastructure layer that developers reach for because nobody else has optimized the codec-streaming-inference stack as deeply. Zakaria's specific experience building both low-latency systems and GPU inference engines is the right combination for this, and the timing -- VLMs crossing the real-time performance threshold in 2024-2025 -- creates a window. But the window is open to everyone, and the players with hundreds of millions in capital have stronger structural incentives to close it than Overshoot has to hold it. The history of specialized inference companies being absorbed by platforms is not encouraging. Replicate, the closest analogy in the model-hosting space, was acquired by Cloudflare rather than achieving independent dominance -- and that outcome does not generate power-law returns.

The absence of any identifiable monopoly mechanism is the decisive factor. No network effects -- developer usage of one vision API does not make the next developer's experience better. No proprietary technology -- the models are open-source, the infrastructure optimizations are replicable. No data moat -- Overshoot processes video but does not appear to accumulate proprietary data from it. No meaningful switching costs -- an API call is an API call. Twelve GitHub stars and 300-1,000 developers (the ambiguity between these numbers is itself a minor flag) represent the earliest possible traction. The company is competing on execution speed in a market where the better-capitalized players will eventually prioritize the same optimizations. I look for companies where early dominance creates structural advantages that widen over time. Here, early presence in the market creates no such compounding advantage. The endgame is absorption or commoditization, not monopoly.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Contrarian Secret and Monopoly Potential | 8/35 |
| Founder Conviction and Definite Vision | 14/25 |
| Technological Discontinuity and 10x Superiority | 8/20 |
| Durability and Last-Mover Defensibility | 3/10 |
| Small-Market Dominance with Expansion Path | 5/10 |
| **Total** | **38/100** |

**Total Score: 38/100** (Pass)
