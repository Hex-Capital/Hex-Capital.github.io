# o11 -- Naval Ravikant Evaluation

The first thing I notice is the structural contradiction: two founders in their teens building AI tooling for investment bankers and private equity professionals -- arguably the most workflow-demanding, formatting-obsessed, domain-specific user base in all of enterprise software. The question isn't whether Aryah and Ajay are smart. A Morehead-Cain scholarship and scaling AI at a 10M-user consumer app at age 20 signal raw horsepower. The question is what they know about capital markets that can't be acquired through customer interviews. A DCF model isn't just a spreadsheet formula -- it encodes assumptions about discount rates, terminal values, and comparable company selection that reflect years of pattern recognition. A pitch deck for a leveraged buyout isn't just slides -- it's a language game with implicit conventions that signal credibility to specific audiences. When the founders say "bankers told us they were tired of chat bots that couldn't do real work," that's market research, not specific knowledge. Anyone who spent three months interviewing bankers would hear the same complaint. Specific knowledge in this domain looks like someone who has built models under time pressure at 2 AM, who understands why the formatting of a CIM matters as much as its content, who knows which FactSet fields actually drive deal decisions. I don't see that here.

The leverage architecture is where this should get interesting -- and doesn't. The M365 add-in strategy is clever positioning but it's borrowed leverage, not created leverage. o11 doesn't own the platform; Microsoft does. Every API change, every add-in policy revision, every Copilot feature expansion is an existential variable outside the founders' control. Compare this to Stack Overflow, which owned its knowledge graph, or Notion, which owned its document model. o11 is building on rented infrastructure and calling it a moat. The software scales like any SaaS -- that's baseline, not exceptional. There are no network effects (one banker's usage doesn't make the product better for another), no marketplace dynamics, no protocol. It's a vertical tool on someone else's platform. The pricing tells the same story: $20/month Pro tier for professionals whose firms pay $24,000/year for Bloomberg terminals. Either the product delivers dramatically less value than the price suggests it should in this market, or the founders haven't yet understood how enterprise financial software is actually sold and priced.

The timing is consensus, not contrarian. AI for financial services is the hottest vertical AI category of 2025-2026. Rogo raised $165M at a $750M valuation. Hebbia raised $161M at $700M with $13M ARR. AlphaSense has taken $1.39B. Microsoft itself reports financial services has the highest concentration of firms embedding AI across workflows. When the incumbent platform owner, three heavily-funded startups, and every major bank's innovation team are all converging on the same thesis, there is no asymmetric upside from being early. You're not being right first -- you're being right with less capital, less domain expertise, and less enterprise distribution than every other player at the table. The M365-embed angle is a differentiated go-to-market, but Rogo and Hebbia can build add-ins too; in fact, Hebbia acquired FlashDocs specifically for document-to-draft capabilities. Positioning is not a moat when competitors have 100x your resources.

The bull case deserves honest engagement. If the M365 embed strategy is structurally superior -- if bankers genuinely refuse to leave Excel and PowerPoint, and standalone platforms like Rogo and Hebbia hit an adoption ceiling because of context-switching friction -- then o11 occupies the right layer. Microsoft can't go deep on financial verticals without alienating healthcare, legal, and every other industry, creating a genuine structural gap. Ajay's experience scaling AI at Cal AI to 10M users is non-trivial technical specific knowledge, even if it's in the wrong domain -- building AI products that real humans actually use at scale is harder than most people think, and that knowledge transfers. And 150 reviews at 4.8 stars with logos from Wells Fargo and Bank of America, even as individual user affiliations rather than enterprise contracts, suggests the product works at a basic level. If the founders can hire deeply from banking -- if they can acquire the domain knowledge they lack through team-building -- the raw technical talent and product instincts might be enough. But "hire domain experts later" is an execution plan, not a thesis. And it's the plan that every vertical SaaS company has, which is exactly why most of them plateau.

The technology doesn't compound in a distinctive way. The dossier itself flags this: "the AI layer uses capabilities available from multiple model providers" and "other startups could build similar M365 add-ins." The financial data connectors require API agreements but aren't exclusive -- anyone can negotiate access to PitchBook and Capital IQ. The "zero context limits" claim is interesting but unverified, and long-context retrieval over financial documents is a capability that Hebbia, Rogo, and a dozen other companies are building simultaneously. I look for technology that gets harder to replicate with each iteration. Here, I see engineering intensity -- which is real work -- but not compounding defensibility.

This is ultimately a pass because it fails the specific-knowledge-plus-leverage test at both ends. The founders have general AI product-building knowledge applied to a domain they haven't lived in, competing against well-capitalized specialists in a consensus category, building on a platform they don't control. Smart kids, real energy, working product. But the structure of the bet is wrong for my portfolio. I need the founder who knows something that can't be taught, creating leverage that didn't previously exist, at a time when the crowd thinks they're wrong. Here, the knowledge is learnable, the leverage is borrowed, and the crowd already agrees.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 9/30 |
| Leverage Architecture and Scalability of the Model | 12/25 |
| Contrarian Positioning and Non-Consensus Timing | 6/20 |
| Founder Integrity and Long-Term Orientation | 9/15 |
| Technical Compounding and Defensibility Over Time | 4/10 |
| **Total** | **40/100** |

**Total Score: 40/100** (Pass)
