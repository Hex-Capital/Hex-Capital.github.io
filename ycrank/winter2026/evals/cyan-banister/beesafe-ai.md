# BeeSafe AI -- Cyan Banister Evaluation

The first thing that caught my attention here is genuinely creative -- AI agents that pretend to be scam victims, sustaining conversations with fraudsters for an average of nearly eight days, extracting their mule accounts and crypto wallets and infrastructure in the process. There's a quality to that concept that makes you sit up. When I think about my pattern of backing companies that make invisible systems visible -- Flock Safety exposing neighborhood crime patterns, Carta revealing what was hidden in cap table spreadsheets, Affirm replacing opaque credit card fees with transparent interest -- BeeSafe fits that pattern in a striking way. Scam networks are among the most invisible criminal systems in the world, and this team is building something that maps them from the inside out. That's the part of this company I find myself drawn to.

But here's where I get stuck. When I sit with this team, I'm trying to hear their story -- not the business, their story. And what I see are three accomplished PhDs from UCSD and CMU who arrived at this problem through academic research, not through personal experience. Nobody's grandmother lost her savings to a pig butchering scam. Nobody was themselves a fraud victim who couldn't sleep at night. The connection between these founders and this problem runs through research labs and published papers, not through the kind of biographical thread I've learned to trust most. Daniel Spokoyny interned at Google, Microsoft, Salesforce. Ariana Mirian has a decade of security research credentials that are genuinely impressive. Nikolai Vogler has an NSF fellowship and an NSIN challenge win. These are smart, credentialed people. But when I ask myself the question I always ask -- "is this founder genuinely the right person to tackle this specific problem because they've lived something that made this problem theirs?" -- the answer is ambiguous. They chose this problem; it didn't choose them.

The defensibility question also nags at me. They published their foundational approach in an academic paper on arXiv. I understand why researchers do this -- it's how academic careers work. But defensibility and moat are among the first things I look for, and they've essentially open-sourced their playbook. Apate AI in Australia is already pursuing a nearly identical approach with a CommBank partnership and $2.5 million in seed funding. The underlying technique is now public knowledge. What's left as a moat is the accumulated dataset of scammer conversations and the specific adversarial AI tuning, which is real but not the kind of structural barrier I prefer. Scammers will also adapt -- once honeypot chatbots become known in scammer circles, the adversarial arms race accelerates, and that's expensive to win continuously with a three-person team selling into enterprise procurement cycles.

Now, the bull case deserves honest engagement because it's substantial. The timing here is remarkable -- LLMs only recently became capable of sustaining convincing, weeks-long conversations, trust-based scams are surging past $12 billion in annual US losses, and government attention is intensifying with Treasury sanctions and DOJ indictments. This is an infrastructure inflection point, and I've seen what happens when you catch those right -- Crusoe Energy went from stranded gas flares to a $3 billion AI infrastructure company because they saw a technological inflection before anyone else. If BeeSafe's approach works at scale, the data flywheel is powerful: every scammer engagement produces intelligence that makes the system better and more valuable to enterprise customers. Ariana Mirian's ten years under Stefan Savage and Geoffrey Voelker -- two of the most prominent internet security researchers in the country -- is real domain depth, not a hot-market pivot. And the NSF SBIR award validates that the government is comfortable with this approach, which could meaningfully shorten procurement cycles in a segment where sales cycles kill startups.

Where I ultimately land is that this is a competent team with a creative approach in a space that genuinely needs disruption, but it doesn't trigger enough of my core signals. The cybersecurity AI category isn't unpopular or hard to assess for most investors -- it's well-funded consensus territory. The founders are impressive researchers but don't carry the kind of biographical stake that makes me believe they'll persist through the inevitable crises of building a company in uncharted legal and ethical terrain. The impact on vulnerable populations is real and meaningful -- scam victims are disproportionately elderly, isolated, and economically fragile -- but the delivery mechanism is indirect, filtered through enterprise B2B contracts. I respect this team and I think they could build something valuable. But I'm not feeling that jolt of intuitive energy, and my own money stays in my pocket when that signal isn't there.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Founder Biographical Grit and Personal Stake | 10/30 |
| Anti-Consensus Conviction and Weird Factor | 14/25 |
| Economic Access and Real-World Impact | 12/20 |
| Navigating Complexity in Hard Spaces | 11/15 |
| Co-Founder Alignment and Team Resilience | 6/10 |
| **Total** | **53/100** |

**Total Score: 53/100** (Neutral)
