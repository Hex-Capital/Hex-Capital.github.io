# RunAnywhere -- Sam Lessin Evaluation

Here's the thing about RunAnywhere that immediately activates every alarm in my framework: this is a software company whose entire reason to exist is AI. Strip out AI and there is no business, no SDK, no control plane, nothing. That's the precise opposite of what I look for. My "cherry on top" test asks whether the business would be good if AI didn't exist. RunAnywhere wouldn't exist if AI didn't exist. It's not a painting company that uses AI to optimize dispatch. It's not a parking infrastructure company that layers on computer vision. It's a pure software tool for AI deployment -- a tool for a tool -- and that puts it squarely in the category where I believe incumbents with distribution will dominate.

The sane-person-insane-idea calibration here is inverted in the worst possible way. Sanchit Monga (ex-Intuit SWE 2) and Shubham Malhotra (ex-AWS, distributed systems) are competent engineers -- credible enough to build what they're building. But "unified cross-platform SDK for on-device AI" is one of the most consensus ideas in tech right now. Apple is shipping NPUs in every device. Google is pushing MediaPipe. Meta launched ExecuTorch to GA in October 2025 and runs on-device AI across Instagram, WhatsApp, and Quest. Qualcomm is marketing its Snapdragon NPU capabilities in every keynote. This isn't an idea that provokes skepticism -- it's an idea that provokes nodding. Every VC in the Valley thinks on-device AI is coming. When the idea is consensus, the returns have already been arbitraged away, and you're left competing on execution against the three most resource-rich companies on the planet who also control the platforms you're building on.

The competitive dynamics here are genuinely brutal and go beyond the normal "big tech might copy you" concern. ExecuTorch, MediaPipe, and MLX aren't hypothetical threats -- they're shipped, open-source, well-maintained products backed by engineering teams of hundreds. More critically, Apple controls CoreML and the iOS runtime, Google controls the Android runtime, and Meta controls the largest deployed base of on-device AI models in the world. RunAnywhere's cross-platform abstraction layer is its strongest structural argument -- nobody is incentivized to build the neutral, cross-platform primitive because each platform owner wants lock-in. That's a real insight. But it's the same structural argument that React Native made, and React Native worked because Facebook built it and gave it distribution. RunAnywhere has two engineers in Bengaluru. Meanwhile, Nexa AI already has $3.4M in revenue, a 31-person team, and up to $16.5M in funding -- a funded competitor with a two-year head start in the identical market.

The strongest bull case requires believing three things simultaneously: (1) that on-device AI deployment becomes so fragmented across platforms that enterprises desperately need a neutral abstraction layer, (2) that none of the platform incumbents builds or acquires this layer, and (3) that RunAnywhere's open-source community (9,000 GitHub stars is genuinely impressive for pre-seed) converts into paying enterprise control plane customers at meaningful rates. If all three hold, you could see RunAnywhere becoming the deployment standard for on-device AI the way Docker became the deployment standard for containers. The control plane layer -- OTA model delivery, policy-based routing between on-device and cloud inference, fleet analytics -- is a real enterprise need that the big-tech open-source projects don't address. That's a legitimate wedge. But Docker itself took years and massive funding to monetize, ultimately pivoted multiple times, and got squeezed by Kubernetes. The open-core monetization challenge is well-documented, and the control plane is exactly the kind of SaaS product I think AI will commoditize. Building SaaS on top of AI tooling on top of AI models is layers of exposure to the same platform risk.

The narrative magnitude is real but unownable. "The default way of running on-device AI at scale" is a massive story that can expand from mobile to IoT to automotive to robotics. But the narrative belongs to the market category, not to RunAnywhere specifically. Any competitor -- ExecuTorch, Nexa AI, or the next well-funded entrant -- can tell the same story. When the infinity narrative is available to everyone in the space, it provides no premium to any individual company. Compare this to Helium, where the "decentralized wireless infrastructure" narrative was structurally tied to the protocol and token economics -- the story couldn't be separated from the specific company. RunAnywhere's story can be told by anyone building in on-device AI tooling, which means the narrative creates category interest, not company-specific value.

I respect the 9,000 GitHub stars and 1,663 commits -- that's real developer engagement and the strongest signal in the dossier. But community traction without conversion economics is the Birchbox pattern: enough success to keep going but not enough structural defensibility to compound. The lesson I carry from that experience is that narrative momentum without an AI-resistant moat produces investments that are too successful to fail quickly but too fragile to generate real returns. RunAnywhere is a software business building on software for software -- three layers of exposure to the very commoditization thesis I've been publicly arguing for two years. I'd rather invest in a company that uses on-device AI to do something in the physical world than in the picks-and-shovels layer where Meta, Google, and Apple are already digging.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| "Sane Person, Insane Idea" Calibration | 7/30 |
| AI-Resistant Structural Moat | 5/25 |
| New Primitive or Protocol Position | 8/20 |
| Narrative Magnitude and Infinity Optionality | 7/15 |
| Real Revenue or Asset Cushion | 4/10 |
| **Total** | **31/100** |

**Total Score: 31/100** (Pass)
