# Valgo -- Naval Ravikant Evaluation

These founders didn't acquire specific knowledge -- they generated it. Moss and Katz co-authored the MIT Press textbook on algorithmic safety validation, created and teach Stanford's course on the subject, and were on the core team at MIT Lincoln Laboratory that built ACAS X, the collision avoidance system now certified as an international standard for commercial aviation. When I ask "what does this founder know that can't be taught?", the answer here is almost paradoxical: they literally wrote the curriculum, but the knowledge that matters isn't in the textbook. It's in the decade of work translating probabilistic search algorithms into a system that the FAA trusted to keep planes from colliding. That translation -- from Bayesian optimization on a whiteboard to a certified system flying on every commercial aircraft -- is knowledge that lives in the scar tissue of regulatory negotiations, edge-case discoveries, and engineering tradeoffs that no course can transmit. This is among the strongest founder-problem-fit signals I've encountered at pre-seed.

The leverage architecture is where my enthusiasm meets friction. The black-box approach -- algorithms that wrap around any existing simulator to efficiently discover rare failures -- is genuinely leveraged at the technical layer. One set of algorithms serving automotive, aviation, defense, robotics, and space is the kind of cross-domain infrastructure play I systematically favor. Stack Overflow created a knowledge graph for developers; Valgo could create a validation layer for autonomy. But the delivery mechanism is enterprise sales into some of the slowest-moving procurement environments on earth. Defense contractors and aviation OEMs don't buy software the way developers adopt Replit. Each customer requires integration work, certification conversations, and multi-year sales cycles. The algorithm scales; the go-to-market doesn't. Two people targeting seven industries is not focus -- it's a research lab's wish list.

The contrarian positioning is nuanced. Applied Intuition's $15B valuation proves the market for autonomy validation tools is consensus -- every institutional investor understands this category now. But Valgo's specific bet is non-consensus within that consensus: that a lightweight, simulator-agnostic validation layer beats an integrated full-stack simulation environment. This is structurally interesting because Applied Intuition can't easily offer a tool that works with competitors' simulators -- their business model depends on you using their stack. Ansys and Siemens face the same channel conflict. The non-obvious insight is that validation and simulation are separable problems, and the customer who already has a simulator doesn't want to replace it -- they want to make it smarter. If Valgo is right about this architectural separation, they occupy a layer that incumbents are structurally disincentivized to build.

The strongest objection: the research is published. The textbook is freely previewed. A well-funded competitor -- Applied Intuition with its $1.2 billion in capital -- could recruit from the same Stanford lab and build comparable algorithmic validation as a product feature. The algorithms themselves are not proprietary. What's proprietary is the judgment about which algorithms matter for which domain, how to make them work at production scale in certified environments, and the relationships with regulators who need to trust the output. That's a real but fragile moat. It compounds with each new domain deployment and certification, but it could be overwhelmed by a competitor who combines deep pockets with a single well-placed hire from Kochenderfer's lab. The Public Benefit Corporation structure signals these founders are playing a long game, not optimizing for a quick acquisition -- which I respect, and which partially mitigates the competitive concern by suggesting they'll outwork the feature-team at Applied Intuition who treats validation as a checkbox.

The bull case that keeps me engaged: every autonomous system in every regulated industry will eventually need formal safety validation. Not simulation -- validation. The distinction matters. Simulation shows you what happens; validation proves you've searched hard enough for what could go wrong. As autonomy expands from cars into aircraft, surgical robots, warehouse drones, and defense systems, the regulatory demand for rigorous validation creates a market that doesn't exist yet at scale but is structurally inevitable. These founders built the proof that algorithmic validation works (ACAS X), wrote the theory (the textbook), and are training the next generation of practitioners (the Stanford course). If the market materializes as I expect, they're the default infrastructure layer -- the picks and shovels for autonomy safety. That's the kind of compounding, patient bet I want to make.

I'd write a check. The specific knowledge is exceptional, the infrastructure positioning aligns with my deepest portfolio pattern, and the founders have already demonstrated the academic-to-deployment translation that most PhD teams never achieve. The leverage and go-to-market concerns are real but manageable -- they need to pick one beachhead domain (aviation is obvious given ACAS X) and dominate it before expanding. The score reflects conviction tempered by the structural challenges of enterprise sales in regulated markets and the open-research vulnerability.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 28/30 |
| Leverage Architecture and Scalability of the Model | 15/25 |
| Contrarian Positioning and Non-Consensus Timing | 12/20 |
| Founder Integrity and Long-Term Orientation | 12/15 |
| Technical Compounding and Defensibility Over Time | 7/10 |
| **Total** | **74/100** |

**Total Score: 74/100** (Invest)
