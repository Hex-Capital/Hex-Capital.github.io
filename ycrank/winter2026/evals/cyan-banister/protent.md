# Protent -- Cyan Banister Evaluation

The first thing I notice about Protent is that it's entering one of the most well-capitalized spaces in early-stage AI right now. Ambient.ai has $146 million. Spot AI has $93 million. Lumana just raised $64 million. When I see that much money already flowing into a category, my instinct is to walk the other direction. The most promising companies I've backed -- SpaceX, Crusoe Energy, Contraline -- all shared a quality that Protent doesn't: nobody else wanted to fund them. AI-powered surveillance is the opposite of unpopular right now. It's a consensus bet. The escalation-prediction angle is a real technical distinction from the object-detection approaches most competitors use, but it reads to me like a feature differentiation within a crowded market, not the kind of paradigm break that makes other investors uncomfortable. Ambient.ai already uses the word "proactive" in their marketing. With $146 million in the bank, how long before they add temporal behavioral modeling to their stack?

Here's what I can't get past: I don't know these founders' stories. And I don't mean their resumes -- Srihan Balaji's credentials are impressive. Thomas Jefferson High School, one of the best STEM magnets in the country. Electrical engineering, computer science, math. Lockheed Martin Research deploying reinforcement learning in classified settings. AWS. That's a strong technical trajectory. But when I sit across from a founder, I'm not asking about their credentials. I'm asking: how did you get here? What happened to you that made this the problem you'd pour your life into? Did you witness a security failure that haunted you? Did someone you love get hurt because a surveillance system failed? I have no signal on that from either founder. Abhisheik Sharma's background in NLP and threat detection complements Balaji's video intelligence work, but again -- it's a professional thread, not a biographical one. The founders who survive the inevitable crises that hit every company are the ones solving problems that are personal to them. Without that narrative, I'm left evaluating resumes, and resumes don't tell me whether someone will keep going when the classified training data can't transfer to commercial settings or when Ambient.ai starts competing on their exact feature.

The defense-to-commercial angle is the part that interests me most, and where I'd push hardest if I were meeting these founders. My comfort with Anduril came from Palmer Luckey's deep personal conviction about modernizing defense -- he wasn't just commercializing classified work, he was building from a worldview that the defense establishment was broken and he could fix it. With Protent, I see talented engineers taking what they learned at Lockheed Martin and translating it to the commercial market. That's a legitimate path, and the classified-origin training data could be a real moat -- if it can actually be transferred. The ITAR and export control risks are nontrivial. If those models were developed in classified settings, the founders may need to rebuild their training datasets entirely from commercial data, which erodes the very advantage that makes them different. I'd want to understand exactly what intellectual property they're bringing versus what they're rebuilding from scratch.

The bull case here is that Protent's founders have seen things in classified defense environments that no commercial AI surveillance team has access to -- real escalation scenarios, real threat patterns, real behavioral precursors to violence. If that experience translates into models that genuinely predict escalation before it happens, that's not just a feature improvement over object detection, it's a fundamentally different capability. And the market timing is real: edge AI hardware costs are dropping, video transformers are getting better, and buyer demand for proactive security is growing after high-profile venue attacks. If Balaji can navigate the defense-to-commercial translation and build a data flywheel in the commercial market, this could be the company that defines escalation intelligence as a category. But that "if" is doing a lot of work. It requires the classified data advantage to survive legal transfer barriers, the escalation-prediction approach to stay ahead of well-funded competitors who can hire temporal modeling researchers of their own, and two young engineers to out-execute sales teams at companies with 10-100x their capital. I've seen founders beat those odds -- but usually they were founders with the kind of biographical intensity that made the outcome feel almost inevitable.

One more thing I'd flag: surveillance AI that predicts who is about to escalate raises real questions about who gets watched, who gets flagged, and whose behavior gets labeled as a "precursor." My investments in Flock Safety and Carta share a pattern -- they make invisible power structures visible and create access. Protent adds intelligence to institutional surveillance systems. That's a different vector. It could make public spaces safer, which matters enormously. But it could also encode bias into predictions about human behavior in ways that disproportionately affect the communities I care most about. I'd want to hear the founders' thinking on this, and I'd want it to be deeply considered, not an afterthought.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Founder Biographical Grit and Personal Stake | 8/30 |
| Anti-Consensus Conviction and Weird Factor | 6/25 |
| Economic Access and Real-World Impact | 6/20 |
| Navigating Complexity in Hard Spaces | 10/15 |
| Co-Founder Alignment and Team Resilience | 4/10 |
| **Total** | **34/100** |

**Total Score: 34/100** (Pass)
