# Clam -- Naval Ravikant Evaluation

The first thing I notice is the market structure, and it tells the wrong story. Three well-funded AI security startups -- Protect AI, Lakera, CalypsoAI -- were acquired by major cybersecurity incumbents within months of each other in 2025. The immediate reading is "opportunity: the independents got absorbed, the field is clear." The deeper reading is the opposite. Palo Alto Networks, Check Point, and F5 now own AI security capabilities and will integrate them into platforms that every enterprise already buys. When incumbents acquire in a wave like this, they're not creating a vacuum -- they're announcing that the category is mature enough to absorb. Clam is entering a market where the biggest players just spent $700M+ acquiring the exact capability stack it's assembling from open-source components. That's not contrarian timing. That's arriving at the party after the hosts have locked the doors.

The specific knowledge question is where I get stuck. Anshul built AI evaluation infrastructure at HappyRobot, a YC-backed agent company that reached a $500M valuation. Vaibhav worked on agent orchestration and containerization at Augment Code, a near-unicorn AI coding tool. These are relevant résumés -- they've both been inside the machine and seen the security gaps up close. But I ask: is this knowledge that can't be taught? Any engineer who's spent twelve months building production AI agents has seen the same attack surfaces. The insight that "agents with broad system access create security holes" is visible to everyone deploying these systems. It's an observation, not a revelation. Compare this to what I look for -- the founder who has spent years developing an understanding so deep that they can articulate why every other approach is wrong in ways that surprise domain experts. I don't see that here. I see two smart Berkeley engineers who noticed a real problem from good vantage points. That's valuable but not rare.

The leverage architecture is my deepest concern. Clam deploys agents in dedicated secure virtual machines. Each customer gets provisioned infrastructure. Each VM requires compute resources proportional to usage. This is a managed infrastructure service -- it scales linearly with customers, not exponentially. The network-level interception is architecturally clean, but it doesn't create the kind of leverage I invest behind. When I backed Alchemy, one API layer served thousands of blockchain developers without provisioning per-customer infrastructure. When I backed Stack Overflow, every new question and answer made the platform more valuable for everyone. Clam's model is closer to a hosting company with a security overlay than a platform with compounding returns. The scanning components -- PII detection, prompt injection, malicious code identification -- are individually available as open-source tools. The memo itself states this directly. Wrapping them at the network layer is integration work, not invention.

The bull case deserves honest engagement. If agentic AI becomes the dominant computing paradigm -- agents browsing, coding, calling APIs on behalf of every knowledge worker -- then the security layer for that paradigm is as foundational as Cloudflare was for web traffic. The acqui-consolidation of 2025 removed the funded independents, and none of those acquired companies were specifically targeting the agentic deployment niche. Clam's founders have the right background timing: they've been inside agent companies during the exact period when the security gaps became existential. If they execute fast enough to establish the network-level standard before Palo Alto integrates Protect AI's capabilities into Prisma AIRS, they could own the category. The credential injection approach -- where the agent never touches raw secrets -- is a genuinely smart architectural decision that enterprises would pay real money for. I can see a version of this company that becomes essential infrastructure.

But the version I can see requires several things to go right simultaneously: OpenClaw or similar frameworks must remain the dominant agent paradigm (platform dependency is a fragility, not a feature), the scanning technology must compound through proprietary threat data faster than open-source alternatives improve, and the managed VM model must find a path to platform-scale economics. The name collision with ClamAV is a minor irritant, but it signals something about the speed of the founding process -- when you choose a name that collides with one of the most widely-deployed open-source security tools in history, it suggests you haven't spent enough time in the security world to know the landscape by instinct. I look for founders whose specific knowledge would make that mistake impossible.

This is a real problem with competent founders in a hot market. That combination produces respectable outcomes but not asymmetric ones. I invest for the 1,000x case, which requires either non-consensus timing, compounding technology, or founder knowledge so deep it constitutes a structural advantage. I don't find enough of any of those three here. The technology is assembled from available components, the market is consensus, and the founders' knowledge -- while directly relevant -- doesn't cross the threshold from "experienced" to "irreplaceable."

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 14/30 |
| Leverage Architecture and Scalability of the Model | 11/25 |
| Contrarian Positioning and Non-Consensus Timing | 8/20 |
| Founder Integrity and Long-Term Orientation | 8/15 |
| Technical Compounding and Defensibility Over Time | 4/10 |
| **Total** | **45/100** |

**Total Score: 45/100** (Neutral)
