# RamAIn -- Naval Ravikant Evaluation

The most striking feature of RamAIn isn't the product -- it's the competitive topology. Computer-use agents are the consensus bet of early 2026. Anthropic ships Computer Use as an API. OpenAI launches Operator. Simular raises $26.5M with DeepMind alumni and gets selected for Microsoft's Windows 365 for Agents program. Browser Use raises $17M with Paul Graham's backing and 50,000 GitHub stars. An open-source framework from HKU researchers matches proprietary model performance on standard benchmarks. Into this landscape walks a two-person team from IIT Delhi with $0 in pricing and no visible traction. When everyone agrees the category is real, the asymmetric upside has been priced away. I'm not looking for companies entering validated markets -- I'm looking for companies where smart people think they're wrong.

The specific knowledge question is where this falls apart for me. Vansh Ramani is clearly talented -- an ICLR 2025 publication, work integrated into Meta's FAISS library, CMU ML research. That's real technical ability. But his research domains are graph neural networks, causal representation learning, and nearest neighbor search. These are adjacent to computer-use agents, not foundational to them. Where is the deep, non-transferable understanding of why enterprise RPA deployments fail? Where is the years-long obsession with how procurement teams navigate legacy desktop applications? Shourya Vir Jain bootstrapped Genoshi to revenue and has McKinsey-adjacent business development skills -- useful, but generic. Neither founder appears to carry the kind of domain knowledge about enterprise automation workflows that would take a competitor years to replicate. They're applying strong general ML skills to whatever category is hottest. That's the opposite of what I look for. When I backed Evan Williams, his specific knowledge about public communication had compounded over a decade. Here, I see competence in search of a domain.

The leverage architecture is middling. Pre-training agents on specific interfaces -- building a library of "UI policies" -- does have a train-once-deploy-many dynamic. That's genuine software leverage at baseline. But RamAIn sits at the application layer, dependent on foundation models from Anthropic, OpenAI, or open-source alternatives for core reasoning. It's downstream of the infrastructure that actually compounds. My portfolio gravitates toward the picks-and-shovels layer -- Alchemy over any individual DeFi app, Replit over any individual software product. A company whose differentiation depends on pre-training on the same interfaces any funded competitor can access doesn't create a new category of leverage. It creates a feature that platform providers will eventually absorb.

The strongest bull case: if RamAIn's pre-training approach genuinely delivers 10x speed improvement over the screenshot-VLM loop, and if speed turns out to be the binding constraint for enterprise CUA adoption, then they could capture a wedge in a massive market before incumbents adapt. UiPath and Automation Anywhere are structurally conflicted -- AI-native agents cannibalize their professional services revenue. A fast-moving team that solves the reliability problem first could build a compounding interface library that becomes a real moat. Vansh's FAISS contribution proves he can build technology that production systems depend on. And the IIT Delhi pipeline has produced founders who punch well above their funding class. For this bull case to work, though, you'd need the pre-training approach to deliver a measurable and durable speed advantage that can't be replicated by Simular's $26.5M team or absorbed into Anthropic's next API update. I don't see evidence that this is the case -- the "10x faster" claim on the YC page is unsubstantiated by benchmarks or customer validation.

I don't doubt the founders' intelligence or energy. But this is a consensus category at peak attention, the founding team brings general ML talent rather than irreplaceable domain knowledge about the enterprise automation problem, and the competitive landscape includes companies with 10-50x more capital pursuing nearly identical approaches. The technology -- pre-trained UI policies -- could compound in theory, but there's no evidence yet that it creates a defensible position against either well-funded startups or platform providers commoditizing from above. I need founders who know something that can't be taught, building leverage that didn't previously exist, at a time when smart people disagree with them. RamAIn has smart builders in a crowded room where everyone agrees.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 10/30 |
| Leverage Architecture and Scalability of the Model | 11/25 |
| Contrarian Positioning and Non-Consensus Timing | 5/20 |
| Founder Integrity and Long-Term Orientation | 8/15 |
| Technical Compounding and Defensibility Over Time | 4/10 |
| **Total** | **38/100** |

**Total Score: 38/100** (Pass)
