# Cajal -- Elad Gil Evaluation

The competitive landscape here tells me everything I need to know about whether this market is non-obvious. Harmonic AI has raised $295M at a $1.45B valuation. Axiom Math has raised $164M at a $300M valuation. Google DeepMind published AlphaProof. DeepSeek released open-source Lean4 prover models. When I backed PagerDuty, nobody else thought operations alerting was interesting. When I backed Harvey, most investors considered legal AI a science project. The structural moment in AI-for-formal-verification is real -- LLM capabilities crossed a formal reasoning threshold in 2024-2025 -- but this is consensus, not non-obvious. The market has been identified, sized, and capitalized by multiple well-funded teams. A two-person pre-seed company entering a space where incumbents have 500x their capital isn't exploiting a market everyone else dismisses. It's arriving late to a market everyone else already found.

Cajal's claimed differentiation is "applied scientific domains" -- quantum computing, finance, aerospace -- rather than competition mathematics or code verification. That's a positioning statement, not a moat. Axiom Math already targets quantitative finance. Nothing structurally prevents Harmonic from pointing their $295M and gold-medal-level proving capability toward applied domains whenever the commercial opportunity materializes. The domain-specific formalization libraries that would create real switching costs haven't been built -- no public evidence of proprietary datasets, no benchmarks with adoption, no customer relationships. When I evaluate product-to-distribution trajectory, I look for whether the initial wedge creates a customer relationship that enables additional products. The datasets, evaluations, and RL environments listed on Cajal's site could theoretically serve as infrastructure that AI research teams depend on. But LeanDojo is free and backed by Caltech, NVIDIA, and MIT. DeepSeek's open-source models are free. The picks-and-shovels play works when the picks are proprietary. Here, the core infrastructure is open-source and actively being commoditized.

The strongest bull case would be: formal verification applied to specific regulated domains -- aerospace correctness proofs, defense system certification, quantum computing protocol verification -- creates exactly the kind of regulatory-complexity-as-moat I've backed before. Anduril works because ITAR compliance and security clearances take years to acquire. If Cajal built deep relationships with defense primes or national labs that require formally verified mathematical proofs, the compliance overhead and domain specialization could deter competitors focused on general-purpose reasoning. The quantum computing angle is particularly interesting: as quantum hardware matures over the next 3-5 years, the need for provably correct quantum algorithms becomes critical infrastructure. A company that owns the formalization libraries for quantum computing could become embedded in the same way Samsara became embedded in fleet operations. But this bull case requires the founders to have credibility in these domains, and here's where it breaks down.

Neither founder has publicly documented expertise in formal verification, theorem proving, or the Lean ecosystem. Luke Johnston's background is ML and neuroscience. Pedro Nobre's background is computer vision and a prior startup called Vertebra. Pedro's GitHub shows student-level projects -- air quality monitoring, paper plane optimization, vehicle detection. Building a multi-agent system that autonomously discovers novel mathematical proofs in Lean requires deep expertise in type theory, proof tactics, and Lean metaprogramming. This is a domain where you can't fake the technical depth. When I compare this to Harvey, the difference is stark: Harvey's team didn't need to build the underlying AI capability -- GPT-4 was being delivered by OpenAI. Harvey focused on workflow and distribution. Cajal needs to build the core proving technology itself, competing against teams with hundreds of millions and researchers who have already achieved IMO-level performance. That's not one miracle -- it's at minimum two: build competitive formal verification AI AND land enterprise customers in pre-commercial markets like quantum computing. My single-miracle framework specifically rejects plans with compounding low-probability obstacles.

I recognize there's a version of this story where applied formal verification becomes "boring but critical" enterprise infrastructure -- the Gusto of mathematical proofs. Every quantum computing company, every financial firm deploying algorithmic strategies, every aerospace contractor needs provable correctness guarantees. If that's a $50B market in five years, being early with the right domain expertise matters more than being well-capitalized. But the "if" is doing a lot of work in that sentence. Quantum computing remains pre-commercial for most applications. The sales cycle to defense organizations is measured in years. And the founders haven't demonstrated why they specifically will build the technical infrastructure that captures this market against dramatically better-resourced competitors. I pass.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Non-Obvious Market at Structural Inflection | 9/35 |
| Product-to-Distribution Trajectory | 9/25 |
| Single-Miracle Operational Clarity | 5/15 |
| Founder Execution Velocity | 4/15 |
| Technology Cycle Positioning | 5/10 |
| **Total** | **32/100** |

**Total Score: 32/100** (Pass)
