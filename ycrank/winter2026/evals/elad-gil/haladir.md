# Haladir -- Elad Gil Evaluation

The first thing I notice about Haladir is the product focus split -- and it's not a good sign. Their GitHub org description says "AI-Enabled Mainframe Modernization and Code Translation." Their YC description says RL training infrastructure for verifiable domains. Their Rosetta product is a COBOL-to-modern-language tool in request-access mode. Their OR-bench repository is a benchmark suite across 10 operations research problem types. These are two fundamentally different products for fundamentally different buyers with fundamentally different sales motions. Enterprise COBOL modernization means selling to Fortune 500 IT departments running mainframes. RL training data means selling to frontier AI labs. When I apply the single-miracle test, I can't identify which miracle this team is organized around, because they appear to be pursuing two businesses simultaneously. That's not a platform strategy -- Stripe didn't start by building both a payment API and a separate accounting product. That's a team that hasn't yet decided what company they're building.

The RL training environment market has a real structural moment behind it. DeepSeek-R1 and OpenAI's o1/o3 demonstrated that RL with verifiable rewards transforms model reasoning capability. Anthropic reportedly plans to spend over $1 billion on RL environments in the next year. That's a genuine inflection point -- the RLVR paradigm shift created demand for diverse verifiable training domains that didn't exist 18 months ago. But here's the problem: this is not a non-obvious market. It's one of the most consensus-hot categories in AI infrastructure right now. Applied Compute raised $100M+ and reached a $1.3B valuation with ex-OpenAI founders. Mechanize is working directly with Anthropic. Scale AI has a dedicated RL environments team. When I look at my best investments -- PagerDuty, Gusto, Coinbase at the earliest stages -- other investors thought I was crazy. Nobody thinks RL training environments are crazy right now. Everybody is looking at this market.

Haladir's differentiation is domain-specific: operations research and formal verification rather than coding. That's a genuine gap. Most RL environment startups cluster around code because that's what AI lab researchers understand best. OR problems -- vehicle routing, scheduling, portfolio optimization -- produce verifiable ground truth through classical solvers, which makes them structurally suitable for RLVR. The OR-bench repository covering 10 problem types shows real technical work. But the underlying tools (OR-Tools, TLA+ provers) are open-source, and the barrier to replication is interdisciplinary expertise, not proprietary technology. Applied Compute, with $100M+ in the bank, could hire a team of operations research PhDs and build equivalent coverage in months. Domain specialization is a head start, not a moat.

The strongest bull case goes like this: AI labs actively want vendor diversity to avoid concentration risk, the OR/formal-verification domain is genuinely orthogonal to coding-centric competitors, and being the specialized provider in an underserved niche within a massively funded market could create a real business. If Anthropic and OpenAI each allocate even a small fraction of their RL environment budgets to non-code verifiable domains, that's tens of millions in potential revenue for a focused provider. The COBOL modernization angle, rather than being a distraction, could generate formally verifiable code translation tasks that feed the RL training pipeline -- linking an enterprise product to the infrastructure offering. And the YC plus Susa Ventures backing suggests sophisticated investors see something worth funding. For this to work, the team would need to pick one lane, build credibility with a single AI lab partnership, and compound from there. It's not impossible.

But the team composition makes this bull case difficult to believe. All four founders are current undergraduates -- Jibran Hutchins is a freshman at CMU, the others are students at Princeton, UVA, and UVA Wise. No prior startup exits, no industry experience, no published research that I can find. They're trying to sell RL training infrastructure to the most technically sophisticated buyers on the planet -- organizations that employ the researchers who invented these techniques. Wing VC's analysis that "research credibility compounds" is directly applicable here. The Harvey comparison is instructive in reverse: Harvey's team had deep legal domain expertise and understood their buyer intimately. These founders need to convince AI lab leads at Anthropic and OpenAI that their OR benchmarks are worth integrating into multi-billion-dollar training pipelines. That's a credibility gap that YC alone doesn't close. The market they're entering doesn't just require building good data -- it requires building trust with a very small number of extremely discerning buyers.

I'm passing. The structural moment is real but consensus, which means the asymmetric returns I look for aren't available -- every other investor sees this market too. The product focus split between COBOL modernization and RL training data suggests the team hasn't identified their one miracle. The competitive landscape includes players with 200x their capital and direct lab relationships. And while I've backed young founders before, this particular market rewards research credibility and lab relationships in a way that undergraduate profiles struggle to deliver. The domain specialization in operations research is the most interesting angle here, but it's a feature, not a company -- and it's a feature that well-funded competitors can add.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Non-Obvious Market at Structural Inflection | 13/35 |
| Product-to-Distribution Trajectory | 7/25 |
| Single-Miracle Operational Clarity | 5/15 |
| Founder Execution Velocity | 6/15 |
| Technology Cycle Positioning | 7/10 |
| **Total** | **38/100** |

**Total Score: 38/100** (Pass)
