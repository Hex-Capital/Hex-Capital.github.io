# Overshoot -- Naval Ravikant Evaluation

The founder-problem mapping here is unusually precise. Zakaria spent seven years at Uber building surge pricing -- one of the hardest real-time, low-latency optimization problems in consumer software -- then moved to Meta AI writing GPU kernels and inference engines. That's not a resume. That's a decade of accumulating exactly the knowledge you need to build a real-time video inference platform, acquired in two of the only places on earth where that knowledge gets forged under production pressure. Younes built a computer vision training and serving platform from scratch at COSMONiO -- a company Intel acquired specifically for that capability. He lived through the transition from classical CV to vision language models from inside the infrastructure. When I evaluate specific knowledge, I'm looking for understanding that can't be replicated by a smart person with six months and a textbook. These two have it. The question is whether their knowledge translates into a durable business.

The architecture sits at the right layer. I've consistently backed infrastructure over applications -- Alchemy over individual DeFi apps, Replit over individual software products, CoinList over individual token projects. Overshoot is the infrastructure layer for VLM-based video applications: a cloud API that lets developers connect live video feeds to vision models without building the inference stack themselves. That's genuine leverage -- one developer with three lines of SDK integration can build real-time video intelligence that previously required a team of ML engineers managing their own GPU fleet, codec pipeline, and streaming infrastructure. The picks-and-shovels positioning is correct. But here's where I get uncomfortable: the shovel is thin. The SDK integration is deliberately minimal. The underlying models -- Qwen3-VL, InternVL -- are open-source, developed by organizations Overshoot doesn't control. The value capture concentrates in the optimization layer between the model and the video stream: codec tuning, streaming protocol engineering, inference engine specialization. That's real engineering, but it's systems optimization, not fundamental technology. Compare this to Alchemy, which built a blockchain developer platform that accumulated a compound knowledge layer -- debugging tools, enhanced APIs, monitoring, analytics -- that deepened with every developer and every transaction. Overshoot's optimization advantage could be closed by a well-funded competitor deciding video matters.

The contrarian case is real but not deep. Most inference platforms treat video as a secondary modality -- text first, images second, video distant third. Overshoot's thesis is that video requires fundamentally different infrastructure: different codecs, different streaming protocols, different latency profiles, different batching strategies. If that's true, then general-purpose platforms are structurally disadvantaged. That's a specific, defensible claim, not a hot take. But it's also not the kind of idea that smart people actively dismiss. Nobody says "video AI doesn't matter." They say "we'll get to it." The timing angle -- open-source VLMs just crossed the real-time performance threshold in 2024-2025 -- is more compelling. We're in that brief window where the technology works but the infrastructure hasn't been built yet. Those windows produce infrastructure companies. The question is how long the window stays open before Fireworks ($331M raised) or Together ($534M raised) walk through it.

The strongest bull case: this is the Alchemy of computer vision. Alchemy won blockchain infrastructure by obsessing over one modality while AWS and Google treated it as a checkbox feature. If "video agents" -- autonomous systems interpreting live feeds for security, robotics, gaming, consumer products -- become a major application category, the specialized infrastructure layer will capture disproportionate value. The founders have the exact knowledge to build it. The timing on VLM maturity is right. And the general-purpose platforms have billion-dollar incentives to stay broad rather than go deep on any single modality. In that world, Overshoot's sub-200ms latency advantage compounds as they accumulate optimizations across thousands of video deployment patterns. The cousins-as-cofounders relationship suggests genuine long-term alignment -- they're not two strangers who met at a networking event; they've known each other their entire lives. If video agents are even half as big as the current trajectory suggests, this is a legitimate infrastructure play by founders who were born to build it.

But the bear case is equally clear. The optimization layer between open-source models and developer SDKs is the most vulnerable position in the stack. Above you, application developers can switch APIs with minimal friction. Below you, model developers at Alibaba and Shanghai AI Lab control the pace of improvement and can change licensing terms. Beside you, Fireworks and Together have engineering teams that dwarf yours by orders of magnitude and could add video-specific features as a sprint, not a strategy. Three hundred developers is a traction signal, not a moat. No revenue signal at all. The technology compounding story requires Overshoot to accumulate proprietary optimizations faster than well-funded generalists can replicate them -- a race where the two-person team is running against organizations with hundreds of engineers and hundreds of millions in capital. I've made bets like this before and won -- but usually when the underlying technology was more novel or the network effects were more structural.

The founders earn a check. The business model has to prove it deserves one. I'd take a meeting, probe the depth of their technical moat, and look for evidence that their optimizations compound rather than plateau. Right now this is a genuinely skilled team in the right position at the right time, with a moat question that hasn't been answered yet.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 22/30 |
| Leverage Architecture and Scalability of the Model | 16/25 |
| Contrarian Positioning and Non-Consensus Timing | 10/20 |
| Founder Integrity and Long-Term Orientation | 9/15 |
| Technical Compounding and Defensibility Over Time | 5/10 |
| **Total** | **62/100** |

**Total Score: 62/100** (Neutral)
