# Polymath -- Sam Lessin Evaluation

Here's the thing about RL environments as a category: Anthropic is telling everyone they'll spend a billion dollars on this stuff. OpenAI is buying hundreds of website replicas at $20K a pop. SemiAnalysis counts 35-plus vendors. When I hear that, I don't hear opportunity -- I hear the sound of every VC in San Francisco piling into the same trade. This is possibly the single most consensus category in AI infrastructure right now, and consensus is where my returns go to die. The question I ask first -- is this a sane person with an insane idea? -- falls apart immediately because there's nothing insane about the idea. Building automated RL environment factories for frontier labs is what every AI-adjacent engineer with Berkeley or Stanford credentials is trying to do right now. The demand is real, obvious, and already priced into a brutally crowded market.

The founders are competent -- UC Berkeley EECS, experience at AWS, Amazon, Plaid, Hume AI -- but competent in a generic way that doesn't create specific credibility for *this* problem. Compare them to Applied Compute's ex-OpenAI research team, or Mechanize's constellation of Nat Friedman, Daniel Gross, Patrick Collison, and Jeff Dean. When the buyer pool is literally five or six of the most technically sophisticated organizations on Earth, you need founders who've built critical infrastructure *inside* those organizations. Dylan Ma's time at Hume AI and Naren Yenuganti's Amazon Planning & Optimization work are fine backgrounds, but they don't make me think "these are the two people uniquely positioned to win this market." There's no prior exit, no deep RL research pedigree, no evidence of the kind of relationships that get you in the door at Anthropic's procurement team ahead of better-funded competitors.

My framework actively screams against this investment on the structural moat question. I keep asking: would this business exist if AI didn't exist? The answer is definitively no. This isn't "cherry on top" -- this is "the entire dessert menu is AI." My thesis is that AI is a bad startup investment because incumbents with distribution capture the value. Who has more distribution with frontier labs than Scale AI, sitting at a $29B valuation with existing relationships across every major lab? Scale is actively expanding its SEAL lab into RL environments. And here's the structural trap that makes this worse than typical AI-dependent plays: the frontier labs themselves are *deliberately* cultivating a fragmented vendor ecosystem to drive prices down. Your customers are explicitly engineering the commoditization of your product. That's not a market -- that's a procurement strategy where you're the commodity being optimized against.

The one angle that genuinely interests me is Horizon-SWE as a potential standard. If this benchmark becomes the evaluation framework that labs report against -- Claude Opus, GPT-5.2, Gemini 3 are already listed -- there's a shadow of a protocol-layer dynamic here. Benchmarks that become standards create mindshare and credibility loops. But I've seen this movie before: SWE-Bench became a widely-used standard and generated zero economic value for its creators. Benchmarks in AI are disposable -- new ones appear quarterly, each claiming to capture "real-world complexity" better than the last. For Horizon-SWE to become genuine infrastructure, Polymath would need frontier labs to standardize their internal evaluation pipelines around it, which requires a level of lock-in that five-person seed companies almost never achieve against customers who have hundred-person evaluation teams of their own. The standard-setting play is theoretically beautiful but practically implausible without extraordinary execution and relationship depth I don't see evidence of here.

The strongest bull case I can construct: the "automated factory" approach represents a genuine technical wedge. If Polymath can generate production-grade environments 10x faster and cheaper than manual construction -- and the compounding improves with each environment produced -- they could become the infrastructure layer that even Scale AI builds on rather than competes with. The market is about to expand 3-5x into 2026. First-mover advantage in automation could create a window where Polymath captures enough revenue and customer lock-in to survive the eventual consolidation. And if the agentic AI market really hits $93B by 2032, the RL environment slice could be enormous. For this to work, though, you need the automation advantage to be durable, the customer relationships to deepen before Scale AI pivots fully, and the benchmark to gain genuine traction as a standard. That's three simultaneous things that all need to go right, against competitors with 10-100x more capital and stronger founder credentials. I'd need to see evidence of at least one signed contract with a frontier lab, or a technical demonstration that the automated factory approach produces meaningfully different outcomes than manual construction, to start believing the bull case. Neither exists in the public record.

This is a pass. The company sits at the intersection of everything I avoid: AI-first value proposition, software-only moat vulnerable to commoditization, consensus market attracting massive competition, application-layer service rather than protocol-layer primitive, and a customer base small enough to count on one hand. The founders are building in the right market at the right time, but so are 35 other teams, several with dramatically stronger credentials and capital. My money goes where non-consensus meets structural moats, and I see neither here.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| "Sane Person, Insane Idea" Calibration | 8/30 |
| AI-Resistant Structural Moat | 4/25 |
| New Primitive or Protocol Position | 6/20 |
| Narrative Magnitude and Infinity Optionality | 7/15 |
| Real Revenue or Asset Cushion | 3/10 |
| **Total** | **28/100** |

**Total Score: 28/100** (Pass)
