# Crow -- Cyan Banister Evaluation

Here's what I notice first: this is an AI copilot company launched in late 2025, tagged with "Artificial Intelligence, Generative AI, Chatbot, Enterprise, AI Assistant" — every single hot keyword in tech right now. When I look at a deal and every VC in town would nod along and say "yeah, AI agents are huge," that's my signal to step back. The most promising companies are not popular. They are difficult to assess. Crow is neither. A well-funded direct competitor, Command AI, has already raised $23.8M doing essentially the same thing. Intercom bolted Fin onto their platform. Open-source agent frameworks multiply daily. When the insight is "100+ conversations with app builders told us they want an AI copilot," that's market research confirming what everyone already knows. It's the opposite of the independent, ridiculous-sounding insight that drew me to something like Crusoe, where a few people independently concluded that burning waste gas for computation made sense and nobody else agreed.

When I sit down with founders, I don't want to hear the business first. I want to hear their story — how they got here, what broke them, what they rebuilt from. Aryan served as a military officer in the Singapore Armed Forces, which I respect — that's discipline and structure. Jai earned a Regents' and Chancellor's Scholarship at Berkeley, which is genuinely impressive academically. Both have worked at relevant AI companies: Jai at OpenAI and Typeface, Aryan at a YC S23 startup. They're clearly capable engineers. But I'm not hearing the biographical thread that connects these specific humans to this specific problem in a way nobody else could replicate. They didn't struggle with a product's terrible UI and lose something meaningful because of it. They aren't solving a problem that kept them up at night for years before they had the tools to address it. The founder-problem bond I look for — the one where the biography and the mission become inseparable — just isn't surfacing here.

I also evaluate every company through the lens of whether it creates genuine economic access or makes an invisible system visible to people who need it. Uber wasn't a logistics optimization play to me — it was a way for drivers to earn a living on their own terms. Affirm made interest rates transparent where credit cards hid them. Flock Safety brought safety data to communities that had been invisible to law enforcement. Crow makes SaaS products easier to navigate via chat. That's a usability improvement for existing software users — people who already have access to these products. It's fine, it's useful, but it doesn't open doors for anyone who was previously locked out. There's no poverty alleviation angle, no transparency where opacity existed, no economic access being created where it didn't exist before.

The bull case deserves genuine consideration. If Crow executes exceptionally well and becomes the default embedded AI layer for SaaS products — the way Stripe became the default payments layer — the switching costs and data flywheel could create real defensibility over time. The developer-led GTM motion with npm packages, one-click Cursor install, and MCP server support is smart and low-friction. At 1,091 weekly npm downloads, there's early signal of developer interest. And the "why now" is real — LLM capabilities crossed a threshold, inference costs dropped, and MCP standards created interoperability that didn't exist two years ago. If you believe that every SaaS product will need an AI copilot and that most companies won't build it themselves, the infrastructure play is legitimate. The founders have the right technical backgrounds to execute it. But "right people, right time, obvious opportunity" is consensus investing, and consensus investing is not what I do. The absence of any defensibility signal in public sources, combined with a well-funded competitor already in market, means Crow needs to win on execution alone in a category where the underlying technology is commoditized. That's a race I don't feel drawn to fund.

On co-founder dynamics, they met on the first day of college bonding over football — a genuine friendship, and I appreciate that. But I've learned the hard way that friendship under good conditions tells you nothing about partnership under existential pressure. After HQ Trivia, I probe explicitly for how co-founders argue, who makes the final call, what happens when they fundamentally disagree on direction. Two Berkeley CS grads with similar backgrounds and similar career arcs may have too much overlap and not enough productive tension. I'd want to understand their conflict resolution before writing a check, though this isn't the primary reason for my hesitation.

This is a pass for me. Not because the founders aren't talented — they clearly are — but because everything about this company pattern-matches to the kind of bet I deliberately avoid. It's popular. It's easy to assess. It has execution risk but not the kind of technology risk or category risk that creates the asymmetric returns I hunt for. I'm looking for the misfits building something that makes people uncomfortable, not something that makes every investor nod.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Founder Biographical Grit and Personal Stake | 9/30 |
| Anti-Consensus Conviction and Weird Factor | 4/25 |
| Economic Access and Real-World Impact | 5/20 |
| Navigating Complexity in Hard Spaces | 3/15 |
| Co-Founder Alignment and Team Resilience | 5/10 |
| **Total** | **26/100** |

**Total Score: 26/100** (Pass)
