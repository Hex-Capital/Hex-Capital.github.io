# Hex Security -- Paul Graham Evaluation

The first thing I notice about Hex Security is that the problem they're attacking is the opposite of invisible. Five well-funded competitors have collectively raised over $635 million to build autonomous pentesting. Pentera has crossed $100 million in ARR. XBOW's AI reached #1 on HackerOne's global leaderboard. Horizon3.ai has completed 100,000+ pentests with deep federal contracts. Novee was founded by Unit 8200 veterans and closed the fastest Series A in offensive security history. This is not a problem hiding in plain sight because of schlep blindness. This is a problem that every smart team in cybersecurity has already identified, attacked, and raised massive rounds to solve. When I look at a market where $635 million is already deployed against the exact same idea, I don't see opportunity -- I see a consensus bet where the upside has been priced in by everyone else.

The question I always ask first is: how did the founders find this problem? And here the dossier is silent. None of the three founders have documented experience in offensive security, penetration testing, or cybersecurity operations. Huzaifa worked at Amazon and Capital One in unspecified roles, then at Lilac Labs doing voice AI for drive-thrus. Ahmad Khan did robotics and world models research at IIT Delhi. Prama worked at Codegen and studied CS at Georgia Tech. These are capable technical people, but nothing in their backgrounds suggests they stumbled into the pentesting problem through lived experience. Nobody was a frustrated pentester. Nobody ran a security team that couldn't get adequate coverage. The idea reads like it emerged from noticing that "AI + cybersecurity" is a hot intersection -- the kind of idea that gets generated when smart people sit down to brainstorm what markets are large and what technology is trending. That's exactly the failure mode I've written about: brilliant people working on something that exists because they decided to start a startup, not because they couldn't stop thinking about this specific problem.

The co-founder situation compounds my concern. The three founders attended three different universities -- Berkeley, IIT Delhi, Georgia Tech -- and share no documented prior employer. When I see three people who apparently came together specifically to start a company, without the deep relationship that comes from years of working or living together, I get nervous. I've seen this pattern fail repeatedly. In one YC batch, nine companies added co-founders they didn't know well, and all nine fell apart within a year. The co-founder relationship needs to predate the startup idea, not be manufactured alongside it.

The strongest bull case would be this: the autonomous pentesting market is genuinely enormous and accelerating, reinforcement learning could provide a technically differentiated approach that current incumbents haven't fully exploited, and the YC network offers a wedge into thousands of startups that need affordable continuous security testing. The product apparently works -- they claim to have found critical vulnerabilities including SQL injection exposing billions of records across dozens of YC companies. If their RL-based agents are genuinely better at discovering exploit chains than the competition's approaches, the technical moat could compound as they accumulate proprietary vulnerability data across engagements. A startup that delivers continuous pentesting at a fraction of Pentera's $100K average deal size could capture the long tail of companies that can't afford traditional pentesting at all. That's a real market. But for this bull case to hold, you'd need to believe that three founders without offensive security backgrounds can out-execute teams led by Unit 8200 veterans, ex-GitHub security engineers, and former Google CISOs -- all of whom have years of head start and hundreds of millions in capital. That's asking for multiple miracles simultaneously.

The self-reported traction claims don't move me. "Found critical vulnerabilities in dozens of YC companies" could mean they ran their tool against YC companies who gave them access as a favor during the batch -- that's not the same as companies pulling the product toward them because they need it. "Prevented $3B+ in potential damages" is a hypothetical impact estimate, not a measure of demand. I want to see companies paying for this. I want to see organic inbound. I want to see someone who would be genuinely harmed if this product disappeared tomorrow. None of that evidence exists in the public record.

The team is technical enough to build a working product, which counts for something. They're three engineers who apparently wrote code that finds real vulnerabilities. That's more than a PowerPoint. But in a space where XBOW was founded by the creator of CodeQL and Semmle -- tools that fundamentally shaped how the industry does code analysis -- "can write code" is table stakes, not a differentiator. The domain expertise gap matters enormously in security, where credibility with buyers and depth of understanding of attacker techniques are built over years, not months.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Organic Problem Discovery and Schlep Willingness | 5/30 |
| Relentlessly Resourceful Founders | 6/25 |
| Evidence of Wanting: Demonstrated User Pull | 6/20 |
| Technical Hacker Founders Who Build | 8/15 |
| Growth Trajectory and Default Alive Economics | 5/10 |
| **Total** | **30/100** |

**Total Score: 30/100** (Pass)
