# ARC Prize Foundation -- Vinod Khosla Evaluation

Here is a team that has already won. Chollet created Keras -- 63.8 thousand GitHub stars, millions of users, one of the foundational tools of modern deep learning. Knoop co-founded Zapier, scaled it to $5 billion. Four frontier labs -- OpenAI, Anthropic, DeepMind, xAI -- voluntarily report ARC-AGI scores in their model cards. Nearly 3,000 teams have competed across two years. By every conventional measure, this organization has achieved extraordinary traction for its stage. And that is precisely what troubles me. They have reduced the probability of failure so effectively that I need to ask the question I always ask: if this succeeds completely, what actually changes?

The answer is: we get a better yardstick. A more reliable measurement of how close AI systems are to general intelligence. That matters -- I am not dismissing it. What gets measured shapes where billions of dollars in R&D flow. A bad benchmark misdirects an entire field; a good one accelerates genuine progress. But a yardstick is not the thing it measures. When I backed OpenAI in 2019, the consequence of success was artificial general intelligence itself -- not a test that tells you how close you are. When I backed Impossible Foods, success meant replacing animal agriculture -- not publishing a scorecard rating meat alternatives. ARC Prize occupies a structurally meta position: it measures the revolution rather than making it. The consequence of success is important infrastructure, not industry transformation. And as a 501(c)(3) nonprofit with no earned revenue model, the financial consequence of success for my check is definitionally zero. I structure investments as options that either expire or produce transformational returns -- a tax-deductible donation to a nonprofit is neither.

The team composition reveals a second tension with my framework. Chollet is not an outsider attacking an established field -- he is the field. He literally invented the ARC benchmark, authored the foundational paper on measuring intelligence, and built one of the most-used deep learning libraries in history. Knoop scaled a $5 billion company. These are deeply credentialed insiders executing exactly what credentialed insiders would be expected to execute. When Cisco's CTO told me TCP/IP routing would never work, that was the signal to back Juniper. When the food industry said plant-based meat was a joke, that was the signal to back Impossible Foods. Here, the consensus is with ARC Prize -- four frontier labs already adopted it. Nobody is dismissing this as impossible. That consensus validation, which most investors find comforting, is exactly the signal that tells me the innovation is incremental enough to be non-threatening to incumbents.

The strongest bull case deserves serious engagement. If AGI is the most consequential technology in human history -- and I believe it may be -- then whoever controls the definitive measurement standard wields extraordinary influence over the field's direction. Governments are beginning to mandate AI evaluation frameworks. The EU AI Act, the U.S. AI Safety Institute, regulators worldwide need trusted independent benchmarks. ARC Prize is positioned to become the NIST of artificial intelligence -- an institution whose standards shape an entire industry for decades. The timing is genuinely excellent: reasoning models like o3 and DeepSeek-R1 saturated existing benchmarks in months, creating acute demand for harder, reasoning-specific evaluations that ARC-AGI-2 and 3 are designed to fill. If I were making philanthropic grants rather than angel investments, this would be among my highest-conviction bets. But that is the point -- this is a philanthropic opportunity, not an investment opportunity. My framework asks whether the money either expires or builds a very successful company. A nonprofit that becomes the gold standard for AGI measurement is a tremendously valuable institution, but it is not a company. The absence of any mechanism to capture economic value from success makes this structurally incompatible with my option-value portfolio construction.

There is also a Red Queen problem embedded in the model. ARC-AGI-1 went from 33% to 87.5% SOTA within a single year as OpenAI's o3 attacked it with high-compute configurations. Each benchmark version has a finite lifespan before AI systems saturate it. The Foundation must perpetually design harder tests -- not to win, but to avoid losing relevance. This is a treadmill, not a flywheel. The technology risk is not "can we build a harder test?" -- of course they can -- but whether the benchmark design cycle can outpace the AI capability curve indefinitely. And the regulatory risk is real: Scale AI was already selected as the U.S. AI Safety Institute's third-party evaluator. If governments formalize alternative standards, community adoption alone will not sustain ARC Prize's position.

I respect this team enormously and I believe this work matters for civilization. Chollet's intellectual framework for measuring intelligence is genuinely important. But I invest my own money in companies that, if they succeed, make an existing trillion-dollar system obsolete. ARC Prize, at its absolute best, becomes essential infrastructure for the people who are building those transformational systems. That is a worthy mission. It is not my kind of bet.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Consequence Magnitude If Successful | 9/30 |
| Founder Learning Rate and Contrarian Courage | 14/25 |
| Technology Disruption Potential vs. Incumbent Systems | 6/20 |
| Rate of Change and Timing Trajectory | 11/15 |
| Gene Pool Engineering and Team Construction | 7/10 |
| **Total** | **47/100** |

**Total Score: 47/100** (Neutral)
