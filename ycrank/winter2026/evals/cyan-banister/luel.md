# Luel -- Cyan Banister Evaluation

The first thing that jumps out at me about Luel is that it sits squarely in the hottest category in technology right now. AI training data infrastructure. Scale AI at $29 billion. Mercor at $10 billion. Surge AI doing $1.4 billion in run-rate revenue bootstrapped. Protege just raised $65 million from a16z. When I look at an opportunity and every major venture firm in the Valley is already writing enormous checks into the same thesis, something in my chest tightens — and not in the good way. The most promising companies I've backed have always been the ones that were unpopular and difficult to assess. Luel is entering a space that is neither. It's extremely popular, well understood, and crowded with operators who have hundreds of millions in capital and years of enterprise relationships. Two Berkeley students with half a million dollars going up against that — I need to understand why them, why now, and what nobody else sees.

So I go to the founders' stories, which is always where I start. And this is where the dossier goes quiet on me. William is a "2x founding engineer" at unidentified companies, with some network security research. Inigo is an ML researcher from Berkeley's CS program. They both dropped out to build Luel, which does show a certain kind of conviction — walking away from Berkeley's M.E.T. program isn't nothing. But when I'm asking myself "tell me how you got here," I want to hear the biographical thread that makes this problem inescapable for this specific person. What I'm not finding is the moment of lived experience that connects either founder to the pain of sourcing rights-cleared training data, or to the experience of being a data contributor who deserves fair compensation, or to the legal nightmares of scraping copyrighted content. They may have that story — I just can't see it from what's available. And at this stage, when I'm investing in people and my conviction around whether that person can solve this particular problem, the biographical signal is the most important thing I have.

Now, here's where I have to be honest about what genuinely interests me. The contributor side of this marketplace — regular people uploading their photos, videos, and audio and getting paid $0.80, $4.50, $24.50 within a week — that maps directly to something I care deeply about. When I backed Uber, part of what I saw was income creation for drivers. Postmates created income for delivery workers. Thumbtack connected skilled tradespeople with customers. Luel could be building the gig economy for AI training data, giving everyday people a way to monetize the content they're already creating or can easily create. There's also something here about making an invisible system visible: right now, AI labs train on scraped data with murky provenance, and nobody tracks where it came from or whether the creators were compensated. Luel's rights-clearance documentation and consent tracking is essentially bringing transparency to a system that has operated in shadows. That pattern — Carta made equity transparent, Affirm made credit terms transparent, Flock Safety made public safety data visible — is one I keep returning to in my portfolio. So the raw ingredients for something I'd care about are present.

The timing argument also has real substance, and I want to engage with it fairly. Scale AI's independence was effectively destroyed when Meta took a 49% stake, causing Google and OpenAI to reportedly cut ties. That creates a genuine structural opening for a neutral vendor — the same kind of structural shift that created the window for Uber when the taxi medallion system was cracking. And the legal landscape is shifting fast: NYT v. OpenAI, Getty v. Stability AI, and a dozen other lawsuits are making rights-cleared data not just nice-to-have but essential for any responsible AI lab. A purpose-built marketplace for creating new, fully licensed multimodal data is a legitimately different product than what Scale or Surge offer, which is annotation and labeling of pre-existing data. If Luel could become the trusted neutral exchange for rights-cleared training data at exactly the moment the market needs one, that would be a significant company.

But I keep coming back to the arithmetic of conviction versus evidence. The structural opening is real, but Protege raised $65 million from a16z to build a governed data marketplace that is uncomfortably close to this positioning. Mercor has $450 million in run-rate revenue and 30,000 experts. The switching costs for enterprises buying datasets are low unless you build truly proprietary collection infrastructure. The unverified claim of backing from xAI, Meta, and Mercor on the website — with no independent confirmation — also gives me pause. I want to trust founders, but extraordinary investor claims require some form of corroboration. And the marketplace network effects that would be Luel's primary moat are entirely unproven, with no public data on contributor count, retention, or engagement. At pre-seed I don't need traction metrics, but I do need to feel that the founders have an unfair advantage in building both sides of this marketplace, and I can't identify what that advantage is beyond being in YC.

This isn't the kind of company where I feel the jolt. It's competent founders pursuing a real market opportunity with reasonable timing — but it's a consensus opportunity in a well-funded space, and I'm not finding the founder story that would give me conviction that these two people specifically will outrun competitors with a hundred times their capital. The economic access dimension is genuinely appealing, and if I could sit across from William and Inigo and hear them tell me about why data contributors deserve to be compensated fairly, with the kind of passion that makes me forget about the competitive landscape, I might feel differently. But on paper, this is a pass for me.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Founder Biographical Grit and Personal Stake | 8/30 |
| Anti-Consensus Conviction and Weird Factor | 6/25 |
| Economic Access and Real-World Impact | 12/20 |
| Navigating Complexity in Hard Spaces | 8/15 |
| Co-Founder Alignment and Team Resilience | 4/10 |
| **Total** | **38/100** |

**Total Score: 38/100** (Pass)
