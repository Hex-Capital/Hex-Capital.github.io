# Stilta -- Paul Graham Evaluation

The first thing I notice about Stilta is that this is a crowded room. Solve Intelligence has $55M and profitable 8-figure ARR. DeepIP reached 7-figure ARR in seven months. Patlytics grew 20x in six months. IPRally has Nvidia as a customer. When I see four well-funded startups already scaling rapidly in the same category, I know this is not a schlep-blindness opportunity. Nobody unconsciously avoided AI for patent work -- they're all doing it right now, with real revenue and real customers. The hallmark of a great schlep is that the problem sits in plain sight for years while everyone looks away. Patent AI tooling is the opposite: everyone is staring directly at it and sprinting.

The origin question is where I get stuck. How did four McKinsey consultants with backgrounds in sports betting, QuantumBlack AI projects, and Goldman Sachs end up building tools for patent attorneys? The dossier gives me no answer. There's no story of a founder who spent years doing FTO analysis and thought "this is insane, I need to automate this." No one on the team has documented experience in patent law, IP prosecution, or even working at a law firm. The idea reads like it emerged from a market-sizing exercise -- smart people with AI skills surveying industries where manual processes are expensive and picking one with a large TAM. That's the opposite of organic. When I ask "would these founders have built this product if they weren't trying to start a startup?" I suspect the answer is no.

The bull case deserves engagement because there are real strengths here. Oskar Block bootstrapped two companies to $1M+ ARR, which is not nothing -- you don't do that without some combination of persistence and resourcefulness. The team is genuinely cohesive, with shared roots at McKinsey/QuantumBlack that predate the company by years. That matters because co-founder relationships forged through prior working experience are far more durable than ones formed to start a company. And the patent work schlep is objectively real -- legal-grade auditability, malpractice exposure, jurisdictional complexity. If Stilta's "end-to-end workspace" approach turns out to be the right architecture while competitors are stuck as point solutions, there could be a wedge. The relocation from Stockholm to SF for YC shows seriousness. If I learned that one of the founders had spent two years inside a patent prosecution firm and built this out of genuine frustration with the workflow, my calculus would shift meaningfully.

But that's not what I see. What I see is a company entering one of the most actively contested AI verticals with $500K, a four-person team that has no visible domain expertise, and a positioning statement -- "Cursor for patent attorneys" -- that borrows cachet from developer tools and applies it by analogy. The analogy itself is a yellow flag. Cursor works because the founders were programmers building tools for programmers. Stilta's founders are consultants building tools for patent attorneys. That's a fundamentally different relationship to the problem. The "end-to-end" positioning also worries me at this team size -- building across FTO analysis, patent monitoring, and IP strategy simultaneously means competing with Solve Intelligence on drafting, Patlytics on analytics, and IPRally on search, all at once, with a fraction of the resources. Breadth is a luxury you earn after achieving depth somewhere.

The technical team is competent -- QuantumBlack and AWS backgrounds suggest they can build AI systems at scale -- but I see no evidence of the hacker-builder mentality I look for. No public GitHub repos, no demos, no technical blog posts. The skill set reads more as "enterprise AI deployment" than "stay up all night writing code because the problem fascinates you." Patent law requires extraordinarily deep domain knowledge to serve well, and without that knowledge on the founding team, every product decision has to be validated externally. That's a speed disadvantage against competitors who already have patent attorneys as co-founders or key team members.

I respect the team's credentials and the genuine difficulty of the problem they've chosen. But when I apply my tests in sequence -- organic origin, schlep willingness, user pull, technical craft -- the pattern that emerges is smart generalists who identified a market rather than builders who stumbled into a problem they couldn't ignore. In a less competitive market, the McKinsey execution machine might be enough. In a market where Solve Intelligence is already profitable with 8-figure ARR, you need something those competitors cannot replicate, and I don't see what that is.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Organic Problem Discovery and Schlep Willingness | 7/30 |
| Relentlessly Resourceful Founders | 12/25 |
| Evidence of Wanting: Demonstrated User Pull | 8/20 |
| Technical Hacker Founders Who Build | 7/15 |
| Growth Trajectory and Default Alive Economics | 4/10 |
| **Total** | **38/100** |

**Total Score: 38/100** (Pass)
