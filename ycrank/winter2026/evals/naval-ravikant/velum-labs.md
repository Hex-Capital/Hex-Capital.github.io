# Velum Labs -- Naval Ravikant Evaluation

The first thing I notice is a company describing itself three different ways: "ontology engine for enterprise AI" on the website, "open-source firewall for content-level access control" on the YC page, "dynamic data firewall for unstructured data" on the blog. This isn't iterative messaging. It's a team that hasn't yet figured out what they know. When a founder possesses genuine specific knowledge, the product description is precise because the insight is precise. Evan Williams didn't call Twitter "a notification engine" one week and "a messaging protocol" the next. The description emerged from years of understanding what public communication wanted to become. Velum's shifting frames suggest two technically capable people exploring a problem space, not two people who've discovered something non-obvious about how enterprise data exposure actually works.

The specific knowledge question is where this deal falls short for me. The CTO, Alen, has real ML engineering depth — principal engineer at a managed ML platform, deep learning research across multiple institutions, a pinned GitHub repo literally called "ontology." He can build the technical artifact. But building ontology engines is teachable knowledge. It lives in papers and courses. What's non-teachable is understanding how data actually leaks inside a Fortune 500 company — which Salesforce fields contain trade secrets that nobody labeled, which SAP export paths bypass existing DLP, how compliance officers actually think about risk versus workflow disruption. That knowledge comes from years inside the problem, not from adjacent ML research. The CEO's background in physics and quantum computing at Stanford provides quantitative rigor but zero direct signal about enterprise security or data governance. These are smart builders looking at a market, not domain inhabitants who've been living inside the pain.

The structural opportunity has real merit, and I want to be honest about that. This is an infrastructure play — a firewall that sits between data sources and consumers, operating at the platform layer rather than the application layer. That's exactly the kind of picks-and-shovels position I gravitate toward. Alchemy didn't build DeFi apps; it built the developer platform underneath them. Velum is attempting something analogous for AI data security — the content-level control layer that every AI workflow needs but nobody has standardized. The leverage mechanics are sound in theory: one policy engine serving thousands of enterprise data flows, with each customer's ontology mappings creating switching costs. If the open-source strategy works, you get developer adoption as your distribution channel, converting community users to paid enterprise tiers. That's the AngelList playbook applied to security.

But the timing isn't contrarian — it's consensus. AI security is the topic of every enterprise CISO's board presentation right now. Noma Security raised $132M and reports 1,300% ARR growth. Check Point acquired Lakera. Veeam absorbed Securiti for its AI firewall capabilities. This is a market where capital is flooding in, which means the pricing of every deal in the category already reflects optimism. The specific angle — content-level semantic redaction versus document-level access control — offers some differentiation, but "granular DLP for AI" is not a non-consensus bet. It's the next obvious feature that every security vendor is building toward. The real contrarian bet in AI security would be something most smart security people think is wrong or unnecessary. Content-level access control is something everyone agrees is needed; the debate is only about who builds it.

What would have to be true for this to be a great investment? Two things. First, the open-source strategy would need to create genuine developer adoption — hundreds of contributors, thousands of stars, organic pull from engineering teams who discover the tool and bring it into their organizations bottom-up. That would create the distribution leverage that a two-person team with $500K needs against competitors with 100x more capital. Stack Overflow succeeded not because it outspent competitors but because developers chose it as their default knowledge layer. Second, the ontology-based approach would need to prove qualitatively superior to pattern-matching PII detection — showing that semantic understanding of enterprise data context catches exposures that regex-based tools miss, and that each customer's policy library compounds the system's intelligence. If both are true, Velum becomes the content-level security standard for the AI era. But there's no evidence of either yet — no open-source traction visible, no customer validating the ontology approach — and the founders' backgrounds don't give me independent confidence they'll navigate enterprise security sales and compliance requirements that require domain knowledge they haven't demonstrated.

One more concern: the website claims 50+ enterprise integrations and SOC 2 Type II certification for a two-person pre-seed team. These claims couldn't be independently verified. In my framework, integrity is the tiebreaker among intelligence and energy — and overclaiming capabilities you haven't built is the kind of small behavioral tell that warrants attention. It may be aspirational marketing rather than deception, but it creates noise where I want signal.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 10/30 |
| Leverage Architecture and Scalability of the Model | 14/25 |
| Contrarian Positioning and Non-Consensus Timing | 8/20 |
| Founder Integrity and Long-Term Orientation | 7/15 |
| Technical Compounding and Defensibility Over Time | 5/10 |
| **Total** | **44/100** |

**Total Score: 44/100** (Pass)
