# Synthetic Sciences -- Sam Lessin Evaluation

Here's the thing about "AI co-scientists" -- it's the single most consensus idea in venture right now. Google announced one built on Gemini 2.0 in February 2025. Periodic Labs raised $300 million with Nvidia participation to build one with robotic labs. Edison Scientific raised $70 million from Eric Schmidt's FutureHouse to build one for biology. Elicit already has 400,000 monthly researchers and an estimated $18-22 million in ARR doing a subset of the same thing. Sciloop, funded by YC one batch earlier, automates ML experimentation end-to-end with the same pipeline. When I look at this landscape, I don't see a "sane person with an insane idea" -- I see credible young founders chasing the most heavily validated category in tech. That's the opposite of what I look for. The returns in consensus categories get arbitraged to zero by capital and incumbents with distribution advantages.

The founders genuinely impress me on the "sane" axis, and I want to be clear about that. Aayam Bansal at 18 has 15+ papers across ICML, IEEE, and ACL, with research stints at MIT CSAIL, CMU, Harvard, Oxford, and NUS. That's not a normal 18-year-old resume. Ishaan Gangwani competed at IOAI 2025 for India's team and hit USACO Platinum. Both are Z-Fellows and Emergent Ventures recipients -- Tyler Cowen's filtering function has good taste. These are genuinely sharp technical minds who've lived the research workflow pain firsthand. But "sane person, sane idea" produces a fundamentally different investment calculus than "sane person, insane idea." When Brian Armstrong proposed building a regulated crypto exchange in 2012, people thought he was nuts. Nobody thinks building AI research tools is nuts in 2026. Everybody thinks it's the future. That's the problem.

My core structural objection is that this company fails every version of my "cherry on top" test. Strip away AI and ask: what business exists here? The answer is nothing. No physical operations software amplifies, no protocol layer other businesses build on, no installed base of hardware or regulatory position. It's pure software orchestration of other people's LLMs, other people's GPU clouds, other people's paper search APIs. The 93 pre-built research skills and 12 integrations represent real product work, but they're integration engineering, not a moat. The claimed data flywheel -- "product usage generates process data for RL training of increasingly autonomous research agents" -- is exactly the kind of defensibility story every AI startup tells. Google has orders of magnitude more research data, more compute, and more distribution to researchers through Scholar, Colab, and the academic ecosystem. The brand confusion between Synthetic Sciences and InkVell (the legal entity is "Inkvell Inc." and earlier press describes InkVell as "an AI-powered platform addressing research and document productivity") suggests the product scope may have pivoted from a narrower LaTeX/document tool toward the hotter "co-scientist" narrative. Following the hot market is the opposite of the structural conviction I back.

Let me steel-man the bull case because these founders deserve it. If you believe that the computational research niche -- ML, bioinformatics, materials science simulation -- is specifically where AI-native tools can win because the domain itself is computational, then Synthetic Sciences' integrated compute orchestration (GPU provisioning through Modal, Lambda, Together AI) does something Google's Co-Scientist explicitly doesn't do yet. The $50/month entry point enables bottom-up PLG adoption by individual researchers before anyone needs to sell to an institution. And if the RL environment work produces genuinely better research agents trained on proprietary process data, that could compound into a real advantage. The scenario where this works is one where execution speed matters more than resources -- where two brilliant 18-year-olds shipping fast capture researcher workflows before Google's Trusted Tester Program becomes a product and before Edison and Periodic expand into computational domains. It's a plausible scenario. It's just not one I'd put my own money behind, because the structural logic works against it. Distribution advantages and resource advantages compound in AI, and startups in consensus AI categories are running against headwinds that get stronger, not weaker, over time.

The co-founder relationship also trips one of my pattern-match concerns. They connected through fellowship networks -- Z-Fellows and Emergent Ventures -- and started working together in June 2025 before registering the company later that year. That's a fellowship-network co-founder pairing, not a deep pre-existing relationship forged through years of shared work. At 18, neither has had time to build those long relationships, so I'm not penalizing them for their age -- but the signal of relational depth that predicts resilience under pressure isn't there yet. Combined with the fact that they're entering a market where their competitors have $70-300 million in funding and teams from Meta's crypto division, ex-OpenAI VPs, and DeepMind researchers, the path gets very narrow very fast.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| "Sane Person, Insane Idea" Calibration | 10/30 |
| AI-Resistant Structural Moat | 4/25 |
| New Primitive or Protocol Position | 5/20 |
| Narrative Magnitude and Infinity Optionality | 8/15 |
| Real Revenue or Asset Cushion | 3/10 |
| **Total** | **30/100** |

**Total Score: 30/100** (Pass)
