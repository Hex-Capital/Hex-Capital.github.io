# ARC Prize Foundation -- Peter Thiel Evaluation

The most striking fact about ARC Prize Foundation is not its benchmark, its team, or its adoption by frontier labs. It is that this is a 501(c)(3) nonprofit asking me to evaluate it as an angel investment. I invest my own money for power-law returns. The entire architecture of my framework -- monopoly, secrets, last-mover advantage, the power law -- presupposes an entity that captures the value it creates as equity. A nonprofit, by definition and by design, does not do this. Before I evaluate anything else, this structural reality must be acknowledged: there is no equity to purchase, no return to compound, no monopoly profit to capture. The question "could this return the entire fund?" has a definitive answer, and it is zero.

Set that aside for a moment and ask the question I always ask: what is the secret? The implicit thesis is that existing AI benchmarks fail to measure genuine intelligence, and that a properly designed evaluation -- one targeting "skill acquisition efficiency" rather than memorized knowledge -- can become the authoritative yardstick for AGI progress. Is this contrarian? I would argue it is not. The inadequacy of benchmarks like MMLU is practically a consensus view among serious AI researchers. Chollet's more specific claim -- that fluid intelligence and novel reasoning are what matter, not pattern retrieval -- is intellectually interesting, but it reads more as an academic position than a business secret. A secret, in my framework, is a truth that most intelligent people would actively argue against. Nobody argues that current benchmarks are sufficient. The "secret" here is consensus dressed in the language of rigor.

The team, however, deserves separate consideration. François Chollet created Keras -- 63.8K GitHub stars, over two million users, one of the foundational tools of modern deep learning. He left Google after a decade to pursue this full-time. Mike Knoop co-founded Zapier, which reached a $5 billion valuation and $310 million in revenue -- and he chose to work on AGI measurement instead of continuing to compound that success. Greg Kamradt created the "Needle in a Haystack" context retrieval test that became an informal industry standard. This is a team with the intellectual depth and demonstrated conviction I value. Chollet's 608K followers on X give the organization distribution reach that money cannot buy. If this were a for-profit company, the founder profile would be genuinely compelling -- a technical visionary who built a tool used by millions, walking away from Google to pursue a definite vision of how intelligence should be measured. That is the kind of conviction I funded in Zuckerberg and saw in Musk.

The bull case is worth articulating clearly, because it is not trivial. Four frontier labs -- OpenAI, Anthropic, Google DeepMind, and xAI -- now voluntarily report ARC-AGI scores in their public model cards. That is extraordinary adoption for an independent benchmark. As AI regulation accelerates globally, governments will need trusted, independent evaluation infrastructure. ARC Prize, with its academic panel, its nonprofit independence, and Chollet's unmatched credibility in the space, could become the NIST of artificial intelligence -- the standard-setting body that regulators, labs, and the public rely on. The analogy to Palantir is tempting: an organization that becomes indispensable to government institutions through intellectual authority rather than commercial sales. But the analogy collapses precisely where it matters: Palantir is a for-profit company with equity that compounds. Its government entrenchment creates monopoly profits. ARC Prize's government entrenchment, if it occurs, creates influence without equity. And the risk of regulatory capture is real -- Scale AI was already selected as the U.S. AI Safety Institute's third-party evaluator, and Scale has $15.9 billion in funding to entrench that position.

The deeper structural problem is that benchmarks are public goods, and public goods are the antithesis of monopoly. The more widely adopted ARC-AGI becomes, the more it belongs to everyone and the less proprietary it is. The benchmark itself is open. The competition results are public. The research papers are on arXiv. This is by design -- credibility requires transparency, and transparency destroys excludability. The funding model compounds this tension: labs being evaluated are also donors, which means the organization's independence -- its core product -- is structurally compromised by its revenue source. The benchmark saturation cycle adds another layer: ARC-AGI-1 went from 33% to 87.5% SOTA within roughly a year. Each version is a treadmill, not a flywheel. There is no compounding advantage -- only a perpetual obligation to design harder puzzles faster than the models can solve them.

I respect what Chollet, Knoop, and Kamradt are building. The measurement of genuine intelligence is a civilizationally important problem, and this team may be the best-positioned group to solve it. But civilizational importance and investability are not the same thing. I co-founded Palantir because the secret about intelligence analysis could be captured as a for-profit monopoly. I backed SpaceX because reusable rockets could be captured as proprietary technology with compounding cost advantages. ARC Prize creates genuine value -- but it has deliberately structured itself so that value cannot be captured as equity. My money has no instrument to enter, no mechanism to compound, and no path to a power-law return. This is a pass -- not because the work is unimportant, but because it is uninvestable.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Contrarian Secret and Monopoly Potential | 6/35 |
| Founder Conviction and Definite Vision | 16/25 |
| Technological Discontinuity and 10x Superiority | 9/20 |
| Durability and Last-Mover Defensibility | 5/10 |
| Small-Market Dominance with Expansion Path | 6/10 |
| **Total** | **42/100** |

**Total Score: 42/100** (Pass)
