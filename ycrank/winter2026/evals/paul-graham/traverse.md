# Traverse -- Paul Graham Evaluation

The first thing I notice is the pivot. Traverse was Clice AI -- "personal AI agents for team members that actually execute tasks" -- until very recently, when it became a company selling RL training environments to frontier AI labs. The domain clice.ai now redirects to traverse.so. The YC page at /companies/clice-ai shows Traverse's information. This means the current idea is weeks or at most a few months old. I don't automatically penalize pivots -- Justin.tv became Twitch, after all. But the Twitch pivot happened after years of operating a live-streaming platform and noticing that game streams were the only content growing organically. That pivot was an organic discovery. This pivot looks different. Two CS students from Waterloo noticed RL environments are the hottest infrastructure category in AI and repositioned toward it. When I ask "how did they find this problem?" the most likely answer is: they read about it.

The competitive landscape confirms this. Wing VC counts more than 35 companies building RL environments. Scale AI ($29B valuation, ~$870M revenue) and Surge AI (~$1.2B revenue) are both expanding into this space. Mechanize, backed by Nat Friedman and Daniel Gross, is already working with Anthropic and offering $500K engineering salaries. When I wrote that the two most impressive companies I've seen recently are not working on AI, this is the dynamic I was pointing at. When every venture capitalist publishes market analyses about a category, when dozens of well-funded competitors are already fighting over a small number of lab contracts, the signal-to-noise ratio for new entrants collapses. This is a consensus opportunity. Consensus opportunities are already priced.

Traverse claims differentiation in non-deterministic verifiers -- building RL environments for domains like medicine, law, and scientific research where "correct" is subjective. That's a genuinely interesting framing, and if it were real, it could be a meaningful wedge. The schlep of constructing verifiers for taste-dependent work is legitimately hard. But here's what concerns me: building verifiers for medical or legal reasoning requires deep domain expertise in medicine or law. These founders are early-career software engineers. Lance led ML engineering at a university AI club and worked at Kalshi. Zachary built backend systems at Mercor and Uber. Neither has spent years immersed in the messy, regulatory, domain-specific knowledge that would make non-deterministic verifiers actually work. Stripe succeeded because programmers tackled a programmer's problem. Traverse is programmers claiming they'll solve a domain-expert's problem in domains they haven't lived in. The schlep is real, but it's not *their* schlep.

The strongest bull case: maybe the non-deterministic verifier angle is genuinely underserved because the big data labeling companies are optimized for deterministic work at scale, and retooling for subjective verification requires a fundamentally different approach. Maybe Zachary's time at Mercor -- which supplies human contractors to AI labs -- gave him real insight into where the current RL pipeline breaks down. Maybe the pivot is actually a positive signal of founder adaptability, and Jared Friedman's mentorship at YC gives them a credible path to early lab partnerships. If all of this were true, and if they could demonstrate verifier quality that measurably improves model performance on subjective tasks, they'd have something. But every link in that chain is hypothetical. There's no prototype, no lab contract, no pilot data, no evidence that their verifiers work better than what Scale or Surge can build. The positioning is a thesis statement, not a demonstrated capability.

On the founder side, there are real signals of technical ability. Zachary's side projects show genuine builder instincts -- tunesform.com reached 10K+ unique users, vibeornot.com hit 25K+ users in 24 hours, and he organized a hackathon that attracted 800+ applicants. Lance dropped out of Waterloo after one semester to build. These are hackers. I believe they can build software. What I don't believe, yet, is that they have the specific knowledge and relationships needed to sell custom RL environments to frontier labs competing against companies with thousand-person teams and billion-dollar war chests. At pre-seed, the question isn't "can you code?" -- it's "why you, why this, why now?" The "why you" answer here is thin.

This is a pass for me. Two capable young engineers chasing the hottest infrastructure category in AI, having just abandoned a different idea, with no traction and no domain-specific advantage against extremely well-resourced incumbents. The idea wasn't discovered through lived experience; it was assembled from market observation. That's the failure mode I keep warning about -- smart people working on problems they selected rather than problems they couldn't stop thinking about.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Organic Problem Discovery and Schlep Willingness | 6/30 |
| Relentlessly Resourceful Founders | 11/25 |
| Evidence of Wanting: Demonstrated User Pull | 4/20 |
| Technical Hacker Founders Who Build | 10/15 |
| Growth Trajectory and Default Alive Economics | 5/10 |
| **Total** | **36/100** |

**Total Score: 36/100** (Pass)
