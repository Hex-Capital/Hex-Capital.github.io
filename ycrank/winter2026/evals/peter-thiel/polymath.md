# Polymath -- Peter Thiel Evaluation

Thirty-five companies building RL environments. Frontier labs deliberately cultivating a fragmented vendor ecosystem to drive prices down. The SemiAnalysis newsletter describes this market structure in terms that should make any investor pause: seed-stage companies with fewer than twenty employees, typically serving one to three customers under exclusive contracts, while their buyers -- Anthropic, OpenAI, Google DeepMind -- systematically prevent any single vendor from accumulating pricing power. This is not a market with a hidden secret waiting to be exploited. This is a market engineered by its buyers to ensure that competition never stops, that margins never widen, and that no supplier ever achieves escape velocity. The entire structure is a Girardian trap -- dozens of startups imitating each other's approaches, converging on the same small pool of customers, while those customers treat supplier diversity as a strategic objective. When your buyers' explicit strategy is to commoditize you, you are not building a monopoly. You are building a commodity.

What is the secret here? The implicit thesis is that automated environment generation -- "factories" rather than hand-crafted replicas -- is fundamentally superior to manual construction. But this is not a secret. It is an engineering preference that every competent team in the space would articulate. Mechanize may have chosen a human-intensive model, but the automation-versus-labor tradeoff is a tactical choice, not a contrarian insight about the world. No intelligent person would argue that, all else equal, manual construction is preferable to automated construction. The absence of a genuine secret is the core problem. When I invested in Palantir, the secret was that PayPal's fraud-detection algorithms could transform intelligence analysis -- a claim that most intelligence professionals at the time would have actively rejected. Polymath's thesis -- that RL environments should be built programmatically at scale -- is something every frontier lab already agrees with. They simply want multiple vendors competing to do it cheaply.

The customer concentration amplifies the structural problem. The addressable buyer pool consists of perhaps five or six organizations on Earth. Each of these organizations has the engineering talent and financial resources to build environments in-house -- and the strategic incentive to do so. When your entire TAM is a handful of sophisticated technology companies that could replicate your product as a side project, you exist at their sufferance, not through your own structural advantage. This is the inverse of the power dynamic that creates monopoly economics. Palantir's government customers couldn't build their own data-fusion platforms; they lacked the engineering culture. Amazon's enterprise customers couldn't build their own cloud infrastructure; they lacked the capital and expertise. But Anthropic and OpenAI not only can build RL environments -- they already are, and they view vendor diversity as insurance, not dependence.

The strongest bull case requires believing three things simultaneously: that Polymath's automation approach is genuinely an order of magnitude more efficient than alternatives and that this efficiency gap persists as competitors adopt similar techniques; that the Horizon-SWE benchmark becomes an industry standard, creating a standards-setting dynamic that drives demand back to its creators; and that the market grows from tens of millions to billions fast enough that even a commoditized vendor captures substantial absolute revenue. There is a version of this story where Polymath becomes the infrastructure layer for RL environment generation -- the way AWS became infrastructure for web applications. If the automation truly compounds -- each environment making the next one cheaper and better -- the cost advantage could widen rather than narrow. The benchmark credibility is real: Horizon-SWE already shows evaluation results for Claude Opus 4.6, GPT-5.2 Codex, and Gemini 3 Pro, which demonstrates that frontier labs are at least aware of it. But benchmarks are public goods. SWE-Bench made Scale AI's SEAL lab visible; it did not make Scale AI a monopolist in RL environments. Standards-setting creates attention, not moats.

The founders are competent but unremarkable for this stage. Two UC Berkeley graduates, one from Hume AI and AWS, the other from Amazon and Plaid. Solid engineering backgrounds. The CTO's prior startup at Berkeley SkyDeck shows entrepreneurial inclination. But I see no signal of the extreme conviction that characterizes the founders I back -- no prior exit, no refused acquisition, no published worldview on where AI training is headed, no evidence of deep intellectual frameworks beyond market opportunity. The Horizon-SWE benchmark publication demonstrates execution capability and a desire to set standards, which counts for something. But at pre-seed with two founders against thirty-five competitors -- several of whom are backed by Benchmark, Founders Fund portfolio companies, and the technical luminaries of the field -- I need to see something extraordinary in the founders that suggests they can escape the competitive trap their market was designed to create. I do not see it here.

This is a company entering a competitive market with a better version of an existing approach -- exactly the pattern I avoid. The market is real, the timing is right, the team is capable. But there is no secret, no path to monopoly, and no structural defense against commoditization. The buyers themselves are ensuring that no vendor wins. Pass.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Contrarian Secret and Monopoly Potential | 6/35 |
| Founder Conviction and Definite Vision | 10/25 |
| Technological Discontinuity and 10x Superiority | 8/20 |
| Durability and Last-Mover Defensibility | 3/10 |
| Small-Market Dominance with Expansion Path | 4/10 |
| **Total** | **31/100** |

**Total Score: 31/100** (Pass)
