# MouseCat -- Paul Graham Evaluation

The first thing I notice about MouseCat is the competitive timing problem. Sardine raised $70M in February 2025 explicitly to build "a suite of intelligent agents designed to streamline fraud and compliance operations." That's not a vague adjacency. That's the same product described in nearly the same words. When a well-funded incumbent with 100+ customers and 130% ARR growth raises a round specifically targeting your thesis, the schlep blindness argument gets harder to make. Stripe worked partly because the banks and legacy payment companies were structurally blind to developer experience as a category. They didn't see the problem. Here, Sardine, Sift, DataVisor, and Unit21 all see the problem. They're funded. They're building. The question is whether MouseCat can outrun them anyway.

The organic discovery signal from McAllister is the strongest thing in this dossier. Four years at Coinbase building ML models for ATO and ACH fraud means he was the person sitting in the seat that MouseCat now aims to automate. He wasn't reading about fraud investigation in TechCrunch -- he was building the streaming features, training the risk models, and presumably watching investigators manually cross-reference signals from Socure and LexisNexis before translating findings into production rules. That's the kind of professional lived experience where you see the broken workflow every day until you can't ignore it anymore. Aldridge's background at AWS AI is the technology counterpart -- he built Bedrock Agents, AgentCore, and Knowledge Bases, which means he literally architected the AI agent infrastructure that powers this category. The founder-problem-technology convergence is unusually precise. McAllister knows what needs automating. Aldridge knows how to build the automation. That's a real match.

But I keep coming back to the co-founder relationship. The dossier finds no shared employer, no shared university, no public record of how they met. Aldridge was at AWS in what I assume was Seattle. McAllister was at Coinbase and before that Microsoft and Cornell. Two strangers in adjacent domains deciding to start a company together is a pattern I've seen fail more often than succeed. In one YC batch, nine companies that added co-founders they didn't know between interview and start all fell apart within a year. I'm not saying that's what happened here -- I simply don't have the data. But the absence of a founding story is itself a signal. When the co-founder relationship is strong, founders tend to tell the story. When it's absent from every public source, I get cautious.

The schlep here is genuine. Integrating with a dozen data vendors, building on-premises deployment for banks that won't let data leave their environment, maintaining compliance audit logs, connecting to Databricks and Snowflake -- this is ugly infrastructure work that most AI startups would rather not touch. The investigation-to-production-rule pipeline specifically is a workflow most AI companies skip because it requires understanding both the investigator's manual process and the ML team's feature engineering pipeline. That's not something you can build well without McAllister's kind of domain background. The problem is that "genuine schlep" is necessary but not sufficient. Stripe had genuine schlep plus structural blindness among incumbents. MouseCat has genuine schlep plus incumbents who are actively throwing money at the same schlep.

The bull case goes like this: incumbents building agentic features are bolting AI onto existing real-time scoring architectures. MouseCat is building investigation-to-production natively -- a different workflow targeting a different user (the analyst and ML engineer, not the risk operations manager clicking rules in a dashboard). Unit21's no-code approach and Sardine's real-time decisioning serve different personas than MouseCat's backtesting and synthetic label generation pipeline. If MouseCat can get embedded in a customer's Databricks infrastructure with production rules running in their feature store, the switching costs compound quickly. And the YC product showcase rating -- "2nd highest-rated company" -- suggests peers who understand the space saw something real. Both founders clearly can build the product: Aldridge is a Principal Engineer who shipped major AWS products, McAllister has 32 GitHub repos and published engineering work at Coinbase. These are hackers, not pitch artists. If they can land two or three design partners in the next six months and demonstrate that their AI-generated rules outperform manually written ones, the data flywheel could make the incumbent competition irrelevant.

What keeps me from investing is the category heat. When I said the most impressive YC companies I've seen recently aren't working on AI, this is the pattern I was pointing at. "AI for fraud detection" is a category where every VC is writing checks, every incumbent is launching features, and every smart ML engineer at every fintech is thinking about starting a company. MouseCat's founders are better positioned than most -- McAllister's Coinbase fraud background and Aldridge's agent infrastructure expertise are real differentiators -- but I've learned that in consensus categories, even the best team faces a crowded field where differentiation gets harder over time. I'd want to see early customer pull -- a signed LOI, a design partner running backtests, anything showing that fraud teams prefer MouseCat's approach to what their existing vendors are shipping -- before writing a check.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Organic Problem Discovery and Schlep Willingness | 20/30 |
| Relentlessly Resourceful Founders | 14/25 |
| Evidence of Wanting: Demonstrated User Pull | 6/20 |
| Technical Hacker Founders Who Build | 12/15 |
| Growth Trajectory and Default Alive Economics | 4/10 |
| **Total** | **56/100** |

**Total Score: 56/100** (Neutral)
