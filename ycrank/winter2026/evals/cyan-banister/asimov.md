# Asimov -- Cyan Banister Evaluation

Here's what catches my attention first, and it's not good: this is a category that's rapidly becoming consensus. Scale AI launched its Physical AI data collection platform in 2025. Multiple YC batches now have companies doing variations of robotics training data. VCs poured $7.2 billion into robotics last year. When I invested in SpaceX, private space was considered delusional. When I backed Uber, ride-sharing was literally illegal. The best investments I've ever made were ones that other investors actively mocked. Asimov is operating in a space where the biggest data company on earth — Scale AI at $29 billion — has already planted its flag. That doesn't mean there isn't an opportunity here, but it means the weirdness premium I rely on has been substantially eroded. The most promising companies are not popular, and robotics data infrastructure is getting popular fast.

The founder question is where I'd normally start, and it's where I struggle most with this company. I don't know Lyem Ningthou's story — not the LinkedIn version, but the real one. Why does a recent UC Berkeley CS grad care about capturing how humans fold laundry and stack dishes? The dossier gives me a resume: startup experience at FLIP and Blume, NSF-funded GPU time, an innovation challenge win in eighth grade. That's a capable young person, absolutely. But my whole process begins with the biographical thread that makes a founder and their problem inseparable. Travis Kalanick had been raging about the taxi medallion system for years before Uber existed. The Crusoe founders had independently arrived at an insight about wasted gas that was rooted in their understanding of thermodynamics. I need to know what personal experience drove Lyem to the specific realization that 8 billion people generate untapped physical intelligence every day. That thread might exist — I just can't see it from here, and its absence leaves my primary evaluation channel blocked.

Where this company genuinely speaks to me is on economic access, and I wish the founders were telling this story more loudly. Five thousand people across three continents getting paid twenty to thirty dollars an hour to wear a lightweight headband while they cook, clean, serve food, work in factories — that's the creation of an entirely new income stream for people doing work they'd be doing anyway. That's the same structural pattern I saw in Uber creating income for drivers and Postmates creating income for delivery workers. You're essentially paying humans for the privilege of their natural physical intelligence, which is both philosophically fascinating and economically empowering. If Asimov scales this contributor network into the tens of thousands across lower-income geographies, it becomes a real tool for economic participation in the AI economy by people who would otherwise be excluded from it. That's the version of this company that gives me a flicker of energy.

The bull case is genuinely interesting if you squint at it right: the distributed headband model captures organic human behavior in real environments — actual kitchens, actual hotel rooms, actual factory floors — while Scale AI is running scripted demonstrations in an SF R&D lab. That's a real qualitative difference in the data. If frontier robotics labs discover that organic egocentric data trains better robots than staged demonstrations, Asimov's supply-side network becomes extremely valuable and difficult to replicate quickly. The market timing is undeniably right — humanoid robot programs have billions in funding and a screaming need for training data. And if 5,000+ contributors is accurate at pre-seed stage, that's a meaningful operational accomplishment that suggests real execution ability. The company could become a critical piece of infrastructure at the exact inflection point when embodied AI goes from research to deployment.

But I keep coming back to defensibility. The headband hardware isn't proprietary. The data collection methodology isn't patented (or at least not evidenced). The contributor network takes time to build, but it's not a deep technical moat — it's an operational head start, and Scale AI has $1.6 billion in funding to close that gap whenever they choose to. The brand confusion with the established synthetic biology company named Asimov is a genuine operational drag on discoverability and credibility. And managing physical hardware logistics across three continents with a team of three people is the kind of operational complexity that breaks small teams, particularly when the hardware is being worn by thousands of individuals in uncontrolled environments. Quality control at that scale is a nightmare I've seen consume much larger teams.

I'd want to sit across from Lyem and hear the real story — the one underneath the resume. There might be something there that changes my read entirely. But based on what I can see today, I have a company in an increasingly crowded category, with a founder whose biographical connection to the problem is opaque to me, facing a dominant incumbent that has already entered their space. The economic access angle is real and underappreciated, and the core insight about organic human behavior as the untapped training data source is sound. But sound isn't the same as strange, and I invest at my best when something feels both impossible and inevitable simultaneously. This feels plausible — which is a different thing entirely.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Founder Biographical Grit and Personal Stake | 10/30 |
| Anti-Consensus Conviction and Weird Factor | 11/25 |
| Economic Access and Real-World Impact | 14/20 |
| Navigating Complexity in Hard Spaces | 6/15 |
| Co-Founder Alignment and Team Resilience | 4/10 |
| **Total** | **45/100** |

**Total Score: 45/100** (Neutral)
