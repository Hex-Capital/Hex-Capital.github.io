# ARC Prize Foundation -- Sam Lessin Evaluation

Here's the structural paradox that makes this one of the most interesting non-investments I've encountered: you have François Chollet -- creator of Keras, 608K followers, arguably one of the fifty most consequential people in the history of deep learning -- teamed with Mike Knoop, who co-founded Zapier and scaled it to $5B and $310M in annual revenue. This might be the most credentialed founding team in the entire YC W26 cohort. And they've built something that four frontier AI labs voluntarily report in their model cards. That's a genuine adoption signal that most seed-stage companies would kill for. But there is no investment to make. ARC Prize Foundation is a 501(c)(3) nonprofit. There's no equity, no token, no revenue share, no convertible note, nothing. I'm deploying my own money. The most "sane" founding team paired with a structurally uninvestable vehicle isn't a bet I can take -- it's a donation, and I'm not running a foundation.

Set aside the nonprofit problem for a moment and apply my framework to the underlying idea. Is this a sane person with an insane idea? Half of the equation is off the charts -- these are some of the sanest people in AI. But "we need better benchmarks to measure AI progress" is maybe the single most consensus statement in the entire AI ecosystem right now. Everyone -- every lab, every researcher, every policy maker -- agrees that existing benchmarks saturate too quickly and don't measure real intelligence. This isn't contrarian. This isn't an idea that makes most investors uncomfortable. It's closer to an idea that makes everyone nod vigorously. The best version of my framework requires that the idea provoke genuine confusion or skepticism. Nobody is confused by ARC Prize. The specific intellectual contribution -- measuring skill-acquisition efficiency rather than memorized knowledge -- is elegant and important, but it's building on Chollet's own 2019 paper that the research community has already absorbed and accepted. This is consensus wrapped in rigor.

The moat question is where this gets genuinely interesting and genuinely troubling. On one hand, the 4-lab voluntary adoption creates real coordination costs -- once ARC-AGI is the reference benchmark, switching requires all participants to move simultaneously. That's a network-effect-adjacent dynamic, and it maps loosely onto my protocol-layer thesis. If ARC-AGI becomes the TCP/IP of intelligence measurement, that's a real primitive. But benchmarks have a fundamental treadmill problem that works against durable defensibility. ARC-AGI-1 went from 33% SOTA to 87.5% (OpenAI's o3 high-compute) within roughly a year. ARC-AGI-2 launched and pure LLMs score 0%, but Grok 4 already hit 15.9%. Each version has a finite shelf life, requiring continuous redesign. That's not a moat deepening over time -- it's a moat you have to rebuild from scratch every twelve to eighteen months. Compare this to Helium, which I held for seven years: the physical infrastructure of hotspots accumulated and compounded. There's nothing accumulating here except reputation and community, which are real but fragile. And the funding dependency on labs being evaluated -- xAI and Google are both donors and subjects -- is a structural conflict that undermines the independence that is theoretically the core value.

The bull case, if I'm being honest, is significant. If AI regulation crystallizes globally and governments require independent evaluation of frontier models -- which the EU AI Act and U.S. AISI activity suggest is plausible -- whoever owns the trusted benchmark owns critical infrastructure. ARC Prize is better positioned for that than Scale AI, whose commercial relationships with labs create obvious conflicts. A world where ARC-AGI-3's interactive reasoning environments become the FAA-equivalent certification test for AI systems is a world where this organization has extraordinary power, even if not equity value. If this were structured as a for-profit with a government contracting model or a certification fee structure -- something like UL for AI -- the conversation would be completely different. That company, with this team, would be a genuinely compelling bet. The protocol position would have a value-capture mechanism, and the "infinity story" of becoming the global standard for intelligence measurement would have financial optionality attached.

But it's not structured that way. And even if someone carved a for-profit entity out of this nonprofit at some future date, that's speculative restructuring, not an investable signal today. My framework requires both "infinity optionality" and a "downside cushion" of real economics. ARC Prize has neither -- infinite importance, yes, but zero financial optionality and zero revenue. The donation model from impressive names (Andy Fang, Dharmesh Shah, Aaron Levie) signals that smart people think this matters, but philanthropy is not a business model. I'd rather fund Craftwork -- a painting company with a tech layer that generates actual cash flow -- than an evaluation organization with world-class credibility and no mechanism to turn that credibility into returns. Important work. Not my check to write.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| "Sane Person, Insane Idea" Calibration | 16/30 |
| AI-Resistant Structural Moat | 9/25 |
| New Primitive or Protocol Position | 12/20 |
| Narrative Magnitude and Infinity Optionality | 9/15 |
| Real Revenue or Asset Cushion | 2/10 |
| **Total** | **48/100** |

**Total Score: 48/100** (Neutral)
