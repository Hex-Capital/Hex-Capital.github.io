# MouseCat -- Naval Ravikant Evaluation

The most striking thing about MouseCat isn't the founders -- it's the competitive timing. Sardine raised $70M in February 2025 with an explicit mandate to build "intelligent agents designed to streamline fraud and compliance operations." That's not adjacent overlap. That's nearly the same sentence MouseCat would use to describe itself. When a $145M-funded incumbent with 130% year-over-year ARR growth and 100+ enterprise customers announces it's building your exact product category, the question stops being "is this a good idea?" and becomes "why does it matter that you thought of it first?" The answer has to come from specific knowledge -- something these founders know that Sardine's team, with all their resources, cannot easily acquire.

On specific knowledge, the founders clear the bar individually. McAllister spent four years at Coinbase building the actual ML models for ATO and ACH fraud -- not advising on fraud strategy, not managing a fraud team, but writing the sequence features and streaming systems that detect fraudulent patterns in real-time transaction data. He published on it. That's knowledge acquired through doing, not studying. Aldridge is the rarer find: 6.5 years as Principal Engineer at AWS building Bedrock Agents, AgentCore, and Knowledge Bases -- the literal infrastructure that powers AI agent systems at cloud scale. He's described as a core maintainer of the Model Context Protocol. You could not hire a recruiter to assemble this combination. The fraud domain expert and the person who built the production agent infrastructure, together building AI agents for fraud. The complementarity is precise, not accidental. But I note a distinction: this is institutional knowledge, deep and real, but acquired through high-status engineering roles rather than through years of independent obsession with a problem no one else was looking at. Evan Williams thought about public communication for a decade before Twitter. These founders worked at excellent companies on relevant problems. That's strong but it's a different kind of strong.

The leverage question is where my framework creates the most friction with this company. MouseCat makes existing fraud analysts more productive -- automating investigations, generating rules, synthesizing signals from multiple vendors. That's efficiency. It's not creating a new form of leverage that didn't exist before. Compare: Replit turned non-programmers into programmers. AngelList turned individuals into fund managers. Uber turned car owners into taxi drivers. MouseCat turns a fraud analyst who can handle 20 cases per day into one who can handle 200. Valuable to the employer, but the leverage multiplier is incremental, not categorical. And structurally, MouseCat is an application sitting on top of other people's infrastructure -- Databricks, Snowflake, and critically, data from vendors like Sardine, Socure, and LexisNexis. My portfolio has consistently favored the infrastructure layer, the picks-and-shovels. MouseCat is the person using the shovel, not the company selling it. When one of your essential data vendors is also your primary competitor, you've got a dependency that can be weaponized against you.

The bull case I genuinely consider: if MouseCat lands three to five enterprise customers in the next twelve months, the switching costs could be real. MouseCat-generated rules and features embedded into a customer's production fraud stack -- wired into their Databricks pipelines, their rule engines, their feature stores -- create genuine stickiness. Every backtested rule that goes into production becomes a piece of institutional knowledge that the customer can't easily rip out. The "2nd highest-rated at YC product showcase" signal, thin as it is, suggests the demo impressed a crowd that sees hundreds of companies per batch. And the on-premises deployment model, while it limits cross-customer network effects, is exactly what enterprise risk teams demand -- it's not a bug, it's a feature of the go-to-market. If agentic fraud investigation becomes a must-have category and MouseCat is the first purpose-built product with real production deployments, the incumbents' bolt-on features might not be good enough. The founders' specific knowledge of both the agent infrastructure and the fraud domain could produce a product that's qualitatively better than what Sardine builds as a side feature.

But I keep returning to the timing problem. This isn't contrarian. "AI agents for fraud" is the most consensus subcategory in an already overheated market. Every major fraud vendor is announcing agentic features. The underlying technology -- LLMs orchestrating multi-step investigation workflows, synthetic label generation -- uses published techniques. The barrier to replication is integration complexity and domain tuning, not fundamental science. When the consensus and the company are pointing in the same direction, you get paid for execution speed, not for being right first. And a two-person team selling on-prem enterprise software to financial institutions, navigating security reviews and procurement cycles, is one of the hardest GTM motions in tech. The founders are strong enough that I'd want to see what they build next if this particular timing window closes. But I'm not writing a check into a race where the other runners have a hundred-million-dollar head start and are running the same direction.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 21/30 |
| Leverage Architecture and Scalability of the Model | 12/25 |
| Contrarian Positioning and Non-Consensus Timing | 7/20 |
| Founder Integrity and Long-Term Orientation | 9/15 |
| Technical Compounding and Defensibility Over Time | 5/10 |
| **Total** | **54/100** |

**Total Score: 54/100** (Neutral)
