# Polymath -- Elad Gil Evaluation

The most striking thing about Polymath's market isn't the demand -- it's the buyer dynamics. Anthropic has discussed spending over $1 billion on RL environments. OpenAI is purchasing hundreds of site replicas at $20K each. That's real money. But the SemiAnalysis newsletter reveals what's actually happening: frontier labs are *deliberately cultivating diverse vendor ecosystems to commoditize RL environments and reduce costs*. The buyers are engineering a market structure where no single vendor accumulates leverage. I've seen this pattern before -- it's the opposite of what created durable value at Stripe or PagerDuty. Those companies served millions of developers or thousands of enterprises. Polymath's entire addressable buyer pool is five to seven organizations, and those organizations are the most technically capable entities on Earth. They could build this in-house. They're outsourcing for speed, not because they lack capability. That's a procurement relationship, not a distribution moat.

The structural inflection is genuine -- I won't argue otherwise. RLVR emerged as a major training paradigm in 2025, agent capabilities crossed a threshold where long-horizon multi-tool tasks became feasible, and environment quality became the acknowledged bottleneck. That's a real "why now." But this inflection is completely consensus. Thirty-five-plus companies are already building RL environments. Applied Compute raised $100M. Mechanize is backed by Nat Friedman and Patrick Collison. Scale AI, at a $29B+ valuation with existing relationships at every frontier lab, is expanding its SEAL lab directly into this space. Prime Intellect is open-sourcing environments entirely. When I invested in PagerDuty, nobody thought operations alerting was exciting -- that's why the opportunity existed. When I backed Coinbase, most software investors were allergic to financial regulation. This market is the opposite: everyone sees it, everyone is funding it, and the incumbents are already moving in. "Non-obvious" is the core of my thesis, and this market is as obvious as it gets in 2026.

The bull case deserves genuine engagement. Polymath's "automated environment factory" concept is the right architectural insight -- if you can generate production-grade RL environments programmatically at 10x the throughput and a fraction of the cost of Mechanize's approach (paying SWEs $500K to build environments manually), that's a real technical wedge. The Horizon-SWE benchmark is a smart move: publishing a benchmark with evaluation results for Claude Opus, GPT-5.2, and Gemini 3 Pro creates a standards-setting dynamic that could pull frontier labs into your orbit. If labs start reporting against Horizon-SWE the way they report against SWE-Bench, Polymath becomes the reference implementation. And the deeper bull case is market expansion: today it's five frontier labs, but as AI agents get deployed across enterprises, every company running agents will need evaluation environments. If the automated factory scales horizontally into that broader market, the TAM expands by orders of magnitude and the customer concentration problem dissolves. For this to work, though, you need the automation to actually be 10x better than alternatives, you need the benchmark to achieve adoption despite Scale AI's competing SWE-Bench Pro, you need to survive long enough for the enterprise market to materialize, and you need to avoid getting replicated by well-resourced competitors. That's at least three sequential miracles, and I've written extensively about why compounding low-probability events is the primary way startups fail.

The product-to-distribution trajectory is where I struggle most. Stripe's payment API wasn't just a product -- it was a developer relationship that became the distribution channel for Atlas, Billing, Radar, and Treasury. What does Polymath distribute through its RL environment contracts? More RL environments. There's no natural expansion into adjacent products because the customer relationship is a procurement contract with a handful of labs, not an embedded integration with thousands of developers. The benchmark has some platform potential -- if it becomes the standard, Polymath could layer evaluation services, leaderboard products, and environment marketplace capabilities on top. But that expansion path is speculative, and it's competing against Scale AI's established SEAL leaderboard infrastructure and Prime Intellect's open-source Environments Hub.

The founders have relevant backgrounds -- UC Berkeley EECS, experience at Hume AI, AWS, Plaid, Amazon -- and publishing Horizon-SWE with 50 tasks across a 20,000+ commit monorepo with five frontier model evaluations is legitimate shipped work for a pre-seed company. That's not vaporware. But I don't see evidence of the kind of distribution-first thinking or operational intensity that would give me conviction they can navigate a market this competitive. The dossier shows no confirmed customers, no revenue, and minimal public reach. At this stage that's forgivable in isolation -- but combined with the market structure concerns, it means there's no counterbalancing signal to override my structural objections.

I'm passing. The market timing is right, but the market structure is wrong for building a durable, high-value company. Frontier labs holding all the buyer power, 35+ vendors competing, open-source alternatives emerging, and Scale AI entering from an established position -- that's a market where even the winner may not generate venture-scale returns. Polymath has the right technical instinct with automated environment generation, but the right instinct in a commoditizing market with concentrated buyers isn't enough. I need to see either a non-obvious market that others are missing, or a distribution advantage that compounds. I see neither here.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Non-Obvious Market at Structural Inflection | 12/35 |
| Product-to-Distribution Trajectory | 8/25 |
| Single-Miracle Operational Clarity | 6/15 |
| Founder Execution Velocity | 7/15 |
| Technology Cycle Positioning | 6/10 |
| **Total** | **39/100** |

**Total Score: 39/100** (Pass)
