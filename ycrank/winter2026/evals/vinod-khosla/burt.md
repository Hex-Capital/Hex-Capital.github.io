# Burt -- Vinod Khosla Evaluation

The most telling signal about Burt is that the company can't decide what it is. The YC page describes a general-purpose model fine-tuning platform. The live website describes logistics back-office automation — invoices, documents, data entry. These are not two expressions of the same thesis. They are two different companies, both small, and the fact that the founders haven't committed reveals something I find disqualifying before I even get to the team or the technology: neither framing, even if fully realized, produces a consequence of success that changes how the world works. A managed fine-tuning service that makes inference 3x faster for unnamed customers is a useful optimization. Automating logistics paperwork is a useful vertical SaaS play. Neither is an industry transformation. Neither makes the incumbent approach obsolete. The founders have aimed at targets where success means a modest business — and that is exactly the pattern I walk away from.

Let me engage with the strongest version of the bull case, because it deserves honest consideration. The argument would go like this: as AI agents proliferate to billions of daily inference calls, the gap between frontier model costs and what production economics can sustain will widen dramatically. A company that reliably produces specialized models at 10x lower cost becomes critical infrastructure — an optimization layer that captures value precisely because the cloud providers' incentives are misaligned (they want you to burn more tokens, not fewer). If Burt accumulates domain-specific training recipes across dozens of verticals, compounding expertise creates a real moat. That's a defensible position worth pursuing. But here's why that argument fails my test: even in the best case, you're building a cost-reduction layer for AI infrastructure. You're saving companies money on inference. That's a real business. It's not a civilization-scale business. And the competition — Together AI at $534M raised and $300M in annualized revenue, Fireworks AI at $327M raised and $280M in annualized revenue — already occupies this space with multi-year head starts and thousands of customers. Predibase, the closest direct comparable to what Burt describes, was acquired by Rubrik for reportedly $100M after raising $28M. That's a fine outcome for early investors. It is not a venture-scale outcome, and it suggests the standalone fine-tuning platform may not survive as an independent category.

On the technology itself, I see no structural disruption. The claim is "outperform SOTA models like gemini-3-flash/pro while being 10x faster and cheaper" — but fine-tuning open-source models to beat general-purpose models on narrow tasks is well-understood technique at this point. Axolotl, LLaMA-Factory, Unsloth, and dozens of similar frameworks make this accessible to any competent ML engineer. The single cited case study — a VLM that's "~3x faster" than Gemini for an unnamed customer — is a performance improvement, not a new capability that didn't exist before. Compare this to Juniper building TCP/IP routers when Cisco's CTO said they'd never do it, or Square replacing the entire POS infrastructure with a phone dongle. Those were structural replacements. This is an optimization within an existing paradigm, offered as a managed service in a market that's rapidly commoditizing.

Bobby Zhong's career shows standard YC-ecosystem progression — founding engineer at Pirros (W23), software engineer at Replo (S21) working on coding agents, a prior startup (Educado) that ran for seven months. That's a young builder gaining experience, which I respect. But there's no signal of the contrarian courage I look for — no evidence of attacking a problem experts dismissed as impossible, no outsider perspective applied to an established industry. The CTO, Kurt Sharma, is essentially invisible in public sources — no LinkedIn profile conclusively identified, no GitHub, no professional history. For a company whose entire value proposition is technical capability in model training and deployment, this opacity is concerning. I can't evaluate what I can't see.

The timing question is worth noting: the fine-tuning trend is already consensus. Together AI and Fireworks AI are at hundreds of millions in annual revenue. The category has been named, funded, and consolidated. Burt isn't skating to where the puck will be — it's arriving at a rink where the game is well underway and the dominant players have been scoring for years. When I backed OpenAI in 2019, AI was "laughable" to most investors. The fine-tuning platform market in 2026 is anything but laughable — it's a recognized, heavily capitalized sector. That's not where I find asymmetric returns.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Consequence Magnitude If Successful | 5/30 |
| Founder Learning Rate and Contrarian Courage | 6/25 |
| Technology Disruption Potential vs. Incumbent Systems | 5/20 |
| Rate of Change and Timing Trajectory | 6/15 |
| Gene Pool Engineering and Team Construction | 4/10 |
| **Total** | **26/100** |

**Total Score: 26/100** (Strong Pass)
