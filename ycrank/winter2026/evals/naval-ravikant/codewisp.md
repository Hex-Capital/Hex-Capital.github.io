# CodeWisp -- Naval Ravikant Evaluation

Here's the uncomfortable fact: I already have a bet in this exact space. I backed Moonlake AI at their $28M seed alongside Nvidia Ventures and Ian Goodfellow. So I've already asked myself the question "can AI make game creation accessible?" and answered yes -- with a check. The question isn't whether the market exists. The question is whether CodeWisp is the right vehicle, and whether Elvin Fu knows something my Moonlake founders don't.

Start with the specific knowledge test. Elvin Fu has been making games since he was ten. He's built two game engines from scratch. He's in the Top 20 most followed accounts on Scratch out of 135 million users. He's taught game development to 22 million students online. This isn't a consultant who read a McKinsey report about gaming and decided to found a startup. This is someone who has spent over a decade on the exact seam between "people who want to make games" and "the tools that stop them." He understands the dropout curve of beginner game creators better than almost anyone alive -- not because he studied it, but because he's watched millions of students hit it. That knowledge is genuine, non-transferable, and directly relevant to the product he's building. It's the kind of obsessive domain immersion I look for.

But specific knowledge about the user is only half the equation. The other half is specific knowledge about the technology. And here the signal thins out. Fu's GitHub shows minimal public activity. The AI generation layer -- the part that turns natural language into playable games -- is built on top of LLMs that CodeWisp doesn't own and can't differentiate. The leverage in this business is borrowed leverage. When I backed Replit, Amjad Masad had been building coding environments for years and was constructing a novel runtime architecture. When I backed Stack Overflow, Jeff Atwood and Joel Spolsky were building a knowledge graph that compounded with every question. CodeWisp's core technology is an API call to someone else's model with a game-specific prompt layer on top. That's a feature, not a platform. And with Rosebud at 2.1 million games created and $9M raised, Moonlake with Stanford AI researchers and $28M, and Unity inevitably shipping AI creation features into their engine, the generation layer is racing toward commodity faster than the community layer can build a moat.

The leverage architecture is where this falls short of my framework. The best investments create a new form of leverage that didn't exist before -- Uber turned every car into a taxi, AngelList turned every accredited investor into an angel. CodeWisp applies existing leverage (LLM code generation) to a specific vertical (2D web games). That's useful but it's not new leverage. The community and education layers -- courses, leaderboards, game showcase -- are the right instinct. If CodeWisp becomes the place where the next generation of game creators grows up, the way Scratch was for the current generation, the network effects could be real. But 4,122 developers and single-digit likes on featured games is early evidence of community, not proof of a flywheel.

The contrarian timing test fails cleanly. "AI can generate games" is not a secret -- it's a PowerPoint slide in every gaming VC's deck. Five funded competitors are building variations of the same thesis. Google reports 90% of game developers already use generative AI. YC itself noted 25% of its W25 batch had codebases that were 95%+ AI-generated. When the category has its own market research reports projecting 29% CAGR, you're not early and non-consensus -- you're in a crowded race where execution speed and capital determine winners. My best returns came from bets where smart people thought I was wrong. Nobody thinks "AI will change game creation" is wrong in 2026.

The strongest bull case: Fu's distribution is his real asset. Twenty-two million students taught, Top 20 on Scratch, 65K YouTube subscribers -- that's a warm-start distribution channel that Moonlake and Rosebud can't replicate by raising more money. My education bets -- Udemy, Codecademy, Stack Overflow -- all had this quality: they started with a community of learners and built a platform around them. If CodeWisp captures the transition from "Scratch for kids" to "AI game creation for teens and adults," the audience is already there and Fu is the natural person to lead them. The educational content -- structured courses, block coding, progressive difficulty -- shows he's thinking about retention, not just acquisition. For this to work, Fu needs a strong technical co-founder who can build proprietary AI capabilities that differentiate from commodity LLM wrappers, and the community needs to reach escape velocity before the well-funded competitors absorb the same audience. Neither of those conditions is met today.

I'd pass. Fu has real specific knowledge about his users, but the technology is thin, the market is consensus, and the leverage is borrowed from LLM providers rather than created by the platform. The solo-founder structure without a visible technical co-founder compounds these concerns. I've already placed my bet in this space with Moonlake, where the Stanford AI team and deeper research foundation give me more confidence in technical compounding. CodeWisp has the right founder for the user side of this problem -- but in a commodity-technology race, understanding your users isn't enough. You need to own the technology that serves them.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 19/30 |
| Leverage Architecture and Scalability of the Model | 12/25 |
| Contrarian Positioning and Non-Consensus Timing | 6/20 |
| Founder Integrity and Long-Term Orientation | 9/15 |
| Technical Compounding and Defensibility Over Time | 4/10 |
| **Total** | **50/100** |

**Total Score: 50/100** (Neutral)
