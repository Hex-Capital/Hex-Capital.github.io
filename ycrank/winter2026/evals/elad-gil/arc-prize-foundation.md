# ARC Prize Foundation -- Elad Gil Evaluation

The first thing I notice is the 501(c)(3) structure. ARC Prize is a nonprofit. There is no equity, no revenue model, no return mechanism for an angel check. As someone investing my own money, this is a structural non-starter before I even evaluate the market or team. But the more analytically interesting question is *why* the founders chose nonprofit status -- and the answer reveals something important about the market itself. Chollet, Knoop, and Kamradt are sophisticated enough to have built a for-profit if they believed one existed here. They chose nonprofit because independent AI benchmarking has a fundamentally broken payment structure: the entities who need the benchmark (AI labs) are the same entities being evaluated, and the broader beneficiaries (researchers, policymakers, the public) aren't positioned to pay. This is the same pattern I've described in EdTech -- when the person who benefits isn't the person who pays, you don't have a market, you have a cause. I've never invested in EdTech for this reason, and AI benchmarking has the same structural flaw.

Set aside the nonprofit issue and ask: is there a structural moment for AI evaluation? Yes, clearly. Reasoning models -- o1, o3, DeepSeek-R1, Gemini Deep Think -- saturate traditional benchmarks within months of release. OpenAI's o3 hit 87.5% on ARC-AGI-1's semi-private eval shortly after ARC-AGI-1 became the reference. Governments are standing up AI safety evaluation frameworks. Four frontier labs voluntarily report ARC-AGI scores in model cards. The demand signal for credible, independent AI evaluation is real and growing. But a structural moment for evaluation demand is not the same as a structural moment for a *company*. The market dynamics here look more like academic publishing or standards bodies than like infrastructure software. When I invested in PagerDuty, operations alerting seemed boring but every software-running company needed it and would *pay* for it. ARC Prize is important but occupies a space where the willingness-to-pay is donation-based, not commercial.

The team is exceptional -- possibly the strongest founding team I've seen in this batch on pure credibility. Chollet created Keras (63.8K GitHub stars, 2M+ users) and authored the foundational ARC benchmark and "On the Measure of Intelligence" paper. Knoop co-founded Zapier, a $5B company generating $310M in 2024 revenue, and is a YC alum. Kamradt's "Needle in a Haystack" test became a community standard for LLM context evaluation. Together they have 678K+ combined X followers and genuine reach into the AI research community. This is a team that could build almost anything. The execution evidence confirms it: two years of competitions with 2,885+ teams, 130+ research papers generated, benchmark versions shipping on schedule, independent academic panel assembled. If this team were building commercial AI evaluation infrastructure -- say, compliance tooling for enterprises navigating the EU AI Act, or evaluation-as-a-service with contractual SLAs -- I'd evaluate very differently.

The distribution moat question is where this falls apart for my framework. A benchmark cannot become a distribution channel for additional products the way Stripe's payment API became a channel for Atlas, Billing, and Treasury. ARC Prize's "product" is a public good -- freely available benchmark tasks, open competitions, published research. Community adoption creates influence, not revenue compounding. The 4,437-member Discord and 1,455 competition teams are engagement metrics for a research community, not a customer base that generates expanding revenue per seat. There is no product-to-distribution trajectory because there is no commercial product.

The strongest bull case would require believing that AI evaluation becomes a regulated, commercially mandated function -- like financial auditing or credit ratings -- and that ARC Prize converts to or spawns a for-profit entity positioned as the Moody's of AI. That's a plausible future. But it requires multiple miracles: regulatory mandates crystallizing around ARC-AGI specifically (not Scale AI's SEAL, which already has the AISI relationship), a conversion from nonprofit to commercial model without losing the independence that makes the benchmark credible, and sustained benchmark relevance against a saturation treadmill where each version gets solved faster than the last. Three sequential low-probability events. I pass on multi-miracle plans regardless of team quality.

I also flag a structural conflict: lab donors (xAI, Google) are also the entities being evaluated. We saw this exact dynamic destroy credibility in credit rating agencies. The independence that gives ARC-AGI its value is undermined by the funding model that sustains it. This isn't a fatal flaw for a research organization, but it's a fundamental problem for anyone trying to build a durable institution around evaluation credibility.

Bottom line: extraordinary team, genuine structural moment for AI evaluation, but no investable entity and no commercial market structure. This is a donation, not an investment. As an angel check from my own capital, I pass.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Non-Obvious Market at Structural Inflection | 10/35 |
| Product-to-Distribution Trajectory | 3/25 |
| Single-Miracle Operational Clarity | 6/15 |
| Founder Execution Velocity | 12/15 |
| Technology Cycle Positioning | 7/10 |
| **Total** | **38/100** |

**Total Score: 38/100** (Pass)
