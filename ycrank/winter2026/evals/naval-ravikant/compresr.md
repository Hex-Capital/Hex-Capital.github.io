# Compresr -- Naval Ravikant Evaluation

The first thing I notice about Compresr is the structural contradiction at the center of the bet. They're building a cost-reduction middleware layer for LLM inference, positioned between applications and model APIs. The entire value proposition depends on token costs remaining painful. But the single most predictable trend in AI infrastructure is that inference costs drop roughly 10x per year. Anthropic already ships prompt caching. OpenAI offers cached context discounts. Context windows keep expanding. Compresr is building a dam against a river that's drying up. The bet isn't contrarian -- it's actually a consensus bet dressed as infrastructure. "AI costs too much" is the most widely shared complaint in the developer ecosystem. Every YC pitch deck mentions it. That's not a secret. That's a PowerPoint slide.

The specific knowledge question is where I start every evaluation, and here the answer is nuanced but ultimately insufficient. Ivan Zakazov researched LLM context compression at EPFL, and Oussama Gabouj worked on prompt compression at DLab. That's genuine domain proximity. But the knowledge was acquired through an educational institution -- which, by my framework, means it's teachable, and if it's teachable, eventually a larger team with more resources will replicate it. Zakazov's publication record is actually in medical imaging (MICCAI 2020-2022), not in compression or NLP. The compression work appears to be more recent. Compare this to what I look for: the kind of knowledge that emerges from years of obsessive engagement with a specific problem, knowledge that lives outside the academic pipeline. These are smart researchers who pivoted toward a timely problem. That's different from founders who've been living inside a domain for a decade and can articulate non-obvious truths about it.

The leverage test fails in a way that's instructive. My best investments create new forms of leverage -- new categories of capability that didn't exist before. Replit gave non-programmers the leverage of code. AngelList gave founders the leverage of capital formation. Notion gave individuals the output of a team. Compresr gives developers a discount on their LLM bill. That's cost optimization, not leverage creation. Nobody uses Compresr and suddenly becomes capable of something they couldn't do before. They do the same thing, slightly cheaper. The API architecture scales in the software-default sense -- one server can handle many requests -- but there are no network effects, no data flywheel, no compounding moat. Each compression call is stateless and independent. This is a thin optimization layer sitting between two parties that both have incentives to eliminate it: LLM providers by lowering prices, and application developers by adopting free open-source alternatives like Microsoft's LLMLingua (5.8k GitHub stars, integrated into LangChain and LlamaIndex). The middleware layer that gets squeezed from both sides is not where I want to be.

The strongest bull case requires you to believe three things simultaneously: that absolute token spending will continue doubling even as unit costs fall, that agentic AI workflows will generate orders of magnitude more tokens per session, and that Compresr's proprietary compression will materially outperform freely available alternatives. There's real logic here -- agents consume 10-100x more tokens through conversation history, tool traces, and retrieval context, so even with falling prices, the absolute cost pressure could intensify. If the team's algorithms genuinely achieve better compression-to-quality ratios than LLMLingua, and if their managed API and Context Gateway create enough integration convenience to justify paying over self-hosting, there's a viable business. The Go-based proxy architecture sitting transparently between agents and model APIs is architecturally clean. But "viable business" is not what I invest for. I invest for asymmetric upside, and I don't see 1000x outcomes in a cost-optimization middleware layer competing against an open-source alternative from Microsoft Research and against the LLM providers' own caching features.

Four EPFL co-founders with a shared institutional background, all current students or recent graduates, no prior exits, enterprise experience limited to internships and research roles. I don't see red flags on integrity -- consistent academic focus, serious technical work. But I also don't see the kind of signal that makes me want to learn from these founders for a decade. The technology doesn't compound in a distinctive way: no published benchmarks proving their algorithms outperform, no proven data flywheel, and active academic research at EMNLP, ACL, and NAACL means the methodological frontier is advancing publicly. A well-funded competitor or a motivated open-source contributor could match their compression quality within months. This is a linear execution race in a market that may shrink as LLM pricing evolves. Pass.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 12/30 |
| Leverage Architecture and Scalability of the Model | 11/25 |
| Contrarian Positioning and Non-Consensus Timing | 5/20 |
| Founder Integrity and Long-Term Orientation | 8/15 |
| Technical Compounding and Defensibility Over Time | 4/10 |
| **Total** | **40/100** |

**Total Score: 40/100** (Pass)
