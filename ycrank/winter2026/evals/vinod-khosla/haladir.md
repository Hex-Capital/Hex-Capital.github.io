# Haladir -- Vinod Khosla Evaluation

The first thing I notice is the product focus ambiguity, and it concerns me more than any single risk factor in this dossier. The GitHub organization says "AI-Enabled Mainframe Modernization and Code Translation." The YC description says RL training infrastructure for verifiable domains. The public repos split between COBOL tools (MOBOL, Specula) and operations research benchmarks (OR-bench). When I look at a company and can't tell which problem they've committed to solving, that's not versatility -- that's a team that hasn't yet found conviction. The best outsider founders I've backed -- Pat Brown with meat, Peter Beck with rockets, Pradeep Sindhu with TCP/IP routing -- were possessed by a single problem. They didn't hedge across two product lines in two different markets selling to two different buyers. A pre-seed company with four people cannot simultaneously sell COBOL modernization to enterprises and RL training data to frontier AI labs. One of these paths needs to die for the other to matter.

Let me apply my core test: if Haladir fully succeeds, what changes in the world? They become a high-quality data vendor supplying operations research and formal verification training environments to AI labs. Anthropic's models get better at vehicle routing and scheduling. OpenAI's models improve at portfolio optimization. That's genuinely useful -- but it's picks-and-shovels infrastructure for someone else's transformation. The company that changes how logistics or manufacturing operates won't be Haladir; it'll be whoever deploys the models trained on their data. Haladir's ceiling in the success case is a valuable B2B supplier in a growing market. That's not a bad outcome, but it's not the kind of consequence magnitude that makes me ignore a 90% failure probability. When I backed Impossible Foods, success meant restructuring the entire global food system. When I backed Commonwealth Fusion, success meant replacing fossil fuels with limitless clean energy. Haladir's success means AI labs have slightly more diverse training data. The scale of ambition doesn't match the scale of the opportunity.

The strongest bull case, and I want to be honest about it, rests on timing. The RLVR paradigm shift -- DeepSeek-R1, OpenAI's o1 and o3 -- has created genuine, accelerating demand for diverse verifiable training domains. Anthropic reportedly plans to spend over a billion dollars on RL environments in the next year. Most competitors -- Applied Compute, Mechanize -- cluster around coding tasks. Operations research and formal verification are legitimately underserved niches with solver-computed ground truth that's mathematically provable. If you believe AI labs will pay a premium for domain diversity and Haladir can establish relationships before larger players expand into OR, the timing window is real. And the fact that Susa Ventures co-invested alongside YC suggests at least one sophisticated fund saw something here. For this to be a great investment, you'd need to believe that domain-specific OR expertise creates a durable data moat, that AI labs won't simply hire OR PhDs internally, and that four undergraduates can sell into the most technically demanding buyers on Earth faster than Applied Compute's ex-OpenAI founders or Mechanize's Anthropic-partnered team can expand their domain coverage. I find each of those assumptions individually plausible but the conjunction unlikely.

The technology itself doesn't give me a disruption signal. OR-Tools is open-source. TLA+ provers are open-source. The OR-bench repository demonstrates competence across ten problem types, which shows domain knowledge -- but domain knowledge in operations research lives in thousands of graduate programs worldwide. Any well-funded competitor who decides to expand into OR verification can hire that expertise. Applied Compute at $1.3 billion in valuation and $100 million raised could build this capability as a product extension. Scale AI at $29 billion could do it as a Tuesday afternoon project. The interdisciplinary barrier -- combining OR, formal verification, and RL training pipelines -- is real but not structural. It's an execution speed advantage, not a moat. The technology doesn't make an incumbent approach economically unviable; it packages existing solver outputs in a new format for a new buyer.

On the team: four undergraduate students with no documented professional experience, startup exits, or published research. I have nothing against young founders -- I backed many before they had gray hair. But my outsider thesis requires outsiders who bring first-principles insight that industry veterans lack. Being an undergraduate is not the same as being a contrarian outsider. Pat Brown's outsider advantage was that he understood protein chemistry at a level the food industry never would. Peter Beck's was that he approached rocket engineering from manufacturing first principles rather than aerospace convention. What first-principles insight do these founders bring to RL training infrastructure that experienced ML researchers at Applied Compute or Mechanize don't have? The dossier provides no evidence. Joseph Tso's ORCID and Princeton CS background suggest research orientation, which is relevant. Quan Huynh's applied math background maps to OR. But I see no signal of the learning rate or contrarian courage that would make me bet on this team against competitors with a hundred-fold capital advantage.

This is ultimately a company where the timing is strong but the consequence magnitude is modest, the technology is integrative rather than disruptive, and the team hasn't yet demonstrated why they'll win a market with well-funded incumbents. They're building a data supplier in a growing market -- and I don't invest in data suppliers. I invest in companies that make existing systems obsolete. Pass.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Consequence Magnitude If Successful | 10/30 |
| Founder Learning Rate and Contrarian Courage | 8/25 |
| Technology Disruption Potential vs. Incumbent Systems | 6/20 |
| Rate of Change and Timing Trajectory | 11/15 |
| Gene Pool Engineering and Team Construction | 4/10 |
| **Total** | **39/100** |

**Total Score: 39/100** (Pass)
