# Zatanna -- Naval Ravikant Evaluation

The first thing I look for is what the founders know that can't be taught. When I read this dossier, I see three technically capable people -- CS from Michigan, data science from Wisconsin, a CTO who built at a sports betting startup -- and zero documented connection to dental billing, insurance workflows, or healthcare administration. The dossier says it plainly: "No founder has publicly documented direct dental industry or healthcare billing experience." That's not necessarily disqualifying at pre-seed, but it means the core thesis -- codifying the "tribal knowledge" of experienced dental billing staff -- is being built by people who don't possess that tribal knowledge themselves. They're systematizing expertise they had to go learn, not expertise that emerged from years of obsessive engagement with the problem. Any three smart engineers who spent six months shadowing dental office managers would arrive at a similar product spec. That's the definition of teachable knowledge, which means it's eventually going to be replicated by a computer -- or by the next funded team that tries.

The leverage architecture here is real but thin. Automating insurance verification, claims filing, and appeals for dental practices is labor replacement -- it removes a person from a workflow. That's useful, but it's not the same as creating a new form of leverage that didn't exist before. When I backed Replit, the thesis was that people who could never have written code before could now build software. That's capability creation, not task elimination. Zatanna makes an existing process cheaper. The dental practice doesn't gain a new capability; it just spends less on the capability it already had. The "continuously learning" angle and the 30,000 EOB dataset gesture toward something more interesting -- a knowledge infrastructure that compounds with each practice onboarded -- but 30,000 EOBs is a modest dataset, and the compounding mechanism hasn't been demonstrated. Stack Overflow became a $1.8B acquisition because each question and answer made the knowledge graph irreplaceable. Whether Zatanna's EOB corpus can achieve similar network-scale compounding in a narrower domain remains speculative.

The timing is consensus, not contrarian. "AI agents for [industry vertical]" is the single hottest category in venture right now. Every pitch deck in 2026 describes an AI agent that automates some domain-specific workflow. Trust AI already has 8,000 dentists on its platform and $6.5 million in seed funding. DentalRobot has been training on dental-specific workflows for five years. Overjet has $133 million and a $550 million valuation in adjacent dental AI. Nobody smart is saying "dental admin automation is impossible" or "AI can't handle insurance claims." The crowd is optimistic, not gloomy. When I invested in Uber at a $4 million valuation, ride-sharing was literally illegal. When I invested in Bitcoin in 2014, serious people called it a Ponzi scheme. The asymmetric upside comes from being right when the consensus is wrong. Here, the consensus is right -- this is a real problem, and AI will solve it. The question is only which team wins, and Zatanna is entering with less domain knowledge and less data than its most direct competitors.

The strongest bull case requires believing three things simultaneously: that the founders' technical sophistication (Coinbase, Amazon, published ML research) gives them an execution edge over more domain-experienced competitors; that the EOB dataset will compound into a genuine moat faster than DentalRobot's five-year head start; and that dental is a wedge into broader healthcare billing where the real leverage emerges at scale. If all three are true, you get a picks-and-shovels infrastructure play for healthcare admin -- billing infrastructure that sits underneath existing practice management systems rather than replacing them, which is a more defensible architectural position than Trust AI's PMS-replacement approach. Jared Friedman as YC partner lends credibility to the team's ability to execute. And the technical founding team -- all three appear to be builders, not MBA-types outsourcing development -- satisfies my baseline requirement. But the bull case demands multiple things to break right in a market where better-funded, more domain-experienced competitors are already running.

I'd pass. The pattern here maps too closely to what I avoid: smart generalists identifying an obvious gap in a vertical, building standard automation with an LLM layer, in a market where the timing is consensus and the competitors have deeper roots. The founders are technically competent, but competence is table stakes. I want founders who know something about dental billing that would surprise a veteran billing manager -- who've discovered some non-obvious truth about how insurance adjudication actually works that their competitors haven't seen. Nothing in this dossier suggests that knowledge exists on this team.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 5/30 |
| Leverage Architecture and Scalability of the Model | 11/25 |
| Contrarian Positioning and Non-Consensus Timing | 6/20 |
| Founder Integrity and Long-Term Orientation | 8/15 |
| Technical Compounding and Defensibility Over Time | 5/10 |
| **Total** | **35/100** |

**Total Score: 35/100** (Pass)
