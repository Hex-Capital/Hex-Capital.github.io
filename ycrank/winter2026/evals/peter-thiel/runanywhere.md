# RunAnywhere -- Peter Thiel Evaluation

The most revealing fact about RunAnywhere is its own positioning: "Ollama but for mobile, with a cloud fallback." This is not how a company built on a secret describes itself. This is how a company built on imitation describes itself. Ollama exists. Mobile exists. The conjunction is not a secret -- it is an engineering task. When a founder's pitch is reducible to "X but for Y," the company is definitionally going from one to n, not from zero to one. The entire framing concedes that someone else had the original insight and that this team is extending it to an adjacent surface area. I have never made a significant investment in a company whose thesis was that an existing open-source tool should also work on phones.

The deeper problem is competitive structure, and here the Girardian analysis is damning. Meta has ExecuTorch, which reached 1.0 GA in October 2025 and already runs on-device AI for billions of users across Instagram, WhatsApp, Quest, and Ray-Ban glasses. Google has MediaPipe with LLM inference APIs. Apple has MLX, optimized for the silicon they control. These are not hypothetical future competitors -- they are shipping production-grade tools today, for free, backed by engineering organizations that dwarf anything a two-person startup can assemble. And then there is Nexa AI: same thesis, two-year head start, $3.4 million in revenue, thirty-one engineers, and real funding. RunAnywhere is entering a market where at least four serious players are already doing approximately the same thing. This is the opposite of monopoly. This is a market defined by mimetic convergence -- every participant has independently concluded that on-device AI needs cross-platform tooling, and they are all building it simultaneously. When the secret is shared by Meta, Google, Apple, a funded startup, and a pre-seed YC company, it is not a secret. It is a consensus.

The bull case rests on the control plane -- the commercial layer for OTA model delivery, policy-based routing, A/B testing, and fleet analytics. The argument is that Big Tech companies give away inference runtimes but won't build paid fleet management tools because it would cannibalize their cloud inference revenue. This is the kind of business model misalignment thesis that sounds strategically clever in a pitch but dissolves under scrutiny. Google gives away Android, Chrome, Kubernetes, and TensorFlow -- not because they monetize those tools directly, but because ecosystem control drives developer lock-in that monetizes elsewhere. If on-device AI fleet management becomes important enough that enterprises will pay for it, Google and Meta will build it into their existing developer platforms and give it away, because their incentive is ecosystem capture, not SaaS revenue. The structural barrier is soft, and it erodes precisely when the opportunity becomes large enough to matter. HashiCorp and GitLab built successful open-core businesses, but they operated in categories where no platform company was giving away a comparable foundation. RunAnywhere is trying to sell a premium layer on top of a space where the foundations are being constructed by the three most powerful technology companies on earth.

The founders are competent software engineers -- Sanchit Monga at Intuit, Shubham Malhotra at AWS -- but the profile is infrastructure-experienced engineers executing on an obvious market observation, not singular technical visionaries with a definite plan for how the world changes. There is no evidence of deep ML systems research, no proprietary inference technology, no architectural insight that Meta's or Google's teams lack. The 9,000 GitHub stars are a legitimate developer awareness signal, but star counts measure curiosity, not commitment, and converting open-source interest into enterprise revenue is a challenge that has defeated far better-capitalized developer tools companies. The SDK itself is an abstraction layer wrapping existing runtimes -- GGUF, ONNX, CoreML, MLX -- which means the core technology is integration engineering, not discontinuous innovation. A competent team at any well-funded DevTools company could replicate this surface area in a quarter.

What would have to be true for this to be a great investment? On-device AI would need to become critical infrastructure for every mobile application -- not a feature, but a requirement -- and the fragmentation across runtimes and platforms would need to persist for years because no incumbent builds a satisfactory cross-platform solution. The control plane would need to become operationally indispensable, creating switching costs comparable to what Palantir achieves through deep government integration. And RunAnywhere would need to build that position before Nexa AI or any Big Tech extension captures it, with a two-person team against a thirty-one-person competitor with revenue and a two-year lead. Each of these conditions individually is plausible. Their conjunction is not a bet I would make with my own money. The power law demands that I invest only where success, if it comes, is extreme. Here, even the upside scenario produces a solid infrastructure business in a competitive market -- not a monopoly.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Contrarian Secret and Monopoly Potential | 7/35 |
| Founder Conviction and Definite Vision | 8/25 |
| Technological Discontinuity and 10x Superiority | 6/20 |
| Durability and Last-Mover Defensibility | 3/10 |
| Small-Market Dominance with Expansion Path | 4/10 |
| **Total** | **28/100** |

**Total Score: 28/100** (Pass)
