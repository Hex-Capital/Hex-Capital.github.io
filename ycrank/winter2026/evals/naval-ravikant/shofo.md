# Shofo -- Naval Ravikant Evaluation

The first thing I notice is the leverage architecture, or rather its absence. Shofo describes a "human-in-the-loop pipeline" that cleans, segments, and labels video data. That phrase -- human-in-the-loop -- is the opposite of what I look for. Every dataset delivery requires proportional human effort. Every custom query ("50k cooking videos featuring hand-object interactions") triggers a labor-intensive fulfillment cycle. The framing is "Common Crawl for Video," but Common Crawl works because web crawling is automated, legal, and permissionless. Shofo's version requires scraping platforms that actively resist it, then routing the output through human annotators. This isn't code leverage multiplied across users. It's a services business with a data index sitting on top. Scale AI built a $29B company on this model, but Scale AI also has 6,000+ employees and $870M in revenue -- which proves the point that labeling scales with headcount, not with code.

The specific knowledge question is where this falls apart for me. What do these founders know that can't be taught? Bryan Hong interned at MongoDB and Adobe. Misra dropped out of UCSB to build Correkt, a consumer AI search engine. Braga researches NLP -- language models, not computer vision. Dishman did economics and worked at AWS. They're smart. They can build and ship -- 40,000 users on Correkt as undergrads demonstrates energy and execution. But the pivot from consumer AI search to video data infrastructure for AI labs is a market-driven move, not a knowledge-driven one. The through-line is "we indexed things before." That's operational experience, not the kind of deep domain insight that takes years to accumulate and can't be replicated by a well-funded competitor in six months. Nobody on this team has worked inside an AI lab struggling with video data pipelines. Nobody has a background in computer vision research. Nobody has operated at Scale AI or Labelbox and seen the annotation workflow from the inside. They identified an opportunity from the outside and pivoted into it. That's not specific knowledge -- that's pattern recognition applied to a trending market.

The bull case rests on timing and market structure, and it's worth taking seriously. Meta's 49% stake in Scale AI genuinely compromised the dominant platform's neutrality. Google, OpenAI, and Anthropic need alternatives. Video training data demand is growing at 32% CAGR. Multimodal models -- Sora-class video generation, embodied AI, autonomous vehicles -- all require exactly the kind of annotated video Shofo promises to deliver. If Shofo can build the actual largest index of short-form video and establish relationships with two or three major labs during this window of Scale AI disruption, the accumulated annotations and client feedback loops could create a real data moat. The "Common Crawl for Video" positioning is directionally correct -- Common Crawl became critical infrastructure for LLM training, and no equivalent exists for video. If someone builds that, it's genuinely valuable infrastructure.

But I keep returning to two structural problems. First, the legal foundation. Shofo's index draws from TikTok, Instagram, LinkedIn, and X. These platforms actively restrict scraping. The content belongs to creators who haven't consented to having their videos segmented and relabeled for commercial AI training. We're in the middle of a wave of lawsuits over exactly this -- Getty v. Stability AI, the New York Times v. OpenAI. A company whose core asset depends on scraping platforms that don't want to be scraped, using content whose creators didn't consent, is building on sand. Common Crawl works on the public web. Social media video is not the public web. Second, the customer concentration risk is severe -- the buyer universe is essentially five to ten well-funded AI labs, each of which has the engineering resources to build internal video pipelines if Shofo's pricing doesn't dramatically undercut the build-versus-buy calculus. When your entire TAM is a handful of organizations that are collectively the most technically sophisticated companies in human history, your moat needs to be very deep.

The pivot from Correkt also gives me pause. Not because pivoting is wrong -- some of the best companies pivoted. But when a team abandons a product with 40,000 users to enter an entirely different market, I want to understand whether the new direction comes from deep conviction about the problem or from pattern-matching to what's hot. "AI labs need data" is the most consensus view in Silicon Valley right now. There's nothing contrarian about this positioning. Everyone from Y Combinator to McKinsey agrees that training data is a bottleneck. The contrarian bet would be that training data stops mattering -- that synthetic data or self-supervised learning eliminates the need for human-labeled datasets entirely. Shofo is betting the opposite: that human-curated, platform-scraped video data becomes more valuable over time. That's a defensible position, but it's not a non-consensus one.

I respect the team's energy and their ability to ship. Building anything to 40,000 users as undergraduates shows real drive. But energy without specific knowledge in a consensus market with significant legal and structural headwinds -- that's not where I put my money. I want founders who know something the market doesn't, building leverage that didn't exist before, at a time when smart people think they're wrong. Shofo has none of these three.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 7/30 |
| Leverage Architecture and Scalability of the Model | 10/25 |
| Contrarian Positioning and Non-Consensus Timing | 9/20 |
| Founder Integrity and Long-Term Orientation | 8/15 |
| Technical Compounding and Defensibility Over Time | 5/10 |
| **Total** | **39/100** |

**Total Score: 39/100** (Pass)
