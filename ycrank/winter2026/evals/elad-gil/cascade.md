# Cascade -- Elad Gil Evaluation

The first thing I notice about Cascade is the competitive landscape, and it tells me something important about the market structure. WitnessAI has raised $58M. Fiddler AI has raised roughly $100M. CalypsoAI was acquired by F5 for $180M. Guardrails AI and Invariant Labs have open-source frameworks already in developer hands. Meta shipped LlamaFirewall as open source. When I see a pre-seed company entering a market where incumbents have collectively deployed over $300M in capital and multiple open-source alternatives already exist, the question isn't "is this market real?" -- the question is "what structural advantage does this team have that $300M hasn't already bought?" I don't see an answer in the dossier.

The market structural moment here is genuine but entirely consensus. Gartner identifies "AI Security Platforms" as a top strategic technology trend for 2026. When Gartner is naming your category as a trend, you are not in a non-obvious market -- you are in the most obvious market possible. Compare this to when I invested in PagerDuty: nobody at Gartner was writing reports about "operations alerting infrastructure" as a strategic trend. The market looked boring and niche. That's where the asymmetric returns lived. Cascade is entering a market where every enterprise CIO and every security vendor already knows autonomous agent safety matters. The TAM slide writes itself -- $49B growing to $160B. That's exactly the kind of static market sizing that makes me cautious, because when everyone can see the same number, the returns get competed away. The "why now" is "AI agents are being deployed," which is true but applies identically to every company in this category. There's no unique structural inflection that Cascade sees and others don't.

The more concerning structural issue is commoditization from above. In cloud security, independent vendors like CrowdStrike thrived because the threat model was external -- attackers vs. infrastructure -- and the cloud provider couldn't fully internalize the security function without a conflict. In agentic AI safety, the threat IS the agent's own behavior, and the platform provider (OpenAI, Anthropic, Google) has the deepest understanding of their agent's failure modes. These companies have existential incentives to make their agents safe -- it's not a nice-to-have feature, it's table stakes for enterprise adoption. When the platform provider is also the most natural safety provider, the independent infrastructure layer gets squeezed. Cascade's "self-improving models" differentiation assumes their models will learn faster than the platform providers' own safety systems, which requires more production deployment data than the platforms themselves have. That's a difficult argument to sustain.

The bull case would require several things to be true simultaneously. First, that enterprise agent deployments become genuinely multi-platform -- companies running agents from OpenAI, Anthropic, Google, and open-source models, needing a unified safety layer across all of them. Second, that platform providers face structural conflicts in auditing their own agents' safety, creating demand for independent verification. Third, that Cascade's "self-improving" models create a data flywheel where production failure data compounds into a moat that open-source alternatives and well-funded competitors can't replicate. And fourth, that the founders' research credentials -- particularly AlSayyad's work with Dawn Song, who is genuinely top-tier in AI security -- translate into technical differentiation that survives contact with the market. If all four of these are true, this could be a Samsara-style bet where infrastructure monitoring for a new category of autonomous systems becomes deeply embedded. But that's four conditions, which starts to look like a multi-miracle problem.

The founders have relevant domain backgrounds -- BAIR research on agentic safety and graph reasoning (AlSayyad), production monitoring infrastructure at Netflix and Amazon (Demirhan). These are credible credentials for this specific problem. But I see no shipped product (the website returned only CSS framework code), no traction signals, no distribution strategy, and no evidence of the kind of rapid execution velocity that would suggest they're building ahead of the competition rather than behind it. At pre-seed, I don't penalize for absent traction -- but in a market with $300M+ of competitor funding already deployed, I need to see either exceptional execution speed or a fundamentally different approach. "Self-improving models" is a product claim, not a distribution strategy. The founders haven't articulated how they become a channel rather than a point product, and in a market this competitive, product quality alone won't determine the winner. Distribution will.

I'm passing. The market is real but consensus-hot, the competitive dynamics favor incumbents and platform providers, and I don't see the structural advantage that would let a two-person pre-seed team with no visible product outrun companies that have raised 100-200x more capital. This is a market where being right about the category isn't enough -- you need to be positioned at a structural advantage that compounds. I'd want to see evidence of a distribution wedge, a specific enterprise deployment generating proprietary data, or a technical approach that is architecturally distinct from what Fiddler, WitnessAI, and the platform providers are building. Without that, this is a well-credentialed team entering a crowded race late.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Non-Obvious Market at Structural Inflection | 10/35 |
| Product-to-Distribution Trajectory | 6/25 |
| Single-Miracle Operational Clarity | 5/15 |
| Founder Execution Velocity | 6/15 |
| Technology Cycle Positioning | 6/10 |
| **Total** | **33/100** |

**Total Score: 33/100** (Pass)
