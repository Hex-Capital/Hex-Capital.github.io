# Ishiki Labs -- Cyan Banister Evaluation

Here's what strikes me first about Ishiki Labs: this is a consensus bet dressed in research credentials. Meeting AI is one of the most well-funded, widely-competed categories in enterprise software right now. Otter.ai just crossed $100M ARR. Fireflies hit a billion-dollar valuation. Granola raised $67 million. Read.ai pulled in $81 million. When I look at a deal and every major VC has already placed bets in the category, I feel the opposite of excitement -- I feel like the weirdness has been priced out. The most promising companies I've backed share a few characteristics: they're not popular, they're difficult to assess. Ishiki Labs is easy to assess -- it's a meeting copilot with a social awareness layer -- and it sits in one of the most popular AI application categories on earth. That mismatch with how I invest is hard to get past.

If I could sit down with Amit and Robert and ask them my opening question -- tell me your story, not the business, how did you get here -- I suspect I'd hear a story about brilliant academic achievement and elite corporate experience. Amit's trajectory from IIT Gandhinagar (Director's Silver Medal, finished early) through a Purdue PhD with 20+ publications at CVPR and NeurIPS to Meta's LLaMA team is genuinely impressive. Robert spent four years at Meta building the orchestration layer for multimodal assistants on smart glasses, plus a stint at Citadel Securities. These are exceptional technical resumes. But when I listen for what I call the biographical thread -- the specific hardship or personal stake that makes this founder unable to walk away from this particular problem -- I don't find it in what's available to me. They built similar technology at Meta and decided to commercialize it. That's a reasonable founding story, but it's the story of researchers spinning out a capability, not outsiders burning to solve a problem the world told them was impossible.

The bull case deserves a full hearing, because the founder-market fit on the technical dimension is as strong as I've seen at pre-seed. These two didn't just work adjacent to the problem -- they literally built always-on, socially-aware multimodal AI for Meta's Orion smart glasses, which is almost exactly what Fern is attempting for meetings. If anyone on the planet can make an AI that understands conversational turn-taking and knows when to shut up, it's probably this team. And the real upside scenario isn't meetings at all -- it's that "social awareness" becomes a foundational layer for all AI agents, from AR glasses to earbuds to robots, and Ishiki Labs owns the research frontier. If meetings are just the beachhead and the real play is building the social cognition layer that every AI assistant eventually needs, that's a much bigger and weirder bet than the dossier suggests. But that story isn't the one they're telling right now, and I have to evaluate what's in front of me.

What I don't see -- and this is where my lens diverges from a typical analyst -- is any mechanism for creating economic access or making an invisible system visible. When I backed Uber, yes it was a logistics company, but it also created income for hundreds of thousands of drivers who needed flexible work. Affirm made hidden credit card fees transparent. Flock Safety brought public safety data to communities that had none. Ishiki Labs makes meetings more efficient for salespeople, consultants, and executives -- people who are already well-served by the economy. That's a real product solving a real annoyance, but it doesn't create the kind of positive-sum economic outcome that I orient my portfolio around.

The defensibility question concerns me. "Knowing when not to speak" is described in the dossier as a single feature dimension, and that framing is accurate. When I think about the companies in my portfolio that built real moats -- Flock Safety's camera network where every node makes the whole system more valuable, Carta's position as the system of record for cap tables -- those are structural advantages that compound over time. A social awareness feature, however technically impressive, is something Microsoft could ship as a Copilot update or Zoom could add as a toggle. The potential data moat from real meeting interactions could become meaningful, but it doesn't exist yet, and incumbents with 20-25 million users have a massive head start on conversational training data.

On co-founder dynamics, I'll note the positive: Amit and Robert worked at Meta on overlapping technology (smart glasses multimodal AI), which means they've seen each other operate in a professional context and chose to build together with shared technical understanding. That's better than strangers meeting at a startup weekend. But I don't have visibility into how they handle real disagreement or crisis -- and after what happened with HQ Trivia, where the product and timing were perfect but the 50/50 co-founder split destroyed everything, I always want to understand how two people fight before I bet on them building together for a decade.

I respect these founders deeply as technologists. If they were applying their expertise to something the world hadn't figured out how to fund yet -- something that made other investors uncomfortable, something in a stigmatized or overlooked space -- my reaction would be very different. But they're entering the most consensus AI category with narrow differentiation against entrenched, well-funded incumbents, and that's a pattern I've learned to walk away from. The best ideas I've funded never looked obvious at the start. This one looks obvious to everyone.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Founder Biographical Grit and Personal Stake | 10/30 |
| Anti-Consensus Conviction and Weird Factor | 5/25 |
| Economic Access and Real-World Impact | 4/20 |
| Navigating Complexity in Hard Spaces | 7/15 |
| Co-Founder Alignment and Team Resilience | 6/10 |
| **Total** | **32/100** |

**Total Score: 32/100** (Pass)
