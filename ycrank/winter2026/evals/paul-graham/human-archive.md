# Human Archive -- Paul Graham Evaluation

The first thing I notice about Human Archive is that everyone else noticed the same thing they did. Scale AI launched its Physical AI division in September 2025, collecting over a thousand hours of demonstration data per day. Sensei came through YC two batches ago attacking the same problem. Cortex AI came through one batch ago. When I see four companies in the same narrow category within eighteen months -- one of them a $29 billion incumbent -- that's not schlep blindness. That's a gold rush. The defining characteristic of schlep blindness is that smart people unconsciously avoid the problem. Nobody is unconsciously avoiding "robotics needs training data." It's on the cover of every AI newsletter. Stripe worked because thousands of programmers knew payments were broken but nobody wanted to deal with the banks. Here, everyone wants to deal with the data. Scale AI wants to deal with it. The question isn't whether the problem is real -- it clearly is -- but whether these particular founders have any structural reason to be the ones who solve it.

When I ask how the founders found this problem, the dossier has no answer. Samay Maini worked at Contoro Robotics, which provides the only thread of domain connection, but there's no story of personally hitting the data wall while building a robot, no "I was training a manipulation model and couldn't find aligned multimodal data anywhere." The other founders' backgrounds are in Coinbase product management, mango delivery, and agricultural fungicides. These are interesting people, but the connection to robotics data feels constructed after the fact. Raj and Shloke Patel's description as having "thought deeply about the fine line between biomimicry and its application to humanoid systems" sounds like language that was crafted for a company page, not something that grew out of years of living with a problem. The test I apply is simple: would these founders have built this if they hadn't decided to start a startup? Nothing in the evidence suggests yes.

The strongest argument for Human Archive is the operational willingness. The team moved to Asia to deploy custom data-collection hardware across residential and manufacturing environments. They're hiring videographers and operations managers in India. This is genuinely uncomfortable work that most technical founders would avoid -- they'd rather stay in San Francisco and write software. The Patel brothers running a produce delivery operation during the pandemic (16,000 mangoes) and a fungicide hardware startup suggest a comfort with messy, physical operations that might translate here. If robotics training data turns out to be an operations problem rather than a technology problem -- if the company that wins is simply the one willing to deploy hardware into a thousand kitchens and factories and process the output -- then this team's bias toward doing the unglamorous physical work is an asset. And their India operations could provide a meaningful cost advantage over Scale AI's contractor model.

But I don't think that's enough. The bull case requires believing that (1) real-world data remains irreplaceable as simulation improves, (2) custom hardware provides meaningfully better data than standardized equipment operated by contractors, (3) four undergraduate dropouts can outexecute Scale AI on operational scale, and (4) the team can secure contracts from a tiny buyer set of frontier labs before those labs build their own collection infrastructure or choose an established vendor. Each of these is plausible individually. Together they require too many things to go right. When Skild AI is generating a thousand times more data points through simulation, the burden is on real-world data providers to prove the qualitative difference matters -- and that's a research question nobody has answered yet. Meanwhile, the buyer set is dangerously narrow. There are maybe a dozen frontier labs that would buy this data. That's not a market where a scrappy startup has natural advantages.

The absence of any traction signal -- no revenue, no named customers, no dataset size, no LOIs -- means I'm evaluating this entirely on team and idea. The team is young and energetic but lacks the deep domain expertise that would give me confidence they understand the nuances of what robotics researchers actually need. Samay's ML background is relevant but thin. Nobody on this team has published robotics research, built a robot, or worked at one of the frontier labs they're selling to. When your customers are some of the most technically sophisticated organizations in the world, you need credibility that comes from having been one of them.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Organic Problem Discovery and Schlep Willingness | 7/30 |
| Relentlessly Resourceful Founders | 11/25 |
| Evidence of Wanting: Demonstrated User Pull | 5/20 |
| Technical Hacker Founders Who Build | 6/15 |
| Growth Trajectory and Default Alive Economics | 4/10 |
| **Total** | **33/100** |

**Total Score: 33/100** (Pass)
