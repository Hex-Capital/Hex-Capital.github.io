# Traverse -- Elad Gil Evaluation

The first thing I notice about Traverse is a pattern I've written about as an end-of-cycle signal: founders pivoting into whatever category is attracting capital. Traverse was "Clice AI" -- personal AI agents for team coordination -- until very recently, when it became an RL environments company selling to frontier labs. The domain clice.ai now redirects to traverse.so. This is not inherently disqualifying -- pivots can be intelligent -- but when the pivot is into a market with 35+ entrants, where Scale AI ($29B valuation, $870M revenue) and Surge AI ($1.2B revenue) are already expanding aggressively, and where Mechanize (backed by Nat Friedman and Daniel Gross) is already contracted with Anthropic, the pivot pattern looks less like insight and more like chasing the funding environment. When I wrote about late-cycle capital flows, this is one of the structures I was describing: founders entering a sector they recently discovered because the buyer appetite is visible.

The structural moment for RL environments is real -- I'll give them that. OpenAI's o1 proved that reinforcement learning can meaningfully extend model capabilities beyond pre-training, and labs shifted from static RLHF datasets to dynamic training environments over 2024-2025. Anthropic is reportedly spending tens of millions annually on RL environments with projected 3-5x growth. This is a genuine market that barely existed 18 months ago. But here's what separates this from the non-obvious markets where I've found the best returns: this market is entirely consensus. Wing VC published analysis mapping the space. Thirty-five-plus companies have entered. Every AI-focused fund is looking at RL environment plays. When I invested in PagerDuty, the market triggered dismissive reactions -- "operations alerting, who cares?" When I looked at Gusto, investors said payroll was boring and solved. The RL environment market for frontier labs triggers the opposite reaction: everyone sees the opportunity, which means competition is structural, not incidental.

The non-deterministic verifier angle is the most intellectually interesting element. Traverse claims the gap between deterministic RL (math, coding -- where verifiers can objectively score outputs) and non-deterministic RL (medicine, law, taste-dependent work -- where "correct" is subjective) is large enough to be a separate market. This is a real observation. As labs exhaust capability gains from training on problems with clear right answers, the next scaling lever requires training on judgment-dependent tasks. If Traverse could build genuinely superior verifiers for a specific non-deterministic domain, the expertise might compound into a learning-curve advantage. That's the bull case: the 35 competitors are mostly building for deterministic environments, and non-deterministic verification is a fundamentally different capability that requires different processes and domain expertise. If that's true, the addressable competitive set shrinks from 35 to maybe 3-5. But here's where it falls apart: building a credible verifier for legal reasoning or medical decision-making requires deep domain expertise that neither founder possesses. Both are CS undergrads -- Lance from Kalshi (prediction markets), Zachary from Mercor and Uber AI. No clinical experience, no legal background, no published research in the target domains. Scale AI can hire domain experts at scale. A two-person team cannot.

The customer concentration problem is what I'd flag as structurally disqualifying for the current positioning. The total buyer set for third-party RL environments is perhaps 5-7 frontier labs globally: Anthropic, OpenAI, Google DeepMind, Meta, xAI, Mistral, and a handful of well-funded AI startups. When your entire TAM is a handful of organizations, you don't have a market -- you have a set of procurement relationships. And in that game, the distribution advantage goes to companies with existing lab relationships (Scale AI has been supplying data to these labs for years) and founders with elite AI-lab networks (Nat Friedman co-ran GitHub, where half these labs' researchers contributed). I don't see how Traverse breaks into these accounts. The product-to-distribution trajectory is also limited: contracted RL environments for a few labs is fundamentally a services model. There is no obvious second product, no platform expansion, no distribution channel being built. Stripe's payments API became a developer relationship that distributed Atlas, Billing, and Treasury. What does Traverse distribute beyond more custom environments? More domains of the same thing is linear scaling, not compounding distribution.

On execution, Zachary Yu shows some velocity signals -- vibeornot.com attracted 25K users in 24 hours, he organized a hackathon with 800+ applicants -- which suggests he can ship and iterate. Lance Yan's ML background at wat.ai is relevant to the technical work. But neither founder has demonstrated anything under the Traverse brand. Zero public traction, zero disclosed revenue, one GitHub repo that's a take-home recruiting assignment. At pre-seed this is normal and not inherently damning, but combined with the pivot recency and the competitive intensity of the market, the absence of any early signal -- no named lab conversations, no LOIs, no prototype demonstrations -- makes this a bet on positioning rather than on demonstrated capability.

This is a Pass. The market timing is real but consensus, the competitive landscape is brutal, the customer concentration creates structural fragility, and the pivot pattern combined with the founders' lack of domain expertise in the non-deterministic verticals they're targeting (medicine, law) means the claimed differentiation remains an assertion rather than a demonstrated capability. I need to see that a company is building something that compounds -- not positioning itself in a space where incumbents with 1000x the resources are already expanding.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Non-Obvious Market at Structural Inflection | 12/35 |
| Product-to-Distribution Trajectory | 6/25 |
| Single-Miracle Operational Clarity | 5/15 |
| Founder Execution Velocity | 6/15 |
| Technology Cycle Positioning | 6/10 |
| **Total** | **35/100** |

**Total Score: 35/100** (Pass)
