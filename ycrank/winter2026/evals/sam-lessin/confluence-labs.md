# Confluence Labs -- Sam Lessin Evaluation

Confluence Labs open-sourced the one thing that makes them interesting. Their ARC-AGI-2 solver -- 97.9% accuracy on a benchmark where frontier commercial systems topped out around 37.6% -- is MIT-licensed and sitting on GitHub with 73 stars. As a technical flex, it's remarkable. As a business decision, it's the kind of move that signals a team thinking like researchers, not founders. You've taken your primary credibility signal and turned it into a public good. Now Poetiq, which just raised $45.8 million from people with deeper pockets than me, can study your methodology, improve on it, and ship a commercial product while you're still looking for "collaborators." The solver isn't a moat -- it's a resume line item.

Here's where my framework snaps into focus on this one. My first question is always: sane person, insane idea? With Confluence Labs, I see the opposite configuration. The idea -- using AI to design experiments in data-sparse scientific domains -- is one of the most consensus plays in the current market. Lila Sciences raised $200 million at seed. CuspAI took $100 million in a Series A. Periodic Labs raised $300 million. This isn't contrarian; it's a stampede. The founders, meanwhile, are a college dropout who's built MVPs for other startups and a college student with competitive math credentials and psych research experience at Vassar. Neither has worked inside a pharma R&D organization, a materials lab, or any of the enterprise environments they're targeting. When I backed Solana, Anatoly brought Qualcomm systems engineering expertise to a blockchain architecture problem -- the credibility was specific to the challenge. Here, the technical talent is evident but generic. The ARC-AGI-2 result proves they can make LLMs solve abstract grid puzzles efficiently, not that they understand the workflow of a Merck scientist deciding which compounds to synthesize next.

The structural problem runs deeper than founder-market fit. My entire investment framework in 2026 starts with one question: does this business get stronger or weaker as software gets cheaper? Confluence Labs is a company whose existence depends entirely on AI capabilities they don't control. They're layering program synthesis techniques on top of frontier LLMs built by OpenAI, Anthropic, and Google. If the next model release natively handles sample-efficient scientific reasoning -- which is exactly the direction these labs are heading -- Confluence Labs becomes a feature, not a company. This is the "LLM wrapper" problem wearing a lab coat. The cherry-on-top test is simple: would this business be good if AI didn't exist? The answer is that this business literally cannot exist without AI. It IS the AI layer. That's the category I avoid with the most conviction.

The bull case deserves serious engagement because the technical signal is genuinely unusual. Two people with minimal resources outperforming every well-funded lab on a reasoning benchmark is the kind of disproportionate output that occasionally signals a paradigm insight. If their "data-efficient modeling" approach -- combining LLMs with discrete program search -- transfers from synthetic benchmarks to real-world experimental domains, the economic value is enormous. A single pharma compound costs millions to test physically. Even marginal improvements in experiment selection could save tens of millions per drug program. And the truly non-consensus version of this bet isn't "AI for science" (which is mainstream) but rather "two young hackers with no domain credentials can outperform twelve-year-old domain-specific platforms like Citrine Informatics by being fundamentally better at learning efficiency." That IS an insane idea. The problem is I need the "sane" counterweight -- verifiable domain expertise, a pilot customer who validates the approach works outside synthetic benchmarks, some evidence that the ARC-AGI-2 methodology transfers to chemistry or biology. None of that exists yet. It's pure extrapolation from a benchmark score to a multi-vertical enterprise product, and that gap has killed more technically impressive teams than I can count.

There's no new primitive being created here. Confluence Labs is an application built on someone else's protocol layer -- frontier LLMs they access via API. They haven't established a new standard, data format, or infrastructure layer that other companies build on. Compare this to Aleo building zero-knowledge privacy as cryptographic infrastructure, or Helium creating a decentralized wireless protocol. Those are primitives that compound through ecosystem adoption. Confluence Labs, even in its best-case scenario, would be a tool that R&D teams use -- valuable, perhaps, but without the network effects and winner-take-most dynamics that produce venture-scale returns from seed. The ceiling is a successful enterprise software company, not a platform that reshapes how science gets done.

I'm passing. The raw technical talent is real, but I'd rather fund a company where that talent is applied to building infrastructure that other people depend on, in a market where most investors think the idea is crazy, with a moat that strengthens as AI gets cheaper. Confluence Labs is talented people chasing a consensus opportunity with no structural defensibility, no domain credibility in their target markets, no product, no revenue, and an open-sourced methodology that any well-funded competitor can replicate. I'd want to see a working pilot with a real pharma or materials customer, evidence that the approach transfers beyond benchmarks, and a proprietary data or workflow integration strategy that creates switching costs before this becomes my kind of bet.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| "Sane Person, Insane Idea" Calibration | 8/30 |
| AI-Resistant Structural Moat | 3/25 |
| New Primitive or Protocol Position | 5/20 |
| Narrative Magnitude and Infinity Optionality | 8/15 |
| Real Revenue or Asset Cushion | 2/10 |
| **Total** | **26/100** |

**Total Score: 26/100** (Pass)
