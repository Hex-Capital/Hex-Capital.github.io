# 1code (21st.dev) -- Naval Ravikant Evaluation

The structural problem here is that 1code is not infrastructure -- it's a skin. My portfolio leans heavily toward picks-and-shovels plays: Alchemy sits beneath every DeFi app, Stack Overflow sits beneath every developer's workflow, Replit sits beneath the act of programming itself. 1code sits *on top* of Claude Code and OpenAI Codex, adding a visual layer and some workflow automation. That's the opposite architectural position. When you build beneath the stack, you become load-bearing -- ripping you out is expensive. When you build above it, you're one product update away from irrelevance. OpenAI shipped its own Codex app with multi-agent orchestration in February 2026. Anthropic could add a native Claude Code UI tomorrow. The company's entire value proposition lives in a gap that the platform providers have every incentive and capability to close. This isn't a bet on a new form of leverage -- it's a bet on a temporary absence of polish in someone else's product.

The specific knowledge question is where this falls apart for me. Nine products in ten months. That number tells me something important -- and it's not what the founders think it tells me. It tells me these are builders who love building. That's energy. But energy without specific knowledge is just speed in an unspecified direction. What does Serafim know about multi-agent orchestration that can't be replicated by any strong engineer who's spent three months using Claude Code? His background is crypto bridges and micro-acquisitions. What does Sergey know? He's a genuinely talented full-stack engineer -- Deel, hackathon wins, products with real users. But his knowledge is about shipping software fast, not about the deep structural problems of coordinating autonomous coding agents. The gap between "I used this tool and the UX frustrated me" and "I've spent years understanding why agent coordination is fundamentally hard" is the gap between a feature request and a company. Anyone who's run Claude Code in a terminal for a week can identify the friction points 1code addresses. That's teachable knowledge. And if they can teach you to see it, eventually the platform will build it themselves.

The timing is pure consensus. AI coding tools are the single hottest category in technology right now. Cursor reached a billion in ARR in roughly two years. Every developer conference keynote is about agents writing code. Building "a better interface for coding agents" is not a contrarian bet -- it's the most obvious product idea in the ecosystem. When I invested in Uber, ride-sharing was illegal in most cities. When I backed Bitcoin in 2014, serious people called it tulip mania. Here, serious people are actively competing to build the same thing. Cursor, Windsurf, OpenHands, OpenAI's Codex app -- this space has more well-funded competitors than a company at this stage can credibly fight. The pricing already reflects the optimism. There's no asymmetry.

The bull case would require believing that coding agent orchestration becomes a durable middleware layer -- that agents remain heterogeneous commodities while the coordination plane captures value, the way Kubernetes captured value above commoditized containers. If that analogy held, 1code's agent-agnostic design and open-source community would be genuine advantages. The founders' shipping velocity would let them iterate faster than any single platform provider. The 5,000 GitHub stars suggest real developer interest, and the $20/$100 per month pricing on a daily-use tool could compound into meaningful revenue. But the analogy doesn't hold. Containers were interchangeable; coding agents are not. Anthropic and OpenAI differentiate on model quality, and each has overwhelming incentive to own the user experience around their own agent. There's no structural reason the orchestration layer stays independent when the platforms beneath it are controlled by two companies with the resources and motivation to build it themselves.

The founders have genuine execution talent -- I don't question that. Sergey's engineering credentials are real, and the ability to ship repeatedly is not nothing. But I keep coming back to the distinction between the identity of builder and the identity of domain expert. These founders are passionate about creating products. Whether the product is a UI component marketplace, a crypto bridge, an AI response generator, or an agent orchestration tool seems almost incidental. That pattern -- hopping between ideas, always shipping, never going deep -- is exactly the "more passionate about founding than about the specific problem" signal I've learned to watch for. The company I'd invest in here would be founded by someone who spent three years inside a large engineering organization wrestling with multi-agent coordination at scale, who understood the failure modes of concurrent code generation at a level that surprised me, who had a structural insight about why orchestration can't be done well inside the IDE. I don't see that founder in this dossier.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 10/30 |
| Leverage Architecture and Scalability of the Model | 11/25 |
| Contrarian Positioning and Non-Consensus Timing | 5/20 |
| Founder Integrity and Long-Term Orientation | 7/15 |
| Technical Compounding and Defensibility Over Time | 4/10 |
| **Total** | **37/100** |

**Total Score: 37/100** (Pass)
