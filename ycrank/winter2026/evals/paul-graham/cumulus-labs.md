# Cumulus Labs -- Paul Graham Evaluation

The first thing I notice about Cumulus Labs is the competitive landscape, and it's hard to look past. GPU cloud infrastructure is not a problem hiding in plain sight. It is the most visible infrastructure opportunity of the last five years. RunPod is at $120M ARR. Together AI has raised $533M. Fireworks has $327M. Lambda has $2.3 billion. Modal has $111M. When I wrote that "the two most impressive companies I've seen so far are not working on AI," this is exactly the kind of category I was warning about. A market where every VC in San Francisco is writing checks is a market where the upside has already been priced. Cumulus is entering a knife fight with a two-person team and $500K against opponents with a thousand times their resources. That doesn't automatically mean they lose -- David sometimes wins -- but you need a very specific reason to believe this David has a sling nobody else has.

The organic origin here is real, though, and it's the part that keeps me from dismissing this outright. Suryaa didn't sit down and brainstorm "what's a hot AI infrastructure idea." He built a distributed GPU marketplace at TensorDock as Lead Engineer. He was inside this problem daily -- wrestling with heterogeneous GPU supply, managing infrastructure at scale, seeing firsthand what broke and what users actually needed. Then he left to build Cumulus. That's the kind of organic discovery I look for: the idea grew from lived technical experience, not from reading market reports. The question I can't answer from the available evidence is *why* he left TensorDock. Did he see a specific architectural insight that TensorDock couldn't or wouldn't pursue? That would be a strong signal. Or did the aggregation model itself prove harder than expected? The dossier notes TensorDock "pursued a similar aggregation model" -- and the fact that the Lead Engineer left to try it again with a different approach could cut either way.

The bull case for Cumulus rests entirely on Ion, the proprietary inference engine. If the pitch is "we aggregate idle GPUs and charge per-second," that's a commodity play in a crowded market. But if the pitch is "we built an inference engine that's meaningfully faster than vLLM and SGLang, and we bundle it into a serverless platform so AI teams never have to think about serving optimization again," that's potentially a wedge. The 16.7-second cold start claim versus 70 seconds on Modal is the kind of specific, measurable performance advantage that could pull technical users. The problem is that Ion is listed as "coming soon" on their website, no public benchmarks exist, and open-source inference engines are improving at a pace that makes any performance lead ephemeral. vLLM and TensorRT-LLM have massive contributor communities. A two-person team trying to maintain an inference engine lead against open-source momentum -- that requires being an exceptional engineering animal, not just a competent one.

On the founder side, the technical backgrounds are relevant and specific. Both have CS degrees from strong programs. Suryaa's TensorDock experience is directly transferable. Veer Shah's aerospace work -- Space Force SBIR contracts, NASA programs that were commercialized and flight-tested -- shows he can build systems that work under constraints where failure is expensive. That's a different domain but a transferable quality. What concerns me is what I can't see. Neither founder has a public GitHub profile. For infrastructure founders building a developer tool, the absence of visible open-source work or technical footprint is unusual. I don't know if these founders are "animals" in the specific sense I mean -- people who stay up all night because they can't stop building. The SDK exists (`pip install cumulus-sdk`) and there's documentation, so they've clearly built something. But I have no way to evaluate the craft.

What's missing entirely is evidence that anyone actually wants this. No users, no revenue, no customer names, no waitlist numbers. A LinkedIn post with 487 likes is launch buzz, not user pull. The product is gated behind "Request Access" and "Book a Demo." I understand this is pre-seed and YC Winter 2026 just started, so thin evidence is expected. But in a category this competitive, where RunPod already has 500,000 developers and Together AI processes 10 trillion tokens a day, I'd want to see *some* signal -- even a handful of teams who tried Cumulus and stayed. A company at this stage fighting incumbents this large needs early users who are telling their friends without being asked. I see no trace of that.

For this to be a great investment, you'd need to believe three things: that Ion actually delivers a meaningful and durable performance advantage over open-source alternatives, that the aggregation model creates supply-side economics that improve with scale, and that Suryaa's TensorDock experience gives him an insight into GPU marketplace operations that his competitors -- with their hundreds of millions in funding -- haven't yet figured out. If all three are true, Cumulus could carve out a real position as the inference-optimized serverless platform. Cloudflare acquiring Replicate in November 2025 shows the space is consolidating, which could actually benefit a well-positioned newcomer. But that's multiple things that need to be true simultaneously, and each one is uncertain. I generally avoid bets that require more than one miracle.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Organic Problem Discovery and Schlep Willingness | 16/30 |
| Relentlessly Resourceful Founders | 12/25 |
| Evidence of Wanting: Demonstrated User Pull | 8/20 |
| Technical Hacker Founders Who Build | 9/15 |
| Growth Trajectory and Default Alive Economics | 5/10 |
| **Total** | **50/100** |

**Total Score: 50/100** (Neutral)
