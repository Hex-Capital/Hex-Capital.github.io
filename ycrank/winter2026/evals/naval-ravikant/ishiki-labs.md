# Ishiki Labs -- Naval Ravikant Evaluation

The most interesting tension here is a mismatch between the quality of the founders' specific knowledge and the consensus nature of the market they've chosen to enter. Amit Yadav and Robert Xu built exactly this system -- always-on, socially-aware multimodal AI -- at Meta's Reality Labs, for smart glasses that need to understand when a user is talking to them versus talking to someone else. That's not generic ML experience repackaged for a hot category. That's years of building production multimodal inference pipelines under the hardest possible constraints: real-time latency on constrained mobile hardware, continuous audio-visual processing, and social reasoning that most AI researchers haven't even attempted. Amit's 20+ publications at CVPR and NeurIPS in multimodal LLMs, combined with Robert's four years optimizing orchestration systems for Orion AR glasses -- this is the kind of knowledge that takes a competitor years to accumulate, if they can accumulate it at all. The specific knowledge bar is genuinely met.

But specific knowledge about the technology is not the same as specific knowledge about the problem. These founders know how to build a socially-aware multimodal system. What they haven't demonstrated -- at least not in any public evidence -- is a deep, non-obvious understanding of why meetings are broken in ways that transcription tools don't address. The best application of their knowledge might not be a meeting copilot at all. It might be the social awareness layer itself, sold as infrastructure to every developer building voice AI. When I backed Stack Overflow, the insight wasn't "let's build a better forum" -- it was that developer knowledge is a compounding graph with network effects that grow with every question. Ishiki Labs is building a meeting tool when they could be building the social intelligence API that powers a thousand meeting tools. That's an application-layer choice when the founders' specific knowledge screams infrastructure.

The leverage architecture concerns me. A meeting copilot is a SaaS tool -- it gives individual professionals some advantage in their calls, but it doesn't create a qualitatively new form of leverage. Compare this to Replit, which turned every non-programmer into a potential builder, or AngelList, which turned every accredited investor into a potential angel. Those created new categories of capability. Ishiki makes existing meetings slightly better. The product scales with code rather than headcount, which gives it baseline software leverage, but there's no network effect, no protocol, no marketplace dynamic that produces increasing returns. Each user's experience is largely independent of how many other people use the product.

The timing question is where this falls apart for me. Meeting AI is not contrarian -- it's one of the most consensus categories in technology right now. Otter.ai hit $100M ARR. Fireflies reached a billion-dollar valuation. Granola raised $67M. Read.ai raised $81M. Every investor in Silicon Valley thinks meeting AI is a good idea. You don't get paid for being right when everyone else is also right -- you get the returns that come from competing in a crowded market against well-capitalized incumbents. Yes, the "social awareness" angle within meeting AI is somewhat differentiated, but it's a feature distinction, not a category creation. When Zoom, Teams, or Google Meet add a "listen-only" mode with contextual coaching -- which is on every platform roadmap -- that feature distinction compresses to zero. The foundation model providers themselves (OpenAI with Voice Mode, Google with Gemini Live) are explicitly building toward socially-aware voice AI. Ishiki is running toward the incumbents, not away from them.

The strongest bull case would require believing that social awareness in AI is fundamentally harder than it appears -- that the gap between "voice AI that can converse" and "AI that truly understands social context" is as large as the gap between search and social networking was in 2004. If that's true, then these founders, having spent years at the frontier of this problem at Meta, have a multi-year head start that no amount of funding can close. The meeting copilot becomes the wedge, not the destination -- they'd expand to become the social intelligence layer for all AI interactions, the way Twilio became the communications layer. In that scenario, the meeting data they collect compounds into an unassailable understanding of human social dynamics that no foundation model trained on internet text can replicate. That's a real possibility. But it requires the founders to have the vision and discipline to resist becoming just another meeting SaaS company -- and right now, the positioning as "Fern, your meeting copilot" doesn't signal that ambition.

I'd need a conversation with these founders to understand whether they see meetings as the product or as training data for something larger. The specific knowledge is there. The leverage architecture and contrarian positioning are not. Smart people with deep technical knowledge building in a consensus category against well-funded competitors and platform incumbents -- that's a recipe for a solid company, not a defining one.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Specific Knowledge and Founder-Problem Authenticity | 20/30 |
| Leverage Architecture and Scalability of the Model | 11/25 |
| Contrarian Positioning and Non-Consensus Timing | 8/20 |
| Founder Integrity and Long-Term Orientation | 8/15 |
| Technical Compounding and Defensibility Over Time | 5/10 |
| **Total** | **52/100** |

**Total Score: 52/100** (Neutral)
