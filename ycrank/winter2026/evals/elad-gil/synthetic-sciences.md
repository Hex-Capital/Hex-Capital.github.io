# Synthetic Sciences -- Elad Gil Evaluation

The first thing I notice about Synthetic Sciences is the competitive landscape -- and not in a good way. Google announced its AI Co-Scientist in February 2025. Periodic Labs raised $300M. Edison Scientific raised $70M from Spark Capital with Eric Schmidt's backing. Sciloop, a directly comparable company, went through YC one batch earlier with MIT CSAIL founders who are International Physics Olympiad medalists. When I look at a market and see Google, $370M+ in venture funding to competitors, and a near-identical YC company already a batch ahead, that's not a non-obvious market at a structural inflection. That's a consensus-hot category where everyone has arrived at the same thesis simultaneously. My best investments -- PagerDuty, Gusto, Coinbase at the time -- were in markets other investors dismissed. Nobody is dismissing AI for science. The "why now" is real (LLM reasoning crossed a threshold, GPU compute commoditized through Modal and Lambda), but when every participant in the market can articulate the same "why now," the structural moment advantage evaporates. You're left competing on execution against teams with 100x your capital.

The founders are genuinely impressive for 18-year-olds -- 15+ papers at ICML/IEEE/ACL, research stints at MIT CSAIL, CMU, Harvard, Oxford, Berkeley, and Cambridge. Aayam Bansal has one prior exit. Both are Z-Fellows and Emergent Ventures recipients. They've shipped a real product with 93 pre-built research skills and 12 service integrations. That's meaningful velocity. But I keep coming back to the single-miracle test, and I can't find the single miracle here. The product spans literature search, hypothesis scoping, methodology design, GPU-orchestrated experimentation, results analysis, and LaTeX paper generation -- five operational modes across the entire research lifecycle. In parallel, the company is also building "RL environments and process-based training data for LLMs." That's not one company organized around one miracle. That's two companies trying to do everything. When the founding team is two people and you're competing against Google and a $300M-funded startup, breadth is a liability, not a strength.

The bull case is worth engaging seriously. These founders have lived the computational research workflow -- they're not tourists building for a market they read about. Fifteen papers at top venues by age 18 means they understand the pain points viscerally, the way Stripe's founders understood developer pain with payments. If they focus narrowly on ML researchers (not broad science), the $50/month PLG entry point is smart for a community of grad students and postdocs. The stated data flywheel -- product usage generating process data for RL-trained agents -- is directionally correct: if you accumulate proprietary training signal from how thousands of researchers iterate on experiments, that compounds in a way competitors can't easily replicate. And the best argument for the company is a version of what I've seen before: incumbents like Google will build this for academic partnerships and demos, not as a commercial product for individual researchers. Large cloud providers won't support multi-cloud GPU orchestration because it conflicts with their lock-in incentives. A focused startup could own the gap. For this to work, though, the founders need to reach meaningful user scale before Sciloop does, before Google expands its Trusted Tester Program, and before Edison or Periodic pivot into computational domains. That's a lot of races to win simultaneously.

The brand confusion concerns me as an operational signal. The company operates as "Synthetic Sciences" on its YC page and product website, "InkVell" on LinkedIn and in press coverage, under the legal entity "Inkvell Inc." Earlier coverage describes InkVell as "an AI-powered platform addressing research and document productivity" -- suggesting a pivot from an AI LaTeX editor to a full AI co-scientist platform. Pivoting is fine; I've backed founders who pivoted aggressively. But pivoting toward whatever category just became consensus-hot -- right after Google validated "AI Co-Scientist" as a category in February 2025 -- fits the pattern I describe in my End of Cycle essay: founders entering a trendy sector because that's where the funding is, not because they've identified a structural gap others have missed. I don't have enough evidence to confirm that's what happened here, but the timeline is suggestive.

On the product-to-distribution dimension, there's a glimmer of something interesting. The twelve integrations with ML infrastructure providers (Hugging Face, Modal, Lambda, Pinecone, LangSmith) position the product as an orchestration layer across the ML stack. If researchers build workflows that depend on these integrations, switching costs develop. The five modes suggest multi-product thinking from day one. But there's no evidence of distribution execution -- no community channels, no Product Hunt launch, no social media presence, no user counts. Distribution thinking without distribution execution is just a slide deck. I need to see that the company is a distribution channel, not just a product with features.

I'm passing on this one. The market is real but consensus. The competitive dynamics are brutal for a two-person pre-seed team. The founders are talented but attempting to boil the ocean with a full-lifecycle product while simultaneously building RL training infrastructure. The single miracle isn't identified -- and honestly, this company needs at least two miracles: building a product that out-executes both Sciloop and Google's expanding AI Co-Scientist, AND reaching enough user scale to generate the proprietary training data that creates a flywheel before better-capitalized competitors do. Compounding small odds.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Non-Obvious Market at Structural Inflection | 10/35 |
| Product-to-Distribution Trajectory | 11/25 |
| Single-Miracle Operational Clarity | 5/15 |
| Founder Execution Velocity | 9/15 |
| Technology Cycle Positioning | 6/10 |
| **Total** | **41/100** |

**Total Score: 41/100** (Pass)
