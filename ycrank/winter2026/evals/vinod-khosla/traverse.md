# Traverse -- Vinod Khosla Evaluation

Here is the question I keep coming back to with Traverse: these founders pivoted from building an AI agent product -- Clice AI, personal AI agents that execute tasks for teams -- to selling reinforcement learning environments to the same labs that build those agents. They moved from attempting to create something that transforms how teams work to becoming a vendor in someone else's training pipeline. That directional choice tells me a lot. It suggests founders optimizing for near-term sellability rather than consequence magnitude. The transformation they're adjacent to -- AI that reasons well about medicine, law, scientific research -- belongs to Anthropic and OpenAI if it happens. Traverse captures a consulting contract. When I backed OpenAI in 2019, I was investing in the entity that would create the intelligence itself. A company selling training environments to that entity is a fundamentally different bet on the value chain, and the consequence of its success is fundamentally smaller.

The competitive landscape should alarm anyone paying attention. More than 35 companies building RL environments. Scale AI at $29 billion and $870 million in revenue, already expanding into this exact space. Surge AI doing $1.2 billion in revenue and seeking a $15 billion valuation. Mechanize, backed by Nat Friedman and Daniel Gross, already contracting with Anthropic. And the buyer universe is what -- five, maybe ten frontier AI labs? This is a market where a two-person team fresh off a pivot is competing for the same purchase orders as companies with thousands of employees and billions in capital. The Wing VC analysis projects consolidation to three to five leaders by 2030. Traverse is bringing a slingshot to an artillery battle, and the battlefield is a narrow corridor with a handful of exits.

The claimed differentiation -- non-deterministic verifiers for subjective tasks -- is intellectually interesting but unsubstantiated. Building a verifier that can assess whether a legal argument is persuasive or a medical diagnosis is sound is genuinely harder than grading math problems. I grant that. But the dossier is explicit: "no defensibility signals found in public sources." No proprietary datasets, no patents, no demonstrated verifier that outperforms alternatives. The concept that large data-labeling companies are structurally unable to retool for taste-dependent verification is stated as a possibility, not established as fact. Scale AI built its empire by solving hard labeling problems at scale -- assuming they cannot solve this one is the kind of assumption that gets a startup killed.

The strongest bull case requires one thing to be true: that non-deterministic verification is a genuinely distinct technical capability, not an extension of existing data labeling, and that cracking it requires a fundamentally different approach that Scale AI's infrastructure cannot replicate. If the founders have real insight into how to construct verifiers for subjective domains -- perhaps leveraging Lance Yan's experience with probabilistic reasoning at Kalshi and Zachary Yu's exposure to AI lab contracting workflows at Mercor -- they could establish a learning-curve advantage that compounds with each lab deployment. If RL for non-deterministic tasks becomes the primary bottleneck in frontier model improvement, the company that solves verification owns a chokepoint. In that scenario, the TAM expands dramatically beyond current projections, and being the specialist while Scale AI remains the generalist could be a viable wedge. But this requires the founders to have technical insight that 35 other entrants lack, with no evidence yet that they do.

The founders themselves show some positive signals -- Yan dropped out after one semester, which I respect, and Yu shipped a product to 25,000 users in 24 hours, which shows velocity. The pivot from Clice AI to Traverse during YC could be read as rapid learning rather than indecision. But neither founder brings domain expertise in the non-deterministic fields they claim to serve. If your thesis is building verifiers for medical and legal reasoning, having zero medical or legal expertise on a two-person team is not just a gap -- it contradicts the core value proposition. And they are ML engineers building ML infrastructure, which is the opposite of the outsider pattern I look for. There is nothing contrarian about RL environments in early 2026. This is consensus investing dressed in technical language.

I pass. The consequence of success is a vendor business to a concentrated set of customers in a space where the incumbents have a thousandfold resource advantage. The problem worth solving here -- making AI genuinely capable in subjective domains -- is important enough that I would fund a company attacking it directly. But selling training environments to the companies that will capture that value is not the same bet. These founders are too technically capable to spend their careers as a subcontractor to Anthropic's training pipeline. I would tell them: stop selling picks and shovels. Go build the mine.

### Dimension Scores

| Criterion | Score |
|-----------|-------|
| Consequence Magnitude If Successful | 10/30 |
| Founder Learning Rate and Contrarian Courage | 11/25 |
| Technology Disruption Potential vs. Incumbent Systems | 7/20 |
| Rate of Change and Timing Trajectory | 9/15 |
| Gene Pool Engineering and Team Construction | 4/10 |
| **Total** | **41/100** |

**Total Score: 41/100** (Pass)
